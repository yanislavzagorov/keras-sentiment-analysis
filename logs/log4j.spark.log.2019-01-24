19/01/24 17:26:48 INFO SparkContext: Running Spark version 2.2.0
19/01/24 17:26:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 17:26:48 INFO SparkContext: Submitted application: sparklyr
19/01/24 17:26:48 INFO SecurityManager: Changing view acls to: yanis
19/01/24 17:26:48 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 17:26:48 INFO SecurityManager: Changing view acls groups to: 
19/01/24 17:26:48 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 17:26:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 17:26:48 INFO Utils: Successfully started service 'sparkDriver' on port 52529.
19/01/24 17:26:48 INFO SparkEnv: Registering MapOutputTracker
19/01/24 17:26:48 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 17:26:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 17:26:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 17:26:48 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-5e7e1d9a-120d-483d-adab-a9f4d5aee0c3
19/01/24 17:26:48 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 17:26:48 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 17:26:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 17:26:49 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 17:26:49 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:52529/jars/sparklyr-2.2-2.11.jar with timestamp 1548347209183
19/01/24 17:26:49 INFO Executor: Starting executor ID driver on host localhost
19/01/24 17:26:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52573.
19/01/24 17:26:49 INFO NettyBlockTransferService: Server created on 127.0.0.1:52573
19/01/24 17:26:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 17:26:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52573, None)
19/01/24 17:26:49 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:52573 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 52573, None)
19/01/24 17:26:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52573, None)
19/01/24 17:26:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52573, None)
19/01/24 17:26:49 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 17:26:49 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 17:26:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 17:26:49 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 17:26:50 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 17:26:50 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 17:26:50 INFO ObjectStore: ObjectStore, initialize called
19/01/24 17:26:50 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 17:26:50 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 17:26:51 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 17:26:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 17:26:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 17:26:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 17:26:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 17:26:53 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 17:26:53 INFO ObjectStore: Initialized ObjectStore
19/01/24 17:26:53 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 17:26:53 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 17:26:53 INFO HiveMetaStore: Added admin role in metastore
19/01/24 17:26:53 INFO HiveMetaStore: Added public role in metastore
19/01/24 17:26:53 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 17:26:53 INFO HiveMetaStore: 0: get_all_databases
19/01/24 17:26:53 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 17:26:53 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 17:26:53 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 17:26:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 17:26:53 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/4dbbbe9c-3bf0-4475-ae62-8d1668119960_resources
19/01/24 17:26:53 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/4dbbbe9c-3bf0-4475-ae62-8d1668119960
19/01/24 17:26:53 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/4dbbbe9c-3bf0-4475-ae62-8d1668119960
19/01/24 17:26:53 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/4dbbbe9c-3bf0-4475-ae62-8d1668119960/_tmp_space.db
19/01/24 17:26:53 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 17:26:53 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:26:53 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:26:53 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 17:26:53 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 17:26:53 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 17:26:54 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/c16c0286-087b-4d08-a214-b6bb17a44523_resources
19/01/24 17:26:54 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/c16c0286-087b-4d08-a214-b6bb17a44523
19/01/24 17:26:54 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/c16c0286-087b-4d08-a214-b6bb17a44523
19/01/24 17:26:54 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/c16c0286-087b-4d08-a214-b6bb17a44523/_tmp_space.db
19/01/24 17:26:54 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 17:26:54 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 17:26:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 17:26:56 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:26:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:26:56 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:26:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:26:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 17:26:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 17:26:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 17:26:56 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:26:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:26:56 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:26:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:26:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 17:26:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 17:27:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 17:27:15 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:27:15 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:27:15 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:27:15 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:27:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 17:27:15 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 17:27:15 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 17:27:15 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 17:27:15 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 17:27:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 17:27:15 INFO DAGScheduler: Missing parents: List()
19/01/24 17:27:15 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 17:27:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 17:27:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 17:27:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:52573 (size: 3.4 KB, free: 366.3 MB)
19/01/24 17:27:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 17:27:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 17:27:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 17:27:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 17:27:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 17:27:15 INFO Executor: Fetching spark://127.0.0.1:52529/jars/sparklyr-2.2-2.11.jar with timestamp 1548347209183
19/01/24 17:27:15 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:52529 after 14 ms (0 ms spent in bootstraps)
19/01/24 17:27:15 INFO Utils: Fetching spark://127.0.0.1:52529/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-ea4ed310-2bc9-48c3-8fab-b89c766d21d3\userFiles-5c870036-f0cd-4e7f-87c3-23ff6c3eeb0e\fetchFileTemp1539493563819325421.tmp
19/01/24 17:27:15 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-ea4ed310-2bc9-48c3-8fab-b89c766d21d3/userFiles-5c870036-f0cd-4e7f-87c3-23ff6c3eeb0e/sparklyr-2.2-2.11.jar to class loader
19/01/24 17:27:16 INFO CodeGenerator: Code generated in 166.14944 ms
19/01/24 17:27:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/01/24 17:27:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 512 ms on localhost (executor driver) (1/1)
19/01/24 17:27:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 17:27:16 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,529 s
19/01/24 17:27:16 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,701183 s
19/01/24 17:27:16 INFO SparkSqlParser: Parsing command: reviews
19/01/24 17:27:16 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 17:27:16 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 17:27:16 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:52573 in memory (size: 3.4 KB, free: 366.3 MB)
19/01/24 17:27:16 INFO CodeGenerator: Code generated in 13.395508 ms
19/01/24 17:27:16 INFO CodeGenerator: Code generated in 8.500876 ms
19/01/24 17:27:16 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 17:27:16 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 17:27:16 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 17:27:16 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 17:27:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 17:27:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 17:27:16 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 17:27:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.6 KB, free 366.3 MB)
19/01/24 17:27:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 17:27:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:52573 (size: 7.7 KB, free: 366.3 MB)
19/01/24 17:27:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 17:27:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 17:27:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 17:27:17 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 17:27:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 17:27:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 17:27:17 INFO CodeGenerator: Code generated in 9.625525 ms
19/01/24 17:27:17 INFO CodeGenerator: Code generated in 18.404282 ms
19/01/24 17:27:17 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1885.3 KB, free 364.4 MB)
19/01/24 17:27:17 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:52573 (size: 1885.3 KB, free: 364.5 MB)
19/01/24 17:27:17 INFO CodeGenerator: Code generated in 4.317355 ms
19/01/24 17:27:17 INFO CodeGenerator: Code generated in 19.945387 ms
19/01/24 17:27:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 17:27:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 365 ms on localhost (executor driver) (1/1)
19/01/24 17:27:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 17:27:17 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,366 s
19/01/24 17:27:17 INFO DAGScheduler: looking for newly runnable stages
19/01/24 17:27:17 INFO DAGScheduler: running: Set()
19/01/24 17:27:17 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 17:27:17 INFO DAGScheduler: failed: Set()
19/01/24 17:27:17 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 17:27:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 17:27:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 17:27:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:52573 (size: 3.7 KB, free: 364.4 MB)
19/01/24 17:27:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 17:27:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 17:27:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 17:27:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 17:27:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 17:27:17 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 17:27:17 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:52573 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 17:27:17 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 17:27:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 17:27:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/01/24 17:27:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
19/01/24 17:27:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 138 ms on localhost (executor driver) (1/1)
19/01/24 17:27:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 17:27:17 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,139 s
19/01/24 17:27:17 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,545317 s
19/01/24 17:27:17 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 17:27:17 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:27:17 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:27:17 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 17:27:17 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 17:27:17 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 17:27:17 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 17:27:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 17:27:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 17:27:17 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 17:27:17 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.6 KB, free 364.4 MB)
19/01/24 17:27:17 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.4 MB)
19/01/24 17:27:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:52573 (size: 7.7 KB, free: 364.4 MB)
19/01/24 17:27:17 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 17:27:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 17:27:17 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 17:27:17 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 17:27:17 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 17:27:17 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 17:27:17 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 17:27:17 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
19/01/24 17:27:17 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 45 ms on localhost (executor driver) (1/1)
19/01/24 17:27:17 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 17:27:17 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,046 s
19/01/24 17:27:17 INFO DAGScheduler: looking for newly runnable stages
19/01/24 17:27:17 INFO DAGScheduler: running: Set()
19/01/24 17:27:17 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 17:27:17 INFO DAGScheduler: failed: Set()
19/01/24 17:27:17 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 17:27:17 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 17:27:17 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 17:27:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:52573 (size: 3.7 KB, free: 364.4 MB)
19/01/24 17:27:17 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 17:27:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 17:27:17 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 17:27:17 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 17:27:17 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 17:27:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 17:27:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 17:27:17 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/01/24 17:27:17 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 4 ms on localhost (executor driver) (1/1)
19/01/24 17:27:17 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 17:27:17 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,004 s
19/01/24 17:27:17 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,066584 s
19/01/24 17:27:17 INFO CodeGenerator: Code generated in 4.942403 ms
19/01/24 17:27:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz1`
WHERE (0 = 1)
19/01/24 17:27:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 17:27:18 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:27:18 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:27:18 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:27:18 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:27:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 17:27:18 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 17:27:18 INFO CodeGenerator: Code generated in 6.350403 ms
19/01/24 17:27:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 17:27:19 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d820023324
19/01/24 17:27:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d820023324` AS `zzz2`
WHERE (0 = 1)
19/01/24 17:27:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d820023324`
19/01/24 17:27:21 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d82d8128bd
19/01/24 17:27:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82d8128bd` AS `zzz3`
WHERE (0 = 1)
19/01/24 17:29:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82d8128bd`
LIMIT 7
19/01/24 17:29:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82d8128bd`
LIMIT 7
19/01/24 17:29:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82d8128bd`
LIMIT 7
19/01/24 17:29:03 INFO CodeGenerator: Code generated in 29.881977 ms
19/01/24 17:29:03 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 17:29:03 INFO DAGScheduler: Got job 3 (collect at utils.scala:200) with 1 output partitions
19/01/24 17:29:03 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:200)
19/01/24 17:29:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 17:29:03 INFO DAGScheduler: Missing parents: List()
19/01/24 17:29:03 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:200), which has no missing parents
19/01/24 17:29:03 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 24.1 KB, free 364.4 MB)
19/01/24 17:29:03 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.6 KB, free 364.4 MB)
19/01/24 17:29:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:52573 (size: 10.6 KB, free: 364.4 MB)
19/01/24 17:29:03 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 17:29:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 17:29:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 17:29:03 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 17:29:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 17:29:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 17:29:03 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 17:29:03 INFO CodeGenerator: Code generated in 16.371963 ms
19/01/24 17:29:03 INFO Executor: 1 block locks were not released by TID = 5:
[rdd_9_0]
19/01/24 17:29:03 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 3884 bytes result sent to driver
19/01/24 17:29:03 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 91 ms on localhost (executor driver) (1/1)
19/01/24 17:29:03 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 17:29:03 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:200) finished in 0,091 s
19/01/24 17:29:03 INFO DAGScheduler: Job 3 finished: collect at utils.scala:200, took 0,101656 s
19/01/24 17:29:03 INFO CodeGenerator: Code generated in 16.900373 ms
19/01/24 17:29:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82d8128bd`
LIMIT 7
19/01/24 17:30:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82d8128bd`
19/01/24 17:30:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82d8128bd`
19/01/24 17:31:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82d8128bd`
19/01/24 17:31:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82d8128bd`
19/01/24 17:42:10 INFO SparkSqlParser: Parsing command: SELECT * FROM reviews LIMIT 5
19/01/24 17:42:10 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 17:42:10 INFO DAGScheduler: Got job 4 (collect at utils.scala:200) with 1 output partitions
19/01/24 17:42:10 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:200)
19/01/24 17:42:10 INFO DAGScheduler: Parents of final stage: List()
19/01/24 17:42:10 INFO DAGScheduler: Missing parents: List()
19/01/24 17:42:10 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:200), which has no missing parents
19/01/24 17:42:10 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.2 KB, free 364.4 MB)
19/01/24 17:42:10 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.7 KB, free 364.4 MB)
19/01/24 17:42:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:52573 (size: 5.7 KB, free: 364.4 MB)
19/01/24 17:42:10 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 17:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 17:42:10 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 17:42:10 WARN TaskSetManager: Stage 6 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 17:42:10 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 17:42:10 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 17:42:10 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 17:42:10 INFO Executor: 1 block locks were not released by TID = 6:
[rdd_9_0]
19/01/24 17:42:10 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1840 bytes result sent to driver
19/01/24 17:42:10 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 34 ms on localhost (executor driver) (1/1)
19/01/24 17:42:10 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 17:42:10 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:200) finished in 0,034 s
19/01/24 17:42:10 INFO DAGScheduler: Job 4 finished: collect at utils.scala:200, took 0,045519 s
19/01/24 17:42:10 INFO CodeGenerator: Code generated in 7.961525 ms
19/01/24 17:46:39 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 17:46:39 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 17:46:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 17:46:39 INFO MemoryStore: MemoryStore cleared
19/01/24 17:46:39 INFO BlockManager: BlockManager stopped
19/01/24 17:46:39 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 17:46:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 17:46:39 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-ea4ed310-2bc9-48c3-8fab-b89c766d21d3\userFiles-5c870036-f0cd-4e7f-87c3-23ff6c3eeb0e
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-ea4ed310-2bc9-48c3-8fab-b89c766d21d3\userFiles-5c870036-f0cd-4e7f-87c3-23ff6c3eeb0e
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 17:46:39 INFO SparkContext: Successfully stopped SparkContext
19/01/24 17:46:39 INFO ShutdownHookManager: Shutdown hook called
19/01/24 17:46:39 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-ea4ed310-2bc9-48c3-8fab-b89c766d21d3
19/01/24 17:46:39 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-ea4ed310-2bc9-48c3-8fab-b89c766d21d3
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-ea4ed310-2bc9-48c3-8fab-b89c766d21d3
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 17:46:39 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-ea4ed310-2bc9-48c3-8fab-b89c766d21d3\userFiles-5c870036-f0cd-4e7f-87c3-23ff6c3eeb0e
19/01/24 17:46:39 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-ea4ed310-2bc9-48c3-8fab-b89c766d21d3\userFiles-5c870036-f0cd-4e7f-87c3-23ff6c3eeb0e
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-ea4ed310-2bc9-48c3-8fab-b89c766d21d3\userFiles-5c870036-f0cd-4e7f-87c3-23ff6c3eeb0e
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 17:46:50 INFO SparkContext: Running Spark version 2.2.0
19/01/24 17:46:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 17:46:50 INFO SparkContext: Submitted application: sparklyr
19/01/24 17:46:50 INFO SecurityManager: Changing view acls to: yanis
19/01/24 17:46:50 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 17:46:50 INFO SecurityManager: Changing view acls groups to: 
19/01/24 17:46:50 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 17:46:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 17:46:50 INFO Utils: Successfully started service 'sparkDriver' on port 52845.
19/01/24 17:46:50 INFO SparkEnv: Registering MapOutputTracker
19/01/24 17:46:50 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 17:46:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 17:46:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 17:46:50 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-56ce81da-2950-4835-83f4-11036994ea41
19/01/24 17:46:51 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 17:46:51 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 17:46:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 17:46:51 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 17:46:51 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:52845/jars/sparklyr-2.2-2.11.jar with timestamp 1548348411265
19/01/24 17:46:51 INFO Executor: Starting executor ID driver on host localhost
19/01/24 17:46:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52886.
19/01/24 17:46:51 INFO NettyBlockTransferService: Server created on 127.0.0.1:52886
19/01/24 17:46:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 17:46:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52886, None)
19/01/24 17:46:51 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:52886 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 52886, None)
19/01/24 17:46:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52886, None)
19/01/24 17:46:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52886, None)
19/01/24 17:46:51 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 17:46:51 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 17:46:51 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 17:46:51 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 17:46:52 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 17:46:52 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 17:46:52 INFO ObjectStore: ObjectStore, initialize called
19/01/24 17:46:52 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 17:46:52 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 17:46:53 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 17:46:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 17:46:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 17:46:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 17:46:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 17:46:55 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 17:46:55 INFO ObjectStore: Initialized ObjectStore
19/01/24 17:46:55 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 17:46:55 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 17:46:55 INFO HiveMetaStore: Added admin role in metastore
19/01/24 17:46:55 INFO HiveMetaStore: Added public role in metastore
19/01/24 17:46:55 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 17:46:55 INFO HiveMetaStore: 0: get_all_databases
19/01/24 17:46:55 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 17:46:55 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 17:46:55 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 17:46:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 17:46:55 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/cdf481b3-2831-4cfd-a3eb-c979dd3b2086_resources
19/01/24 17:46:55 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/cdf481b3-2831-4cfd-a3eb-c979dd3b2086
19/01/24 17:46:55 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/cdf481b3-2831-4cfd-a3eb-c979dd3b2086
19/01/24 17:46:55 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/cdf481b3-2831-4cfd-a3eb-c979dd3b2086/_tmp_space.db
19/01/24 17:46:55 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 17:46:55 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:46:55 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:46:55 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 17:46:55 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 17:46:55 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 17:46:55 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/43e8bc8c-20bf-4f5b-a0b4-6d4ecb8d0e4e_resources
19/01/24 17:46:56 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/43e8bc8c-20bf-4f5b-a0b4-6d4ecb8d0e4e
19/01/24 17:46:56 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/43e8bc8c-20bf-4f5b-a0b4-6d4ecb8d0e4e
19/01/24 17:46:56 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/43e8bc8c-20bf-4f5b-a0b4-6d4ecb8d0e4e/_tmp_space.db
19/01/24 17:46:56 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 17:46:56 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 17:46:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 17:46:57 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:46:57 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:46:57 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:46:57 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:46:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 17:46:57 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 17:46:58 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 17:46:58 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 17:46:58 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 17:46:58 INFO DAGScheduler: Parents of final stage: List()
19/01/24 17:46:58 INFO DAGScheduler: Missing parents: List()
19/01/24 17:46:58 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 17:46:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 17:46:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 17:46:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:52886 (size: 3.4 KB, free: 366.3 MB)
19/01/24 17:46:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 17:46:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 17:46:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 17:46:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 17:46:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 17:46:58 INFO Executor: Fetching spark://127.0.0.1:52845/jars/sparklyr-2.2-2.11.jar with timestamp 1548348411265
19/01/24 17:46:58 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:52845 after 14 ms (0 ms spent in bootstraps)
19/01/24 17:46:58 INFO Utils: Fetching spark://127.0.0.1:52845/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-21682cda-6b8f-4305-bb9f-9b16a8addc8a\userFiles-72592bee-bfc7-463b-8a23-e3d6f0a14dc8\fetchFileTemp8945053041562886949.tmp
19/01/24 17:46:58 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-21682cda-6b8f-4305-bb9f-9b16a8addc8a/userFiles-72592bee-bfc7-463b-8a23-e3d6f0a14dc8/sparklyr-2.2-2.11.jar to class loader
19/01/24 17:46:58 INFO CodeGenerator: Code generated in 167.793747 ms
19/01/24 17:46:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/01/24 17:46:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 551 ms on localhost (executor driver) (1/1)
19/01/24 17:46:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 17:46:58 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,566 s
19/01/24 17:46:58 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,739961 s
19/01/24 17:46:59 INFO SparkSqlParser: Parsing command: reviews
19/01/24 17:46:59 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 17:46:59 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 17:46:59 INFO CodeGenerator: Code generated in 14.641592 ms
19/01/24 17:46:59 INFO CodeGenerator: Code generated in 8.260557 ms
19/01/24 17:46:59 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 17:46:59 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 17:46:59 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 17:46:59 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 17:46:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 17:46:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 17:46:59 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 17:46:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.6 KB, free 366.3 MB)
19/01/24 17:46:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 17:46:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:52886 (size: 7.7 KB, free: 366.3 MB)
19/01/24 17:46:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 17:46:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 17:46:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 17:46:59 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 17:46:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 17:46:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 17:46:59 INFO CodeGenerator: Code generated in 10.553616 ms
19/01/24 17:46:59 INFO CodeGenerator: Code generated in 20.058436 ms
19/01/24 17:46:59 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1885.3 KB, free 364.4 MB)
19/01/24 17:46:59 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:52886 (size: 1885.3 KB, free: 364.4 MB)
19/01/24 17:46:59 INFO CodeGenerator: Code generated in 4.444991 ms
19/01/24 17:46:59 INFO CodeGenerator: Code generated in 16.119974 ms
19/01/24 17:46:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 17:46:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 375 ms on localhost (executor driver) (1/1)
19/01/24 17:46:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 17:46:59 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,376 s
19/01/24 17:46:59 INFO DAGScheduler: looking for newly runnable stages
19/01/24 17:46:59 INFO DAGScheduler: running: Set()
19/01/24 17:46:59 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 17:46:59 INFO DAGScheduler: failed: Set()
19/01/24 17:46:59 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 17:46:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 17:46:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 17:46:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:52886 (size: 3.7 KB, free: 364.4 MB)
19/01/24 17:46:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 17:46:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 17:46:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 17:46:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 17:46:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 17:46:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 17:46:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
19/01/24 17:46:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1538 bytes result sent to driver
19/01/24 17:46:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (executor driver) (1/1)
19/01/24 17:46:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 17:46:59 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,029 s
19/01/24 17:46:59 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,448813 s
19/01/24 17:46:59 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 17:47:00 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:52886 in memory (size: 3.4 KB, free: 364.4 MB)
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 17:47:00 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:52886 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 17:47:00 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 17:47:00 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:52886 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 17:47:00 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 17:47:00 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:47:00 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:47:00 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 17:47:00 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 17:47:00 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 17:47:00 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 17:47:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 17:47:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 17:47:00 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 17:47:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.6 KB, free 364.4 MB)
19/01/24 17:47:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.4 MB)
19/01/24 17:47:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:52886 (size: 7.7 KB, free: 364.5 MB)
19/01/24 17:47:00 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 17:47:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 17:47:00 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 17:47:00 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 17:47:00 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 17:47:00 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 17:47:00 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 17:47:00 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1647 bytes result sent to driver
19/01/24 17:47:00 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 51 ms on localhost (executor driver) (1/1)
19/01/24 17:47:00 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 17:47:00 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,052 s
19/01/24 17:47:00 INFO DAGScheduler: looking for newly runnable stages
19/01/24 17:47:00 INFO DAGScheduler: running: Set()
19/01/24 17:47:00 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 17:47:00 INFO DAGScheduler: failed: Set()
19/01/24 17:47:00 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 17:47:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 17:47:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 17:47:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:52886 (size: 3.7 KB, free: 364.4 MB)
19/01/24 17:47:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 17:47:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 17:47:00 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 17:47:00 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 17:47:00 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 17:47:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 17:47:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 17:47:00 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
19/01/24 17:47:00 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
19/01/24 17:47:00 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 17:47:00 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,005 s
19/01/24 17:47:00 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,074509 s
19/01/24 17:47:00 INFO CodeGenerator: Code generated in 5.828557 ms
19/01/24 17:47:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz4`
WHERE (0 = 1)
19/01/24 17:47:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 17:47:00 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:47:00 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:47:00 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:47:00 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:47:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 17:47:00 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 17:47:00 INFO CodeGenerator: Code generated in 8.395486 ms
19/01/24 17:47:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 17:47:00 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:47:00 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:47:00 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:47:00 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:47:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 17:47:00 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 17:47:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 17:47:00 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d83224264a
19/01/24 17:47:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83224264a` AS `zzz5`
WHERE (0 = 1)
19/01/24 17:47:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83224264a`
19/01/24 17:47:02 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d815a734b1
19/01/24 17:47:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d815a734b1` AS `zzz6`
WHERE (0 = 1)
19/01/24 17:47:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d815a734b1`
19/01/24 17:47:34 INFO SparkSqlParser: Parsing command: SELECT * FROM reviews LIMIT 5
19/01/24 17:47:34 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 17:47:34 INFO DAGScheduler: Got job 3 (collect at utils.scala:200) with 1 output partitions
19/01/24 17:47:34 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:200)
19/01/24 17:47:34 INFO DAGScheduler: Parents of final stage: List()
19/01/24 17:47:34 INFO DAGScheduler: Missing parents: List()
19/01/24 17:47:34 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:200), which has no missing parents
19/01/24 17:47:34 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.2 KB, free 364.4 MB)
19/01/24 17:47:34 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 364.4 MB)
19/01/24 17:47:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:52886 (size: 5.7 KB, free: 364.4 MB)
19/01/24 17:47:34 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 17:47:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 17:47:34 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 17:47:34 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 17:47:34 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 17:47:34 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 17:47:34 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 17:47:34 INFO CodeGenerator: Code generated in 12.021422 ms
19/01/24 17:47:34 INFO Executor: 1 block locks were not released by TID = 5:
[rdd_9_0]
19/01/24 17:47:34 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1883 bytes result sent to driver
19/01/24 17:47:34 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 54 ms on localhost (executor driver) (1/1)
19/01/24 17:47:34 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 17:47:34 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:200) finished in 0,055 s
19/01/24 17:47:34 INFO DAGScheduler: Job 3 finished: collect at utils.scala:200, took 0,063301 s
19/01/24 17:47:34 INFO CodeGenerator: Code generated in 6.503201 ms
19/01/24 17:58:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 17:58:35 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:58:35 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:58:35 INFO HiveMetaStore: 0: get_database: default
19/01/24 17:58:35 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 17:58:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 17:58:35 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 17:58:35 INFO CodeGenerator: Code generated in 5.456591 ms
19/01/24 17:58:35 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 17:58:36 INFO DAGScheduler: Got job 4 (collect at utils.scala:44) with 3 output partitions
19/01/24 17:58:36 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:44)
19/01/24 17:58:36 INFO DAGScheduler: Parents of final stage: List()
19/01/24 17:58:36 INFO DAGScheduler: Missing parents: List()
19/01/24 17:58:36 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41), which has no missing parents
19/01/24 17:58:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.5 KB, free 364.4 MB)
19/01/24 17:58:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.6 KB, free 364.4 MB)
19/01/24 17:58:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:52886 (size: 3.6 KB, free: 364.4 MB)
19/01/24 17:58:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 17:58:36 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/01/24 17:58:36 INFO TaskSchedulerImpl: Adding task set 6.0 with 3 tasks
19/01/24 17:58:36 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/01/24 17:58:36 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
19/01/24 17:58:36 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 5035 bytes)
19/01/24 17:58:36 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 17:58:36 INFO Executor: Running task 2.0 in stage 6.0 (TID 8)
19/01/24 17:58:36 INFO Executor: Running task 1.0 in stage 6.0 (TID 7)
19/01/24 17:58:36 INFO Executor: Finished task 1.0 in stage 6.0 (TID 7). 912 bytes result sent to driver
19/01/24 17:58:36 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 894 bytes result sent to driver
19/01/24 17:58:36 INFO Executor: Finished task 2.0 in stage 6.0 (TID 8). 912 bytes result sent to driver
19/01/24 17:58:36 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 7) in 7 ms on localhost (executor driver) (1/3)
19/01/24 17:58:36 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 7 ms on localhost (executor driver) (2/3)
19/01/24 17:58:36 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 8) in 6 ms on localhost (executor driver) (3/3)
19/01/24 17:58:36 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 17:58:36 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:44) finished in 0,007 s
19/01/24 17:58:36 INFO DAGScheduler: Job 4 finished: collect at utils.scala:44, took 0,014552 s
19/01/24 18:02:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:02:49 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:02:49 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:02:49 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:02:49 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:02:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:02:49 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:02:50 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 18:02:50 INFO DAGScheduler: Got job 5 (collect at utils.scala:44) with 3 output partitions
19/01/24 18:02:50 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:44)
19/01/24 18:02:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:02:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:02:50 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[33] at map at utils.scala:41), which has no missing parents
19/01/24 18:02:50 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.5 KB, free 364.4 MB)
19/01/24 18:02:50 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.6 KB, free 364.4 MB)
19/01/24 18:02:50 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:52886 (size: 3.6 KB, free: 364.4 MB)
19/01/24 18:02:50 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 18:02:50 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 7 (MapPartitionsRDD[33] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/01/24 18:02:50 INFO TaskSchedulerImpl: Adding task set 7.0 with 3 tasks
19/01/24 18:02:50 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/01/24 18:02:50 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
19/01/24 18:02:50 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 11, localhost, executor driver, partition 2, PROCESS_LOCAL, 5035 bytes)
19/01/24 18:02:50 INFO Executor: Running task 0.0 in stage 7.0 (TID 9)
19/01/24 18:02:50 INFO Executor: Running task 1.0 in stage 7.0 (TID 10)
19/01/24 18:02:50 INFO Executor: Running task 2.0 in stage 7.0 (TID 11)
19/01/24 18:02:50 INFO Executor: Finished task 0.0 in stage 7.0 (TID 9). 894 bytes result sent to driver
19/01/24 18:02:50 INFO Executor: Finished task 1.0 in stage 7.0 (TID 10). 912 bytes result sent to driver
19/01/24 18:02:50 INFO Executor: Finished task 2.0 in stage 7.0 (TID 11). 912 bytes result sent to driver
19/01/24 18:02:50 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 10) in 8 ms on localhost (executor driver) (1/3)
19/01/24 18:02:50 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 9) in 8 ms on localhost (executor driver) (2/3)
19/01/24 18:02:50 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 11) in 8 ms on localhost (executor driver) (3/3)
19/01/24 18:02:50 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/01/24 18:02:50 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:44) finished in 0,008 s
19/01/24 18:02:50 INFO DAGScheduler: Job 5 finished: collect at utils.scala:44, took 0,014481 s
19/01/24 18:02:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:02:59 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:02:59 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:02:59 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:02:59 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:02:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:02:59 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:02:59 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 18:02:59 INFO DAGScheduler: Got job 6 (collect at utils.scala:44) with 3 output partitions
19/01/24 18:02:59 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:44)
19/01/24 18:02:59 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:02:59 INFO DAGScheduler: Missing parents: List()
19/01/24 18:02:59 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[38] at map at utils.scala:41), which has no missing parents
19/01/24 18:02:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.5 KB, free 364.4 MB)
19/01/24 18:02:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.6 KB, free 364.4 MB)
19/01/24 18:02:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:52886 (size: 3.6 KB, free: 364.4 MB)
19/01/24 18:02:59 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/01/24 18:02:59 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 8 (MapPartitionsRDD[38] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/01/24 18:02:59 INFO TaskSchedulerImpl: Adding task set 8.0 with 3 tasks
19/01/24 18:02:59 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/01/24 18:02:59 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
19/01/24 18:02:59 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 5035 bytes)
19/01/24 18:02:59 INFO Executor: Running task 1.0 in stage 8.0 (TID 13)
19/01/24 18:02:59 INFO Executor: Running task 0.0 in stage 8.0 (TID 12)
19/01/24 18:02:59 INFO Executor: Running task 2.0 in stage 8.0 (TID 14)
19/01/24 18:02:59 INFO Executor: Finished task 1.0 in stage 8.0 (TID 13). 869 bytes result sent to driver
19/01/24 18:02:59 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 13) in 5 ms on localhost (executor driver) (1/3)
19/01/24 18:02:59 INFO Executor: Finished task 2.0 in stage 8.0 (TID 14). 869 bytes result sent to driver
19/01/24 18:02:59 INFO Executor: Finished task 0.0 in stage 8.0 (TID 12). 894 bytes result sent to driver
19/01/24 18:02:59 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 14) in 5 ms on localhost (executor driver) (2/3)
19/01/24 18:02:59 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 12) in 5 ms on localhost (executor driver) (3/3)
19/01/24 18:02:59 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 18:02:59 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:44) finished in 0,006 s
19/01/24 18:02:59 INFO DAGScheduler: Job 6 finished: collect at utils.scala:44, took 0,013739 s
19/01/24 18:02:59 INFO MapPartitionsRDD: Removing RDD 9 from persistence list
19/01/24 18:02:59 INFO BlockManager: Removing RDD 9
19/01/24 18:02:59 INFO SparkSqlParser: Parsing command: reviews
19/01/24 18:02:59 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 18:02:59 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 18:02:59 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 18:02:59 INFO DAGScheduler: Registering RDD 46 (sql at <unknown>:0)
19/01/24 18:02:59 INFO DAGScheduler: Got job 7 (sql at <unknown>:0) with 1 output partitions
19/01/24 18:02:59 INFO DAGScheduler: Final stage: ResultStage 10 (sql at <unknown>:0)
19/01/24 18:02:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
19/01/24 18:02:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
19/01/24 18:02:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[46] at sql at <unknown>:0), which has no missing parents
19/01/24 18:02:59 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.6 KB, free 366.2 MB)
19/01/24 18:02:59 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.2 MB)
19/01/24 18:02:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:52886 (size: 7.7 KB, free: 366.3 MB)
19/01/24 18:02:59 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 18:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[46] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:02:59 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 18:02:59 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:02:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:02:59 INFO Executor: Running task 0.0 in stage 9.0 (TID 15)
19/01/24 18:02:59 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:52886 in memory (size: 5.7 KB, free: 366.3 MB)
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 115
19/01/24 18:02:59 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:52886 in memory (size: 3.7 KB, free: 366.3 MB)
19/01/24 18:02:59 INFO ContextCleaner: Cleaned shuffle 1
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 248
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 275
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 120
19/01/24 18:02:59 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:52886 in memory (size: 3.6 KB, free: 366.3 MB)
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 223
19/01/24 18:02:59 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:52886 in memory (size: 3.6 KB, free: 366.3 MB)
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 122
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 119
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 114
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 116
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 124
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 118
19/01/24 18:02:59 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:52886 in memory (size: 3.6 KB, free: 366.3 MB)
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 117
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 113
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 121
19/01/24 18:02:59 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:52886 in memory (size: 7.7 KB, free: 366.3 MB)
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 123
19/01/24 18:02:59 INFO ContextCleaner: Cleaned accumulator 198
19/01/24 18:02:59 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 1885.3 KB, free 364.4 MB)
19/01/24 18:02:59 INFO BlockManagerInfo: Added rdd_43_0 in memory on 127.0.0.1:52886 (size: 1885.3 KB, free: 364.5 MB)
19/01/24 18:02:59 INFO Executor: Finished task 0.0 in stage 9.0 (TID 15). 2328 bytes result sent to driver
19/01/24 18:02:59 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 15) in 124 ms on localhost (executor driver) (1/1)
19/01/24 18:02:59 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 18:02:59 INFO DAGScheduler: ShuffleMapStage 9 (sql at <unknown>:0) finished in 0,125 s
19/01/24 18:02:59 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:02:59 INFO DAGScheduler: running: Set()
19/01/24 18:02:59 INFO DAGScheduler: waiting: Set(ResultStage 10)
19/01/24 18:02:59 INFO DAGScheduler: failed: Set()
19/01/24 18:02:59 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[49] at sql at <unknown>:0), which has no missing parents
19/01/24 18:02:59 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:02:59 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:02:59 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:52886 (size: 3.7 KB, free: 364.4 MB)
19/01/24 18:02:59 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/01/24 18:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[49] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:02:59 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 18:02:59 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 16, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:02:59 INFO Executor: Running task 0.0 in stage 10.0 (TID 16)
19/01/24 18:02:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:02:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:02:59 INFO Executor: Finished task 0.0 in stage 10.0 (TID 16). 1495 bytes result sent to driver
19/01/24 18:02:59 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 16) in 4 ms on localhost (executor driver) (1/1)
19/01/24 18:02:59 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 18:02:59 INFO DAGScheduler: ResultStage 10 (sql at <unknown>:0) finished in 0,005 s
19/01/24 18:02:59 INFO DAGScheduler: Job 7 finished: sql at <unknown>:0, took 0,145312 s
19/01/24 18:02:59 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 18:02:59 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:02:59 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:02:59 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:02:59 INFO DAGScheduler: Registering RDD 52 (collect at utils.scala:200)
19/01/24 18:02:59 INFO DAGScheduler: Got job 8 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:02:59 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:200)
19/01/24 18:02:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/01/24 18:02:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/01/24 18:02:59 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[52] at collect at utils.scala:200), which has no missing parents
19/01/24 18:02:59 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 15.6 KB, free 364.4 MB)
19/01/24 18:02:59 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.4 MB)
19/01/24 18:02:59 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:52886 (size: 7.7 KB, free: 364.4 MB)
19/01/24 18:02:59 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/01/24 18:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[52] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:02:59 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 18:03:00 WARN TaskSetManager: Stage 11 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:03:00 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:03:00 INFO Executor: Running task 0.0 in stage 11.0 (TID 17)
19/01/24 18:03:00 INFO BlockManager: Found block rdd_43_0 locally
19/01/24 18:03:00 INFO Executor: Finished task 0.0 in stage 11.0 (TID 17). 1690 bytes result sent to driver
19/01/24 18:03:00 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 17) in 45 ms on localhost (executor driver) (1/1)
19/01/24 18:03:00 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 18:03:00 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:200) finished in 0,045 s
19/01/24 18:03:00 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:03:00 INFO DAGScheduler: running: Set()
19/01/24 18:03:00 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/01/24 18:03:00 INFO DAGScheduler: failed: Set()
19/01/24 18:03:00 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:200), which has no missing parents
19/01/24 18:03:00 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:03:00 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:03:00 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:52886 (size: 3.7 KB, free: 364.4 MB)
19/01/24 18:03:00 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 18:03:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:03:00 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 18:03:00 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 18, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:03:00 INFO Executor: Running task 0.0 in stage 12.0 (TID 18)
19/01/24 18:03:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:03:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:03:00 INFO Executor: Finished task 0.0 in stage 12.0 (TID 18). 1452 bytes result sent to driver
19/01/24 18:03:00 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 18) in 3 ms on localhost (executor driver) (1/1)
19/01/24 18:03:00 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 18:03:00 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:200) finished in 0,004 s
19/01/24 18:03:00 INFO DAGScheduler: Job 8 finished: collect at utils.scala:200, took 0,063008 s
19/01/24 18:03:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz7`
WHERE (0 = 1)
19/01/24 18:03:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:03:00 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:03:00 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:03:00 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:03:00 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:03:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:03:00 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:03:00 INFO SparkSqlParser: Parsing command: SELECT * FROM reviews LIMIT 5
19/01/24 18:03:00 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:03:00 INFO DAGScheduler: Got job 9 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:03:00 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:200)
19/01/24 18:03:00 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:03:00 INFO DAGScheduler: Missing parents: List()
19/01/24 18:03:00 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[57] at collect at utils.scala:200), which has no missing parents
19/01/24 18:03:00 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 11.2 KB, free 364.4 MB)
19/01/24 18:03:00 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.8 KB, free 364.4 MB)
19/01/24 18:03:00 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:52886 (size: 5.8 KB, free: 364.4 MB)
19/01/24 18:03:00 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/01/24 18:03:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[57] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:03:00 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 18:03:00 WARN TaskSetManager: Stage 13 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:03:00 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:03:00 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
19/01/24 18:03:00 INFO BlockManager: Found block rdd_43_0 locally
19/01/24 18:03:00 INFO Executor: 1 block locks were not released by TID = 19:
[rdd_43_0]
19/01/24 18:03:00 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 1797 bytes result sent to driver
19/01/24 18:03:00 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:03:00 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 18:03:00 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:200) finished in 0,026 s
19/01/24 18:03:00 INFO DAGScheduler: Job 9 finished: collect at utils.scala:200, took 0,033389 s
19/01/24 18:03:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 18:03:05 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d848da6e3d
19/01/24 18:03:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d848da6e3d` AS `zzz8`
WHERE (0 = 1)
19/01/24 18:03:05 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d849c42501
19/01/24 18:03:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d849c42501` AS `zzz9`
WHERE (0 = 1)
19/01/24 18:03:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d848da6e3d`
19/01/24 18:04:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:04:42 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:04:42 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:04:42 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:04:42 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:04:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:04:42 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:04:42 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 18:04:42 INFO DAGScheduler: Got job 10 (collect at utils.scala:44) with 5 output partitions
19/01/24 18:04:42 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:44)
19/01/24 18:04:42 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:04:42 INFO DAGScheduler: Missing parents: List()
19/01/24 18:04:42 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[62] at map at utils.scala:41), which has no missing parents
19/01/24 18:04:42 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 6.8 KB, free 364.4 MB)
19/01/24 18:04:42 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.6 KB, free 364.4 MB)
19/01/24 18:04:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:52886 (size: 3.6 KB, free: 364.4 MB)
19/01/24 18:04:42 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:42 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 14 (MapPartitionsRDD[62] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
19/01/24 18:04:42 INFO TaskSchedulerImpl: Adding task set 14.0 with 5 tasks
19/01/24 18:04:42 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/01/24 18:04:42 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
19/01/24 18:04:42 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 22, localhost, executor driver, partition 2, PROCESS_LOCAL, 5035 bytes)
19/01/24 18:04:42 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 23, localhost, executor driver, partition 3, PROCESS_LOCAL, 5035 bytes)
19/01/24 18:04:42 INFO TaskSetManager: Starting task 4.0 in stage 14.0 (TID 24, localhost, executor driver, partition 4, PROCESS_LOCAL, 5035 bytes)
19/01/24 18:04:42 INFO Executor: Running task 0.0 in stage 14.0 (TID 20)
19/01/24 18:04:42 INFO Executor: Running task 2.0 in stage 14.0 (TID 22)
19/01/24 18:04:42 INFO Executor: Running task 1.0 in stage 14.0 (TID 21)
19/01/24 18:04:42 INFO Executor: Running task 3.0 in stage 14.0 (TID 23)
19/01/24 18:04:42 INFO Executor: Running task 4.0 in stage 14.0 (TID 24)
19/01/24 18:04:42 INFO Executor: Finished task 1.0 in stage 14.0 (TID 21). 912 bytes result sent to driver
19/01/24 18:04:42 INFO Executor: Finished task 3.0 in stage 14.0 (TID 23). 912 bytes result sent to driver
19/01/24 18:04:42 INFO Executor: Finished task 2.0 in stage 14.0 (TID 22). 912 bytes result sent to driver
19/01/24 18:04:42 INFO Executor: Finished task 4.0 in stage 14.0 (TID 24). 912 bytes result sent to driver
19/01/24 18:04:42 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 21) in 6 ms on localhost (executor driver) (1/5)
19/01/24 18:04:42 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 22) in 6 ms on localhost (executor driver) (2/5)
19/01/24 18:04:42 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 23) in 7 ms on localhost (executor driver) (3/5)
19/01/24 18:04:42 INFO TaskSetManager: Finished task 4.0 in stage 14.0 (TID 24) in 7 ms on localhost (executor driver) (4/5)
19/01/24 18:04:42 INFO Executor: Finished task 0.0 in stage 14.0 (TID 20). 894 bytes result sent to driver
19/01/24 18:04:42 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 20) in 8 ms on localhost (executor driver) (5/5)
19/01/24 18:04:42 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/01/24 18:04:42 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:44) finished in 0,009 s
19/01/24 18:04:42 INFO DAGScheduler: Job 10 finished: collect at utils.scala:44, took 0,013600 s
19/01/24 18:04:42 INFO MapPartitionsRDD: Removing RDD 43 from persistence list
19/01/24 18:04:42 INFO BlockManager: Removing RDD 43
19/01/24 18:04:43 INFO SparkSqlParser: Parsing command: reviews
19/01/24 18:04:43 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 18:04:43 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 18:04:43 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 18:04:43 INFO DAGScheduler: Registering RDD 70 (sql at <unknown>:0)
19/01/24 18:04:43 INFO DAGScheduler: Got job 11 (sql at <unknown>:0) with 1 output partitions
19/01/24 18:04:43 INFO DAGScheduler: Final stage: ResultStage 16 (sql at <unknown>:0)
19/01/24 18:04:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
19/01/24 18:04:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
19/01/24 18:04:43 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[70] at sql at <unknown>:0), which has no missing parents
19/01/24 18:04:43 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 15.5 KB, free 366.2 MB)
19/01/24 18:04:43 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.2 MB)
19/01/24 18:04:43 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:52886 (size: 7.7 KB, free: 366.3 MB)
19/01/24 18:04:43 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[70] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:43 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/01/24 18:04:43 WARN TaskSetManager: Stage 15 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:04:43 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:04:43 INFO Executor: Running task 0.0 in stage 15.0 (TID 25)
19/01/24 18:04:43 INFO CodeGenerator: Code generated in 5.541925 ms
19/01/24 18:04:43 INFO CodeGenerator: Code generated in 13.975336 ms
19/01/24 18:04:43 INFO MemoryStore: Block rdd_67_0 stored as values in memory (estimated size 1865.6 KB, free 364.4 MB)
19/01/24 18:04:43 INFO BlockManagerInfo: Added rdd_67_0 in memory on 127.0.0.1:52886 (size: 1865.6 KB, free: 364.4 MB)
19/01/24 18:04:43 INFO Executor: Finished task 0.0 in stage 15.0 (TID 25). 2285 bytes result sent to driver
19/01/24 18:04:43 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 25) in 123 ms on localhost (executor driver) (1/1)
19/01/24 18:04:43 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 18:04:43 INFO DAGScheduler: ShuffleMapStage 15 (sql at <unknown>:0) finished in 0,123 s
19/01/24 18:04:43 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:04:43 INFO DAGScheduler: running: Set()
19/01/24 18:04:43 INFO DAGScheduler: waiting: Set(ResultStage 16)
19/01/24 18:04:43 INFO DAGScheduler: failed: Set()
19/01/24 18:04:43 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[73] at sql at <unknown>:0), which has no missing parents
19/01/24 18:04:43 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:04:43 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:04:43 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:52886 (size: 3.7 KB, free: 364.4 MB)
19/01/24 18:04:43 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[73] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:43 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/01/24 18:04:43 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:04:43 INFO Executor: Running task 0.0 in stage 16.0 (TID 26)
19/01/24 18:04:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:04:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:04:43 INFO Executor: Finished task 0.0 in stage 16.0 (TID 26). 1452 bytes result sent to driver
19/01/24 18:04:43 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 26) in 3 ms on localhost (executor driver) (1/1)
19/01/24 18:04:43 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/01/24 18:04:43 INFO DAGScheduler: ResultStage 16 (sql at <unknown>:0) finished in 0,003 s
19/01/24 18:04:43 INFO DAGScheduler: Job 11 finished: sql at <unknown>:0, took 0,136317 s
19/01/24 18:04:43 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 18:04:43 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:04:43 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:04:43 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:04:43 INFO DAGScheduler: Registering RDD 76 (collect at utils.scala:200)
19/01/24 18:04:43 INFO DAGScheduler: Got job 12 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:04:43 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:200)
19/01/24 18:04:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/01/24 18:04:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/01/24 18:04:43 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[76] at collect at utils.scala:200), which has no missing parents
19/01/24 18:04:43 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 15.5 KB, free 364.3 MB)
19/01/24 18:04:43 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.3 MB)
19/01/24 18:04:43 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:52886 (size: 7.7 KB, free: 364.4 MB)
19/01/24 18:04:43 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[76] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:43 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/01/24 18:04:43 WARN TaskSetManager: Stage 17 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:04:43 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:04:43 INFO Executor: Running task 0.0 in stage 17.0 (TID 27)
19/01/24 18:04:43 INFO BlockManager: Found block rdd_67_0 locally
19/01/24 18:04:43 INFO Executor: Finished task 0.0 in stage 17.0 (TID 27). 1647 bytes result sent to driver
19/01/24 18:04:43 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 27) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:04:43 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 18:04:43 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:200) finished in 0,025 s
19/01/24 18:04:43 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:04:43 INFO DAGScheduler: running: Set()
19/01/24 18:04:43 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/01/24 18:04:43 INFO DAGScheduler: failed: Set()
19/01/24 18:04:43 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[79] at collect at utils.scala:200), which has no missing parents
19/01/24 18:04:43 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 7.0 KB, free 364.3 MB)
19/01/24 18:04:43 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.3 MB)
19/01/24 18:04:43 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:52886 (size: 3.7 KB, free: 364.4 MB)
19/01/24 18:04:43 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[79] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:43 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/01/24 18:04:43 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 28, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:04:43 INFO Executor: Running task 0.0 in stage 18.0 (TID 28)
19/01/24 18:04:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:04:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:04:43 INFO Executor: Finished task 0.0 in stage 18.0 (TID 28). 1452 bytes result sent to driver
19/01/24 18:04:43 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 28) in 3 ms on localhost (executor driver) (1/1)
19/01/24 18:04:43 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/01/24 18:04:43 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:200) finished in 0,003 s
19/01/24 18:04:43 INFO DAGScheduler: Job 12 finished: collect at utils.scala:200, took 0,036709 s
19/01/24 18:04:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz10`
WHERE (0 = 1)
19/01/24 18:04:43 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:04:43 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:04:43 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:04:43 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:04:43 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:04:43 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:04:43 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:04:43 INFO SparkSqlParser: Parsing command: SELECT * FROM reviews LIMIT 5
19/01/24 18:04:43 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:04:43 INFO DAGScheduler: Got job 13 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:04:43 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:200)
19/01/24 18:04:43 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:04:43 INFO DAGScheduler: Missing parents: List()
19/01/24 18:04:43 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[81] at collect at utils.scala:200), which has no missing parents
19/01/24 18:04:43 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 11.1 KB, free 364.3 MB)
19/01/24 18:04:43 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.8 KB, free 364.3 MB)
19/01/24 18:04:43 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:52886 (size: 5.8 KB, free: 364.4 MB)
19/01/24 18:04:43 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[81] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:43 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/01/24 18:04:43 WARN TaskSetManager: Stage 19 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:04:43 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:04:43 INFO Executor: Running task 0.0 in stage 19.0 (TID 29)
19/01/24 18:04:43 INFO BlockManager: Found block rdd_67_0 locally
19/01/24 18:04:43 INFO CodeGenerator: Code generated in 10.174357 ms
19/01/24 18:04:43 INFO Executor: 1 block locks were not released by TID = 29:
[rdd_67_0]
19/01/24 18:04:43 INFO Executor: Finished task 0.0 in stage 19.0 (TID 29). 1861 bytes result sent to driver
19/01/24 18:04:43 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 29) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:04:43 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/01/24 18:04:43 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:200) finished in 0,032 s
19/01/24 18:04:43 INFO DAGScheduler: Job 13 finished: collect at utils.scala:200, took 0,039420 s
19/01/24 18:04:43 INFO CodeGenerator: Code generated in 6.267623 ms
19/01/24 18:04:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 18:04:48 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d84e3c150b
19/01/24 18:04:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d84e3c150b` AS `zzz11`
WHERE (0 = 1)
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 571
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 348
19/01/24 18:04:48 INFO ContextCleaner: Cleaned shuffle 4
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 344
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 451
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 452
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:52886 in memory (size: 7.7 KB, free: 364.4 MB)
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:52886 in memory (size: 3.7 KB, free: 364.4 MB)
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 341
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:52886 in memory (size: 5.8 KB, free: 364.4 MB)
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 273
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 282
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 278
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 457
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 338
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 450
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 283
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 455
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 453
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 510
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 517
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 281
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 459
19/01/24 18:04:48 INFO ContextCleaner: Cleaned shuffle 5
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 515
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 279
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 513
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 336
19/01/24 18:04:48 INFO BlockManager: Removing RDD 43
19/01/24 18:04:48 INFO ContextCleaner: Cleaned RDD 43
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 460
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 346
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 522
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 274
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 454
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 397
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 287
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 347
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 461
19/01/24 18:04:48 INFO ContextCleaner: Cleaned shuffle 3
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:52886 in memory (size: 3.7 KB, free: 364.4 MB)
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 277
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 339
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:52886 in memory (size: 7.7 KB, free: 364.4 MB)
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:52886 in memory (size: 5.8 KB, free: 364.5 MB)
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 456
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 276
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 343
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 521
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 280
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:52886 in memory (size: 3.6 KB, free: 364.5 MB)
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 337
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 519
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 516
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:52886 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:52886 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 284
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 511
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 512
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 340
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 458
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 286
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 449
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 520
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 342
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 345
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 518
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:52886 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:04:48 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 422
19/01/24 18:04:48 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:52886 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 514
19/01/24 18:04:48 INFO ContextCleaner: Cleaned accumulator 285
19/01/24 18:04:48 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d86eb4e22
19/01/24 18:04:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d86eb4e22` AS `zzz12`
WHERE (0 = 1)
19/01/24 18:04:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d84e3c150b`
19/01/24 18:04:50 INFO CodeGenerator: Code generated in 27.435391 ms
19/01/24 18:04:50 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:04:50 INFO DAGScheduler: Registering RDD 87 (flatMap at CountVectorizer.scala:163)
19/01/24 18:04:50 INFO DAGScheduler: Got job 14 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:04:50 INFO DAGScheduler: Final stage: ResultStage 21 (count at CountVectorizer.scala:176)
19/01/24 18:04:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/01/24 18:04:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/01/24 18:04:50 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[87] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:04:50 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 28.5 KB, free 364.5 MB)
19/01/24 18:04:50 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 18:04:50 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:52886 (size: 13.0 KB, free: 364.5 MB)
19/01/24 18:04:50 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[87] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:50 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/01/24 18:04:50 WARN TaskSetManager: Stage 20 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:04:50 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:04:50 INFO Executor: Running task 0.0 in stage 20.0 (TID 30)
19/01/24 18:04:50 INFO BlockManager: Found block rdd_67_0 locally
19/01/24 18:04:50 INFO CodeGenerator: Code generated in 39.474317 ms
19/01/24 18:04:50 INFO CodeGenerator: Code generated in 6.968523 ms
19/01/24 18:04:50 INFO CodeGenerator: Code generated in 10.110175 ms
19/01/24 18:04:50 INFO Executor: Finished task 0.0 in stage 20.0 (TID 30). 1951 bytes result sent to driver
19/01/24 18:04:50 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 30) in 674 ms on localhost (executor driver) (1/1)
19/01/24 18:04:50 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/01/24 18:04:50 INFO DAGScheduler: ShuffleMapStage 20 (flatMap at CountVectorizer.scala:163) finished in 0,674 s
19/01/24 18:04:50 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:04:50 INFO DAGScheduler: running: Set()
19/01/24 18:04:50 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/01/24 18:04:50 INFO DAGScheduler: failed: Set()
19/01/24 18:04:50 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[90] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:04:50 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 18:04:50 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 18:04:50 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:52886 (size: 1887.0 B, free: 364.5 MB)
19/01/24 18:04:50 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[90] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:50 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/01/24 18:04:50 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 31, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:04:50 INFO Executor: Running task 0.0 in stage 21.0 (TID 31)
19/01/24 18:04:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:04:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:04:50 INFO MemoryStore: Block rdd_90_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 18:04:50 INFO BlockManagerInfo: Added rdd_90_0 in memory on 127.0.0.1:52886 (size: 686.3 KB, free: 363.8 MB)
19/01/24 18:04:50 INFO Executor: Finished task 0.0 in stage 21.0 (TID 31). 1873 bytes result sent to driver
19/01/24 18:04:50 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 31) in 77 ms on localhost (executor driver) (1/1)
19/01/24 18:04:50 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/01/24 18:04:50 INFO DAGScheduler: ResultStage 21 (count at CountVectorizer.scala:176) finished in 0,077 s
19/01/24 18:04:50 INFO DAGScheduler: Job 14 finished: count at CountVectorizer.scala:176, took 0,773914 s
19/01/24 18:04:50 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:04:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 143 bytes
19/01/24 18:04:50 INFO DAGScheduler: Got job 15 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:04:50 INFO DAGScheduler: Final stage: ResultStage 23 (top at CountVectorizer.scala:179)
19/01/24 18:04:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
19/01/24 18:04:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:04:50 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[91] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:04:50 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 4.2 KB, free 363.8 MB)
19/01/24 18:04:50 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.8 MB)
19/01/24 18:04:50 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:52886 (size: 2.2 KB, free: 363.8 MB)
19/01/24 18:04:50 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[91] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:50 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/01/24 18:04:50 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:04:50 INFO Executor: Running task 0.0 in stage 23.0 (TID 32)
19/01/24 18:04:50 INFO BlockManager: Found block rdd_90_0 locally
19/01/24 18:04:50 INFO Executor: Finished task 0.0 in stage 23.0 (TID 32). 174391 bytes result sent to driver
19/01/24 18:04:50 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 32) in 29 ms on localhost (executor driver) (1/1)
19/01/24 18:04:50 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/01/24 18:04:50 INFO DAGScheduler: ResultStage 23 (top at CountVectorizer.scala:179) finished in 0,031 s
19/01/24 18:04:50 INFO DAGScheduler: Job 15 finished: top at CountVectorizer.scala:179, took 0,041125 s
19/01/24 18:04:50 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 18:04:51 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.6 MB)
19/01/24 18:04:51 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:52886 (size: 89.8 KB, free: 363.7 MB)
19/01/24 18:04:51 INFO SparkContext: Created broadcast 23 from broadcast at CountVectorizer.scala:244
19/01/24 18:04:51 INFO CodeGenerator: Code generated in 25.046423 ms
19/01/24 18:04:51 INFO Instrumentation: NaiveBayes-naive_bayes_57d81f7341a3-1285625840-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 18:04:51 INFO Instrumentation: NaiveBayes-naive_bayes_57d81f7341a3-1285625840-1: {"smoothing":1.0,"featuresCol":"vectorizer_output","modelType":"multinomial","labelCol":"Sentiment","predictionCol":"prediction","rawPredictionCol":"rawPrediction","probabilityCol":"probability"}
19/01/24 18:04:51 INFO CodeGenerator: Code generated in 18.33864 ms
19/01/24 18:04:51 INFO SparkContext: Starting job: head at NaiveBayes.scala:154
19/01/24 18:04:51 INFO DAGScheduler: Got job 16 (head at NaiveBayes.scala:154) with 1 output partitions
19/01/24 18:04:51 INFO DAGScheduler: Final stage: ResultStage 24 (head at NaiveBayes.scala:154)
19/01/24 18:04:51 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:04:51 INFO DAGScheduler: Missing parents: List()
19/01/24 18:04:51 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[98] at head at NaiveBayes.scala:154), which has no missing parents
19/01/24 18:04:51 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 113.1 KB, free 362.4 MB)
19/01/24 18:04:51 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 73.0 KB, free 362.4 MB)
19/01/24 18:04:51 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:52886 (size: 73.0 KB, free: 363.6 MB)
19/01/24 18:04:51 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[98] at head at NaiveBayes.scala:154) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:51 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
19/01/24 18:04:51 WARN TaskSetManager: Stage 24 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:04:51 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:04:51 INFO Executor: Running task 0.0 in stage 24.0 (TID 33)
19/01/24 18:04:51 INFO BlockManager: Found block rdd_67_0 locally
19/01/24 18:04:51 INFO Executor: Finished task 0.0 in stage 24.0 (TID 33). 1743 bytes result sent to driver
19/01/24 18:04:51 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 33) in 51 ms on localhost (executor driver) (1/1)
19/01/24 18:04:51 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/01/24 18:04:51 INFO DAGScheduler: ResultStage 24 (head at NaiveBayes.scala:154) finished in 0,052 s
19/01/24 18:04:51 INFO DAGScheduler: Job 16 finished: head at NaiveBayes.scala:154, took 0,084053 s
19/01/24 18:04:51 INFO CodeGenerator: Code generated in 4.899008 ms
19/01/24 18:04:51 INFO Instrumentation: NaiveBayes-naive_bayes_57d81f7341a3-1285625840-1: {"numFeatures":8098}
19/01/24 18:04:51 INFO CodeGenerator: Code generated in 14.925307 ms
19/01/24 18:04:51 INFO SparkContext: Starting job: collect at NaiveBayes.scala:174
19/01/24 18:04:51 INFO DAGScheduler: Registering RDD 103 (map at NaiveBayes.scala:162)
19/01/24 18:04:51 INFO DAGScheduler: Got job 17 (collect at NaiveBayes.scala:174) with 1 output partitions
19/01/24 18:04:51 INFO DAGScheduler: Final stage: ResultStage 26 (collect at NaiveBayes.scala:174)
19/01/24 18:04:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
19/01/24 18:04:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
19/01/24 18:04:51 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[103] at map at NaiveBayes.scala:162), which has no missing parents
19/01/24 18:04:51 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 243.7 KB, free 362.1 MB)
19/01/24 18:04:51 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 76.1 KB, free 362.1 MB)
19/01/24 18:04:51 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:52886 (size: 76.1 KB, free: 363.6 MB)
19/01/24 18:04:51 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[103] at map at NaiveBayes.scala:162) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:51 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/01/24 18:04:51 WARN TaskSetManager: Stage 25 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:04:51 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:04:51 INFO Executor: Running task 0.0 in stage 25.0 (TID 34)
19/01/24 18:04:51 INFO BlockManager: Found block rdd_67_0 locally
19/01/24 18:04:51 INFO CodeGenerator: Code generated in 4.615657 ms
19/01/24 18:04:51 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:52886 in memory (size: 1887.0 B, free: 363.6 MB)
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 598
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 680
19/01/24 18:04:51 INFO BlockManager: Removing RDD 90
19/01/24 18:04:51 INFO ContextCleaner: Cleaned RDD 90
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 596
19/01/24 18:04:51 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:52886 in memory (size: 13.0 KB, free: 364.2 MB)
19/01/24 18:04:51 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:52886 in memory (size: 73.0 KB, free: 364.3 MB)
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 682
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 685
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 600
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 683
19/01/24 18:04:51 INFO ContextCleaner: Cleaned shuffle 6
19/01/24 18:04:51 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:52886 in memory (size: 2.2 KB, free: 364.3 MB)
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 599
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 601
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 681
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 597
19/01/24 18:04:51 INFO ContextCleaner: Cleaned accumulator 684
19/01/24 18:04:51 INFO Executor: Finished task 0.0 in stage 25.0 (TID 34). 1951 bytes result sent to driver
19/01/24 18:04:51 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 34) in 405 ms on localhost (executor driver) (1/1)
19/01/24 18:04:51 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/01/24 18:04:51 INFO DAGScheduler: ShuffleMapStage 25 (map at NaiveBayes.scala:162) finished in 0,405 s
19/01/24 18:04:51 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:04:51 INFO DAGScheduler: running: Set()
19/01/24 18:04:51 INFO DAGScheduler: waiting: Set(ResultStage 26)
19/01/24 18:04:51 INFO DAGScheduler: failed: Set()
19/01/24 18:04:51 INFO DAGScheduler: Submitting ResultStage 26 (ShuffledRDD[104] at aggregateByKey at NaiveBayes.scala:163), which has no missing parents
19/01/24 18:04:51 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 244.4 KB, free 362.7 MB)
19/01/24 18:04:51 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 76.4 KB, free 362.7 MB)
19/01/24 18:04:51 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:52886 (size: 76.4 KB, free: 364.2 MB)
19/01/24 18:04:51 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/01/24 18:04:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (ShuffledRDD[104] at aggregateByKey at NaiveBayes.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:04:51 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/01/24 18:04:51 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 35, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:04:51 INFO Executor: Running task 0.0 in stage 26.0 (TID 35)
19/01/24 18:04:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:04:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:04:51 INFO Executor: Finished task 0.0 in stage 26.0 (TID 35). 132363 bytes result sent to driver
19/01/24 18:04:51 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 35) in 13 ms on localhost (executor driver) (1/1)
19/01/24 18:04:51 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/01/24 18:04:51 INFO DAGScheduler: ResultStage 26 (collect at NaiveBayes.scala:174) finished in 0,013 s
19/01/24 18:04:51 INFO DAGScheduler: Job 17 finished: collect at NaiveBayes.scala:174, took 0,436539 s
19/01/24 18:04:51 INFO Instrumentation: NaiveBayes-naive_bayes_57d81f7341a3-1285625840-1: {"numClasses":2}
19/01/24 18:04:51 INFO Instrumentation: NaiveBayes-naive_bayes_57d81f7341a3-1285625840-1: training finished
19/01/24 18:05:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d86eb4e22`
19/01/24 18:05:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d864a83e04
19/01/24 18:05:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d864a83e04` AS `zzz13`
WHERE (0 = 1)
19/01/24 18:06:33 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d864a83e04`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:06:33 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:06:33 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:06:33 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d864a83e04`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:06:33 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:06:33 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:06:33 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d864a83e04`
GROUP BY `Sentiment`, `Prediction`
LIMIT 11
19/01/24 18:06:33 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:06:33 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:06:33 INFO CodeGenerator: Code generated in 15.270652 ms
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 714
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 713
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 679
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 712
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 711
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 674
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 677
19/01/24 18:06:33 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:52886 in memory (size: 76.1 KB, free: 364.3 MB)
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 710
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 715
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 678
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 676
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 764
19/01/24 18:06:33 INFO ContextCleaner: Cleaned shuffle 7
19/01/24 18:06:33 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:52886 in memory (size: 76.4 KB, free: 364.4 MB)
19/01/24 18:06:33 INFO ContextCleaner: Cleaned accumulator 675
19/01/24 18:06:33 INFO CodeGenerator: Code generated in 60.020684 ms
19/01/24 18:06:33 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:06:33 INFO DAGScheduler: Registering RDD 107 (collect at utils.scala:200)
19/01/24 18:06:33 INFO DAGScheduler: Got job 18 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:06:33 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:200)
19/01/24 18:06:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
19/01/24 18:06:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
19/01/24 18:06:33 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[107] at collect at utils.scala:200), which has no missing parents
19/01/24 18:06:33 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 254.9 KB, free 363.0 MB)
19/01/24 18:06:33 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 115.8 KB, free 362.9 MB)
19/01/24 18:06:33 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:52886 (size: 115.8 KB, free: 364.3 MB)
19/01/24 18:06:33 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/01/24 18:06:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[107] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:06:33 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/01/24 18:06:33 WARN TaskSetManager: Stage 27 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:06:33 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:06:33 INFO Executor: Running task 0.0 in stage 27.0 (TID 36)
19/01/24 18:06:33 INFO BlockManager: Found block rdd_67_0 locally
19/01/24 18:06:33 INFO CodeGenerator: Code generated in 3.714917 ms
19/01/24 18:06:33 INFO CodeGenerator: Code generated in 3.546438 ms
19/01/24 18:06:33 INFO CodeGenerator: Code generated in 3.835623 ms
19/01/24 18:06:33 INFO CodeGenerator: Code generated in 9.680226 ms
19/01/24 18:06:33 INFO CodeGenerator: Code generated in 4.980695 ms
19/01/24 18:06:33 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/01/24 18:06:33 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/01/24 18:06:33 INFO Executor: Finished task 0.0 in stage 27.0 (TID 36). 2263 bytes result sent to driver
19/01/24 18:06:33 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 36) in 346 ms on localhost (executor driver) (1/1)
19/01/24 18:06:33 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/01/24 18:06:33 INFO DAGScheduler: ShuffleMapStage 27 (collect at utils.scala:200) finished in 0,346 s
19/01/24 18:06:33 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:06:33 INFO DAGScheduler: running: Set()
19/01/24 18:06:33 INFO DAGScheduler: waiting: Set(ResultStage 28)
19/01/24 18:06:33 INFO DAGScheduler: failed: Set()
19/01/24 18:06:33 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[110] at collect at utils.scala:200), which has no missing parents
19/01/24 18:06:33 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 236.2 KB, free 362.7 MB)
19/01/24 18:06:33 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 108.9 KB, free 362.6 MB)
19/01/24 18:06:33 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:52886 (size: 108.9 KB, free: 364.2 MB)
19/01/24 18:06:33 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/01/24 18:06:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[110] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:06:33 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/01/24 18:06:33 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 37, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:06:33 INFO Executor: Running task 0.0 in stage 28.0 (TID 37)
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:06:33 INFO Executor: Finished task 0.0 in stage 28.0 (TID 37). 2584 bytes result sent to driver
19/01/24 18:06:33 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 37) in 11 ms on localhost (executor driver) (1/1)
19/01/24 18:06:33 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/01/24 18:06:33 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:200) finished in 0,011 s
19/01/24 18:06:33 INFO DAGScheduler: Job 18 finished: collect at utils.scala:200, took 0,372181 s
19/01/24 18:06:33 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:06:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 149 bytes
19/01/24 18:06:33 INFO DAGScheduler: Got job 19 (collect at utils.scala:200) with 4 output partitions
19/01/24 18:06:33 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:200)
19/01/24 18:06:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
19/01/24 18:06:33 INFO DAGScheduler: Missing parents: List()
19/01/24 18:06:33 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[110] at collect at utils.scala:200), which has no missing parents
19/01/24 18:06:33 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 236.2 KB, free 362.3 MB)
19/01/24 18:06:33 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 108.9 KB, free 362.2 MB)
19/01/24 18:06:33 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:52886 (size: 108.9 KB, free: 364.1 MB)
19/01/24 18:06:33 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/01/24 18:06:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[110] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
19/01/24 18:06:33 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/01/24 18:06:33 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 38, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:06:33 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 39, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:06:33 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 40, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:06:33 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 41, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:06:33 INFO Executor: Running task 0.0 in stage 30.0 (TID 38)
19/01/24 18:06:33 INFO Executor: Running task 1.0 in stage 30.0 (TID 39)
19/01/24 18:06:33 INFO Executor: Running task 2.0 in stage 30.0 (TID 40)
19/01/24 18:06:33 INFO Executor: Running task 3.0 in stage 30.0 (TID 41)
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:06:33 INFO Executor: Finished task 1.0 in stage 30.0 (TID 39). 2558 bytes result sent to driver
19/01/24 18:06:33 INFO Executor: Finished task 2.0 in stage 30.0 (TID 40). 2558 bytes result sent to driver
19/01/24 18:06:33 INFO Executor: Finished task 3.0 in stage 30.0 (TID 41). 2558 bytes result sent to driver
19/01/24 18:06:33 INFO Executor: Finished task 0.0 in stage 30.0 (TID 38). 2558 bytes result sent to driver
19/01/24 18:06:33 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 40) in 15 ms on localhost (executor driver) (1/4)
19/01/24 18:06:33 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 41) in 15 ms on localhost (executor driver) (2/4)
19/01/24 18:06:33 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 39) in 15 ms on localhost (executor driver) (3/4)
19/01/24 18:06:33 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 38) in 16 ms on localhost (executor driver) (4/4)
19/01/24 18:06:33 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/01/24 18:06:33 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:200) finished in 0,017 s
19/01/24 18:06:33 INFO DAGScheduler: Job 19 finished: collect at utils.scala:200, took 0,025322 s
19/01/24 18:06:33 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:06:33 INFO DAGScheduler: Got job 20 (collect at utils.scala:200) with 3 output partitions
19/01/24 18:06:33 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:200)
19/01/24 18:06:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
19/01/24 18:06:33 INFO DAGScheduler: Missing parents: List()
19/01/24 18:06:33 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[110] at collect at utils.scala:200), which has no missing parents
19/01/24 18:06:33 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 236.2 KB, free 362.0 MB)
19/01/24 18:06:33 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 108.9 KB, free 361.9 MB)
19/01/24 18:06:33 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:52886 (size: 108.9 KB, free: 364.0 MB)
19/01/24 18:06:33 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/01/24 18:06:33 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 32 (MapPartitionsRDD[110] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(5, 6, 7))
19/01/24 18:06:33 INFO TaskSchedulerImpl: Adding task set 32.0 with 3 tasks
19/01/24 18:06:33 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 42, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:06:33 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 43, localhost, executor driver, partition 5, ANY, 4726 bytes)
19/01/24 18:06:33 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 44, localhost, executor driver, partition 7, ANY, 4726 bytes)
19/01/24 18:06:33 INFO Executor: Running task 0.0 in stage 32.0 (TID 43)
19/01/24 18:06:33 INFO Executor: Running task 1.0 in stage 32.0 (TID 42)
19/01/24 18:06:33 INFO Executor: Running task 2.0 in stage 32.0 (TID 44)
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:06:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:06:33 INFO Executor: Finished task 0.0 in stage 32.0 (TID 43). 2591 bytes result sent to driver
19/01/24 18:06:33 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 43) in 8 ms on localhost (executor driver) (1/3)
19/01/24 18:06:33 INFO Executor: Finished task 1.0 in stage 32.0 (TID 42). 2558 bytes result sent to driver
19/01/24 18:06:33 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 42) in 11 ms on localhost (executor driver) (2/3)
19/01/24 18:06:33 INFO Executor: Finished task 2.0 in stage 32.0 (TID 44). 2578 bytes result sent to driver
19/01/24 18:06:33 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 44) in 11 ms on localhost (executor driver) (3/3)
19/01/24 18:06:33 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/01/24 18:06:33 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:200) finished in 0,011 s
19/01/24 18:06:33 INFO DAGScheduler: Job 20 finished: collect at utils.scala:200, took 0,019011 s
19/01/24 18:06:33 INFO CodeGenerator: Code generated in 5.659349 ms
19/01/24 18:06:33 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d864a83e04`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:06:33 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:06:33 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:09:15 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 18:09:15 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 18:09:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 18:09:15 INFO MemoryStore: MemoryStore cleared
19/01/24 18:09:15 INFO BlockManager: BlockManager stopped
19/01/24 18:09:15 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 18:09:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 18:09:15 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-21682cda-6b8f-4305-bb9f-9b16a8addc8a\userFiles-72592bee-bfc7-463b-8a23-e3d6f0a14dc8
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-21682cda-6b8f-4305-bb9f-9b16a8addc8a\userFiles-72592bee-bfc7-463b-8a23-e3d6f0a14dc8
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:09:15 INFO SparkContext: Successfully stopped SparkContext
19/01/24 18:09:15 INFO ShutdownHookManager: Shutdown hook called
19/01/24 18:09:15 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-21682cda-6b8f-4305-bb9f-9b16a8addc8a\userFiles-72592bee-bfc7-463b-8a23-e3d6f0a14dc8
19/01/24 18:09:15 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-21682cda-6b8f-4305-bb9f-9b16a8addc8a\userFiles-72592bee-bfc7-463b-8a23-e3d6f0a14dc8
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-21682cda-6b8f-4305-bb9f-9b16a8addc8a\userFiles-72592bee-bfc7-463b-8a23-e3d6f0a14dc8
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:09:15 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-21682cda-6b8f-4305-bb9f-9b16a8addc8a
19/01/24 18:09:15 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-21682cda-6b8f-4305-bb9f-9b16a8addc8a
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-21682cda-6b8f-4305-bb9f-9b16a8addc8a
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:09:30 INFO SparkContext: Running Spark version 2.2.0
19/01/24 18:09:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 18:09:31 INFO SparkContext: Submitted application: sparklyr
19/01/24 18:09:31 INFO SecurityManager: Changing view acls to: yanis
19/01/24 18:09:31 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 18:09:31 INFO SecurityManager: Changing view acls groups to: 
19/01/24 18:09:31 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 18:09:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 18:09:31 INFO Utils: Successfully started service 'sparkDriver' on port 53062.
19/01/24 18:09:31 INFO SparkEnv: Registering MapOutputTracker
19/01/24 18:09:31 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 18:09:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 18:09:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 18:09:31 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-13a04493-d37e-4c94-beee-041bd584e936
19/01/24 18:09:31 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 18:09:31 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 18:09:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 18:09:31 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 18:09:31 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:53062/jars/sparklyr-2.2-2.11.jar with timestamp 1548349771537
19/01/24 18:09:31 INFO Executor: Starting executor ID driver on host localhost
19/01/24 18:09:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53103.
19/01/24 18:09:31 INFO NettyBlockTransferService: Server created on 127.0.0.1:53103
19/01/24 18:09:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 18:09:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53103, None)
19/01/24 18:09:31 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53103 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53103, None)
19/01/24 18:09:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53103, None)
19/01/24 18:09:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53103, None)
19/01/24 18:09:31 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 18:09:31 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 18:09:31 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 18:09:31 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 18:09:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 18:09:32 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 18:09:32 INFO ObjectStore: ObjectStore, initialize called
19/01/24 18:09:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 18:09:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 18:09:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 18:09:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:09:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:09:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:09:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:09:35 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 18:09:35 INFO ObjectStore: Initialized ObjectStore
19/01/24 18:09:35 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 18:09:35 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 18:09:35 INFO HiveMetaStore: Added admin role in metastore
19/01/24 18:09:35 INFO HiveMetaStore: Added public role in metastore
19/01/24 18:09:35 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 18:09:35 INFO HiveMetaStore: 0: get_all_databases
19/01/24 18:09:35 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 18:09:35 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 18:09:35 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 18:09:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:09:36 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/1868c9a2-050f-49ff-a608-d06b84a59075_resources
19/01/24 18:09:36 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/1868c9a2-050f-49ff-a608-d06b84a59075
19/01/24 18:09:36 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/1868c9a2-050f-49ff-a608-d06b84a59075
19/01/24 18:09:36 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/1868c9a2-050f-49ff-a608-d06b84a59075/_tmp_space.db
19/01/24 18:09:36 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:09:36 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:09:36 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:09:36 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 18:09:36 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 18:09:36 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 18:09:36 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/24c7d83f-ad76-41f0-a6d1-ed5b23a4a934_resources
19/01/24 18:09:36 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/24c7d83f-ad76-41f0-a6d1-ed5b23a4a934
19/01/24 18:09:36 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/24c7d83f-ad76-41f0-a6d1-ed5b23a4a934
19/01/24 18:09:36 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/24c7d83f-ad76-41f0-a6d1-ed5b23a4a934/_tmp_space.db
19/01/24 18:09:36 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:09:36 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 18:09:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:09:37 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:09:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:09:37 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:09:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:09:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:09:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:09:38 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 18:09:38 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 18:09:38 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 18:09:38 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:09:38 INFO DAGScheduler: Missing parents: List()
19/01/24 18:09:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 18:09:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 18:09:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 18:09:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53103 (size: 3.4 KB, free: 366.3 MB)
19/01/24 18:09:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 18:09:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 18:09:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 18:09:38 INFO Executor: Fetching spark://127.0.0.1:53062/jars/sparklyr-2.2-2.11.jar with timestamp 1548349771537
19/01/24 18:09:38 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53062 after 16 ms (0 ms spent in bootstraps)
19/01/24 18:09:38 INFO Utils: Fetching spark://127.0.0.1:53062/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-30dec006-617b-433d-b9e9-1a71574b0476\userFiles-8e205c6c-dbd0-4558-b005-d58c7b2cb9bc\fetchFileTemp3133422446807038182.tmp
19/01/24 18:09:38 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-30dec006-617b-433d-b9e9-1a71574b0476/userFiles-8e205c6c-dbd0-4558-b005-d58c7b2cb9bc/sparklyr-2.2-2.11.jar to class loader
19/01/24 18:09:39 INFO CodeGenerator: Code generated in 153.985065 ms
19/01/24 18:09:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/01/24 18:09:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 483 ms on localhost (executor driver) (1/1)
19/01/24 18:09:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 18:09:39 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,499 s
19/01/24 18:09:39 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,673748 s
19/01/24 18:09:39 INFO SparkSqlParser: Parsing command: reviews
19/01/24 18:09:39 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 18:09:39 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 18:09:39 INFO CodeGenerator: Code generated in 15.592658 ms
19/01/24 18:09:39 INFO CodeGenerator: Code generated in 10.282301 ms
19/01/24 18:09:39 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 18:09:39 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 18:09:39 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 18:09:39 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 18:09:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 18:09:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 18:09:39 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 18:09:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 18:09:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 18:09:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53103 (size: 7.7 KB, free: 366.3 MB)
19/01/24 18:09:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 18:09:39 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:09:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:09:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 18:09:39 INFO CodeGenerator: Code generated in 7.064796 ms
19/01/24 18:09:39 INFO CodeGenerator: Code generated in 20.395757 ms
19/01/24 18:09:40 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.4 MB)
19/01/24 18:09:40 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:53103 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 18:09:40 INFO CodeGenerator: Code generated in 4.913595 ms
19/01/24 18:09:40 INFO CodeGenerator: Code generated in 15.229809 ms
19/01/24 18:09:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 18:09:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 362 ms on localhost (executor driver) (1/1)
19/01/24 18:09:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 18:09:40 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,363 s
19/01/24 18:09:40 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:09:40 INFO DAGScheduler: running: Set()
19/01/24 18:09:40 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 18:09:40 INFO DAGScheduler: failed: Set()
19/01/24 18:09:40 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 18:09:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:09:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:09:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53103 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:09:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 18:09:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:09:40 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 18:09:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:09:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/01/24 18:09:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1538 bytes result sent to driver
19/01/24 18:09:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (executor driver) (1/1)
19/01/24 18:09:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 18:09:40 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,029 s
19/01/24 18:09:40 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,432166 s
19/01/24 18:09:40 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 18:09:40 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:09:40 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:09:40 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53103 in memory (size: 3.4 KB, free: 364.5 MB)
19/01/24 18:09:40 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53103 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 18:09:40 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 18:09:40 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53103 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 18:09:40 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 18:09:40 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:09:40 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 18:09:40 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:09:40 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 18:09:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 18:09:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 18:09:40 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 18:09:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 18:09:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.5 MB)
19/01/24 18:09:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53103 (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:09:40 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 18:09:40 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:09:40 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:09:40 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 18:09:40 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:09:40 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1647 bytes result sent to driver
19/01/24 18:09:40 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 39 ms on localhost (executor driver) (1/1)
19/01/24 18:09:40 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 18:09:40 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,040 s
19/01/24 18:09:40 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:09:40 INFO DAGScheduler: running: Set()
19/01/24 18:09:40 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 18:09:40 INFO DAGScheduler: failed: Set()
19/01/24 18:09:40 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 18:09:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:09:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:09:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53103 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:09:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:40 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 18:09:40 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:09:40 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 18:09:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:09:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:09:40 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/01/24 18:09:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
19/01/24 18:09:40 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 18:09:40 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,005 s
19/01/24 18:09:40 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,062070 s
19/01/24 18:09:40 INFO CodeGenerator: Code generated in 7.232181 ms
19/01/24 18:09:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz14`
WHERE (0 = 1)
19/01/24 18:09:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 18:09:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d82bdb1ecc
19/01/24 18:09:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82bdb1ecc` AS `zzz15`
WHERE (0 = 1)
19/01/24 18:09:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d847dd4e17
19/01/24 18:09:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d847dd4e17` AS `zzz16`
WHERE (0 = 1)
19/01/24 18:09:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d82bdb1ecc`
19/01/24 18:09:43 INFO CodeGenerator: Code generated in 31.09743 ms
19/01/24 18:09:43 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:09:43 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 18:09:43 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:09:43 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 18:09:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 18:09:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 18:09:43 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:09:43 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 18:09:43 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 18:09:43 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53103 (size: 13.0 KB, free: 364.5 MB)
19/01/24 18:09:43 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:43 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 18:09:43 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:09:43 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:09:43 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 18:09:43 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:09:43 INFO CodeGenerator: Code generated in 14.122299 ms
19/01/24 18:09:43 INFO CodeGenerator: Code generated in 10.702403 ms
19/01/24 18:09:43 INFO CodeGenerator: Code generated in 7.621286 ms
19/01/24 18:09:43 INFO CodeGenerator: Code generated in 10.325696 ms
19/01/24 18:09:43 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53103 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 117
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 118
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 122
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 115
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 121
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 116
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 120
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 18:09:43 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53103 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 119
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 114
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 113
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 123
19/01/24 18:09:43 INFO ContextCleaner: Cleaned shuffle 1
19/01/24 18:09:43 INFO ContextCleaner: Cleaned accumulator 124
19/01/24 18:09:43 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1951 bytes result sent to driver
19/01/24 18:09:43 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 667 ms on localhost (executor driver) (1/1)
19/01/24 18:09:43 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 18:09:43 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 0,667 s
19/01/24 18:09:43 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:09:43 INFO DAGScheduler: running: Set()
19/01/24 18:09:43 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 18:09:43 INFO DAGScheduler: failed: Set()
19/01/24 18:09:43 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:09:43 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 18:09:43 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 18:09:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53103 (size: 1887.0 B, free: 364.5 MB)
19/01/24 18:09:43 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:43 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 18:09:44 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:09:44 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 18:09:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:09:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:09:44 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 18:09:44 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:53103 (size: 686.3 KB, free: 363.8 MB)
19/01/24 18:09:44 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1830 bytes result sent to driver
19/01/24 18:09:44 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 112 ms on localhost (executor driver) (1/1)
19/01/24 18:09:44 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 18:09:44 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,112 s
19/01/24 18:09:44 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 0,807658 s
19/01/24 18:09:44 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:09:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 18:09:44 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:09:44 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 18:09:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 18:09:44 INFO DAGScheduler: Missing parents: List()
19/01/24 18:09:44 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:09:44 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.8 MB)
19/01/24 18:09:44 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.8 MB)
19/01/24 18:09:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53103 (size: 2.2 KB, free: 363.8 MB)
19/01/24 18:09:44 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:44 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 18:09:44 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:09:44 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 18:09:44 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 18:09:44 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 18:09:44 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 42 ms on localhost (executor driver) (1/1)
19/01/24 18:09:44 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 18:09:44 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,042 s
19/01/24 18:09:44 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,056085 s
19/01/24 18:09:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 18:09:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.6 MB)
19/01/24 18:09:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53103 (size: 89.8 KB, free: 363.7 MB)
19/01/24 18:09:44 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 18:09:44 INFO CodeGenerator: Code generated in 24.059985 ms
19/01/24 18:09:44 INFO Instrumentation: NaiveBayes-naive_bayes_57d83e263503-355433567-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 18:09:44 INFO Instrumentation: NaiveBayes-naive_bayes_57d83e263503-355433567-1: {"smoothing":1.0,"featuresCol":"vectorizer_output","modelType":"multinomial","labelCol":"Sentiment","predictionCol":"prediction","rawPredictionCol":"rawPrediction","probabilityCol":"probability"}
19/01/24 18:09:44 INFO CodeGenerator: Code generated in 17.470356 ms
19/01/24 18:09:44 INFO SparkContext: Starting job: head at NaiveBayes.scala:154
19/01/24 18:09:44 INFO DAGScheduler: Got job 5 (head at NaiveBayes.scala:154) with 1 output partitions
19/01/24 18:09:44 INFO DAGScheduler: Final stage: ResultStage 9 (head at NaiveBayes.scala:154)
19/01/24 18:09:44 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:09:44 INFO DAGScheduler: Missing parents: List()
19/01/24 18:09:44 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154), which has no missing parents
19/01/24 18:09:44 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 113.1 KB, free 362.4 MB)
19/01/24 18:09:44 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 72.9 KB, free 362.4 MB)
19/01/24 18:09:44 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53103 (size: 72.9 KB, free: 363.6 MB)
19/01/24 18:09:44 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:44 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 18:09:44 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:09:44 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:09:44 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 18:09:44 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:09:44 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 1743 bytes result sent to driver
19/01/24 18:09:44 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 71 ms on localhost (executor driver) (1/1)
19/01/24 18:09:44 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 18:09:44 INFO DAGScheduler: ResultStage 9 (head at NaiveBayes.scala:154) finished in 0,072 s
19/01/24 18:09:44 INFO DAGScheduler: Job 5 finished: head at NaiveBayes.scala:154, took 0,081210 s
19/01/24 18:09:44 INFO CodeGenerator: Code generated in 6.934973 ms
19/01/24 18:09:44 INFO Instrumentation: NaiveBayes-naive_bayes_57d83e263503-355433567-1: {"numFeatures":8098}
19/01/24 18:09:44 INFO CodeGenerator: Code generated in 26.165238 ms
19/01/24 18:09:44 INFO BlockManager: Removing RDD 30
19/01/24 18:09:44 INFO ContextCleaner: Cleaned RDD 30
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 176
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 262
19/01/24 18:09:44 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53103 in memory (size: 1887.0 B, free: 364.3 MB)
19/01/24 18:09:44 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 259
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 260
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 175
19/01/24 18:09:44 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53103 in memory (size: 13.0 KB, free: 364.3 MB)
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 178
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 258
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 177
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 174
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 257
19/01/24 18:09:44 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53103 in memory (size: 2.2 KB, free: 364.3 MB)
19/01/24 18:09:44 INFO ContextCleaner: Cleaned accumulator 261
19/01/24 18:09:44 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53103 in memory (size: 72.9 KB, free: 364.4 MB)
19/01/24 18:09:44 INFO SparkContext: Starting job: collect at NaiveBayes.scala:174
19/01/24 18:09:44 INFO DAGScheduler: Registering RDD 43 (map at NaiveBayes.scala:162)
19/01/24 18:09:44 INFO DAGScheduler: Got job 6 (collect at NaiveBayes.scala:174) with 1 output partitions
19/01/24 18:09:44 INFO DAGScheduler: Final stage: ResultStage 11 (collect at NaiveBayes.scala:174)
19/01/24 18:09:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/01/24 18:09:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/01/24 18:09:44 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162), which has no missing parents
19/01/24 18:09:44 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 243.7 KB, free 363.0 MB)
19/01/24 18:09:44 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 76.0 KB, free 363.0 MB)
19/01/24 18:09:44 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53103 (size: 76.0 KB, free: 364.3 MB)
19/01/24 18:09:44 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:44 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 18:09:44 WARN TaskSetManager: Stage 10 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:09:44 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:09:44 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 18:09:44 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:09:44 INFO CodeGenerator: Code generated in 7.637332 ms
19/01/24 18:09:45 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1951 bytes result sent to driver
19/01/24 18:09:45 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 466 ms on localhost (executor driver) (1/1)
19/01/24 18:09:45 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 18:09:45 INFO DAGScheduler: ShuffleMapStage 10 (map at NaiveBayes.scala:162) finished in 0,466 s
19/01/24 18:09:45 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:09:45 INFO DAGScheduler: running: Set()
19/01/24 18:09:45 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/01/24 18:09:45 INFO DAGScheduler: failed: Set()
19/01/24 18:09:45 INFO DAGScheduler: Submitting ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163), which has no missing parents
19/01/24 18:09:45 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 244.4 KB, free 362.7 MB)
19/01/24 18:09:45 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 76.4 KB, free 362.7 MB)
19/01/24 18:09:45 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53103 (size: 76.4 KB, free: 364.2 MB)
19/01/24 18:09:45 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/01/24 18:09:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:09:45 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 18:09:45 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:09:45 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 18:09:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:09:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:09:45 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 132406 bytes result sent to driver
19/01/24 18:09:45 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 11 ms on localhost (executor driver) (1/1)
19/01/24 18:09:45 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 18:09:45 INFO DAGScheduler: ResultStage 11 (collect at NaiveBayes.scala:174) finished in 0,012 s
19/01/24 18:09:45 INFO DAGScheduler: Job 6 finished: collect at NaiveBayes.scala:174, took 0,502347 s
19/01/24 18:09:45 INFO Instrumentation: NaiveBayes-naive_bayes_57d83e263503-355433567-1: {"numClasses":2}
19/01/24 18:09:45 INFO Instrumentation: NaiveBayes-naive_bayes_57d83e263503-355433567-1: training finished
19/01/24 18:10:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d847dd4e17`
19/01/24 18:10:08 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d83a21430e
19/01/24 18:10:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83a21430e` AS `zzz17`
WHERE (0 = 1)
19/01/24 18:10:08 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d83a21430e`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:10:08 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:10:08 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:10:08 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d83a21430e`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:10:08 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:10:08 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:10:08 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d83a21430e`
GROUP BY `Sentiment`, `Prediction`
LIMIT 11
19/01/24 18:10:08 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:10:08 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:10:08 INFO CodeGenerator: Code generated in 20.362207 ms
19/01/24 18:10:08 INFO CodeGenerator: Code generated in 43.52291 ms
19/01/24 18:10:08 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:10:08 INFO DAGScheduler: Registering RDD 47 (collect at utils.scala:200)
19/01/24 18:10:08 INFO DAGScheduler: Got job 7 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:10:08 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:200)
19/01/24 18:10:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/01/24 18:10:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/01/24 18:10:08 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[47] at collect at utils.scala:200), which has no missing parents
19/01/24 18:10:08 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 254.9 KB, free 362.4 MB)
19/01/24 18:10:08 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 115.8 KB, free 362.3 MB)
19/01/24 18:10:08 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53103 (size: 115.8 KB, free: 364.1 MB)
19/01/24 18:10:08 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 18:10:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[47] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:10:08 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 18:10:08 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:10:08 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:10:08 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 18:10:08 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:10:08 INFO CodeGenerator: Code generated in 5.028831 ms
19/01/24 18:10:08 INFO CodeGenerator: Code generated in 4.80237 ms
19/01/24 18:10:08 INFO CodeGenerator: Code generated in 5.811418 ms
19/01/24 18:10:08 INFO CodeGenerator: Code generated in 8.094266 ms
19/01/24 18:10:08 INFO CodeGenerator: Code generated in 4.275783 ms
19/01/24 18:10:09 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/01/24 18:10:09 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/01/24 18:10:09 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 2263 bytes result sent to driver
19/01/24 18:10:09 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 330 ms on localhost (executor driver) (1/1)
19/01/24 18:10:09 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 18:10:09 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:200) finished in 0,331 s
19/01/24 18:10:09 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:10:09 INFO DAGScheduler: running: Set()
19/01/24 18:10:09 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/01/24 18:10:09 INFO DAGScheduler: failed: Set()
19/01/24 18:10:09 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 18:10:09 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 236.1 KB, free 362.1 MB)
19/01/24 18:10:09 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 108.9 KB, free 362.0 MB)
19/01/24 18:10:09 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53103 (size: 108.9 KB, free: 364.0 MB)
19/01/24 18:10:09 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/01/24 18:10:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:10:09 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 18:10:09 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:10:09 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:10:09 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 2541 bytes result sent to driver
19/01/24 18:10:09 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 10 ms on localhost (executor driver) (1/1)
19/01/24 18:10:09 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 18:10:09 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:200) finished in 0,011 s
19/01/24 18:10:09 INFO DAGScheduler: Job 7 finished: collect at utils.scala:200, took 0,360397 s
19/01/24 18:10:09 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:10:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 149 bytes
19/01/24 18:10:09 INFO DAGScheduler: Got job 8 (collect at utils.scala:200) with 4 output partitions
19/01/24 18:10:09 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:200)
19/01/24 18:10:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/01/24 18:10:09 INFO DAGScheduler: Missing parents: List()
19/01/24 18:10:09 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 18:10:09 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 236.1 KB, free 361.7 MB)
19/01/24 18:10:09 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 108.9 KB, free 361.6 MB)
19/01/24 18:10:09 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53103 (size: 108.9 KB, free: 363.9 MB)
19/01/24 18:10:09 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 18:10:09 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
19/01/24 18:10:09 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/01/24 18:10:09 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:10:09 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:10:09 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:10:09 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 16, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:10:09 INFO Executor: Running task 0.0 in stage 15.0 (TID 13)
19/01/24 18:10:09 INFO Executor: Running task 1.0 in stage 15.0 (TID 14)
19/01/24 18:10:09 INFO Executor: Running task 3.0 in stage 15.0 (TID 16)
19/01/24 18:10:09 INFO Executor: Running task 2.0 in stage 15.0 (TID 15)
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:10:09 INFO Executor: Finished task 3.0 in stage 15.0 (TID 16). 2558 bytes result sent to driver
19/01/24 18:10:09 INFO Executor: Finished task 1.0 in stage 15.0 (TID 14). 2558 bytes result sent to driver
19/01/24 18:10:09 INFO Executor: Finished task 0.0 in stage 15.0 (TID 13). 2558 bytes result sent to driver
19/01/24 18:10:09 INFO Executor: Finished task 2.0 in stage 15.0 (TID 15). 2558 bytes result sent to driver
19/01/24 18:10:09 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 16) in 22 ms on localhost (executor driver) (1/4)
19/01/24 18:10:09 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 14) in 22 ms on localhost (executor driver) (2/4)
19/01/24 18:10:09 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 13) in 22 ms on localhost (executor driver) (3/4)
19/01/24 18:10:09 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 15) in 22 ms on localhost (executor driver) (4/4)
19/01/24 18:10:09 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 18:10:09 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:200) finished in 0,023 s
19/01/24 18:10:09 INFO DAGScheduler: Job 8 finished: collect at utils.scala:200, took 0,032435 s
19/01/24 18:10:09 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:10:09 INFO DAGScheduler: Got job 9 (collect at utils.scala:200) with 3 output partitions
19/01/24 18:10:09 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:200)
19/01/24 18:10:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
19/01/24 18:10:09 INFO DAGScheduler: Missing parents: List()
19/01/24 18:10:09 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 18:10:09 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 236.1 KB, free 361.4 MB)
19/01/24 18:10:09 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 108.9 KB, free 361.3 MB)
19/01/24 18:10:09 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53103 (size: 108.9 KB, free: 363.8 MB)
19/01/24 18:10:09 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/01/24 18:10:09 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 17 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(5, 6, 7))
19/01/24 18:10:09 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
19/01/24 18:10:09 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 17, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:10:09 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 5, ANY, 4726 bytes)
19/01/24 18:10:09 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 19, localhost, executor driver, partition 7, ANY, 4726 bytes)
19/01/24 18:10:09 INFO Executor: Running task 1.0 in stage 17.0 (TID 17)
19/01/24 18:10:09 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
19/01/24 18:10:09 INFO Executor: Running task 2.0 in stage 17.0 (TID 19)
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:10:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:10:09 INFO Executor: Finished task 1.0 in stage 17.0 (TID 17). 2515 bytes result sent to driver
19/01/24 18:10:09 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 2548 bytes result sent to driver
19/01/24 18:10:09 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 17) in 11 ms on localhost (executor driver) (1/3)
19/01/24 18:10:09 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 11 ms on localhost (executor driver) (2/3)
19/01/24 18:10:09 INFO Executor: Finished task 2.0 in stage 17.0 (TID 19). 2535 bytes result sent to driver
19/01/24 18:10:09 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 19) in 13 ms on localhost (executor driver) (3/3)
19/01/24 18:10:09 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 18:10:09 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:200) finished in 0,013 s
19/01/24 18:10:09 INFO DAGScheduler: Job 9 finished: collect at utils.scala:200, took 0,020306 s
19/01/24 18:10:09 INFO CodeGenerator: Code generated in 4.465776 ms
19/01/24 18:10:09 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d83a21430e`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:10:09 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:10:09 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:10:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:10:09 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:10:09 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:10:09 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:10:09 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:10:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:10:09 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:10:09 INFO CodeGenerator: Code generated in 3.969093 ms
19/01/24 18:10:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:10:09 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:10:09 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:10:09 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:10:09 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:10:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:10:09 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:10:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83a21430e`
19/01/24 18:10:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83a21430e`
19/01/24 18:10:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83a21430e`
LIMIT 11
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 354
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 289
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 355
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 292
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 347
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 349
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 341
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 343
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 254
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 353
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 346
19/01/24 18:10:19 INFO ContextCleaner: Cleaned shuffle 4
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 255
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 252
19/01/24 18:10:19 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53103 in memory (size: 76.0 KB, free: 363.9 MB)
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 348
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 290
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 291
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 351
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 256
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 344
19/01/24 18:10:19 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53103 in memory (size: 115.8 KB, free: 364.0 MB)
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 253
19/01/24 18:10:19 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53103 in memory (size: 108.9 KB, free: 364.1 MB)
19/01/24 18:10:19 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53103 in memory (size: 108.9 KB, free: 364.2 MB)
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 357
19/01/24 18:10:19 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53103 in memory (size: 76.4 KB, free: 364.3 MB)
19/01/24 18:10:19 INFO ContextCleaner: Cleaned shuffle 3
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 288
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 350
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 287
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 342
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 345
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 251
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 356
19/01/24 18:10:19 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53103 in memory (size: 108.9 KB, free: 364.4 MB)
19/01/24 18:10:19 INFO ContextCleaner: Cleaned accumulator 352
19/01/24 18:10:19 INFO CodeGenerator: Code generated in 52.801996 ms
19/01/24 18:10:19 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:10:19 INFO DAGScheduler: Got job 10 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:10:19 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:200)
19/01/24 18:10:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:10:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:10:19 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[53] at collect at utils.scala:200), which has no missing parents
19/01/24 18:10:19 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 280.1 KB, free 363.0 MB)
19/01/24 18:10:19 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 117.6 KB, free 362.9 MB)
19/01/24 18:10:19 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53103 (size: 117.6 KB, free: 364.3 MB)
19/01/24 18:10:19 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/01/24 18:10:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[53] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:10:19 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/01/24 18:10:19 WARN TaskSetManager: Stage 18 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:10:19 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:10:19 INFO Executor: Running task 0.0 in stage 18.0 (TID 20)
19/01/24 18:10:19 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:10:19 INFO Executor: Finished task 0.0 in stage 18.0 (TID 20). 7303 bytes result sent to driver
19/01/24 18:10:19 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 20) in 74 ms on localhost (executor driver) (1/1)
19/01/24 18:10:19 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/01/24 18:10:19 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:200) finished in 0,074 s
19/01/24 18:10:19 INFO DAGScheduler: Job 10 finished: collect at utils.scala:200, took 0,082702 s
19/01/24 18:10:19 INFO CodeGenerator: Code generated in 13.659165 ms
19/01/24 18:10:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83a21430e`
19/01/24 18:11:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83a21430e`
WHERE ( != )
19/01/24 18:11:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83a21430e`
WHERE ( != )
19/01/24 18:11:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83a21430e`
WHERE ( != )
19/01/24 18:11:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d83a21430e`
19/01/24 18:11:37 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:11:37 INFO DAGScheduler: Got job 11 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:11:37 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:200)
19/01/24 18:11:37 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:11:37 INFO DAGScheduler: Missing parents: List()
19/01/24 18:11:37 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[56] at collect at utils.scala:200), which has no missing parents
19/01/24 18:11:37 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 280.2 KB, free 362.6 MB)
19/01/24 18:11:37 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 117.6 KB, free 362.5 MB)
19/01/24 18:11:37 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53103 (size: 117.6 KB, free: 364.2 MB)
19/01/24 18:11:37 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/01/24 18:11:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[56] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:11:37 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/01/24 18:11:37 WARN TaskSetManager: Stage 19 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:11:37 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:11:37 INFO Executor: Running task 0.0 in stage 19.0 (TID 21)
19/01/24 18:11:37 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:11:38 INFO ContextCleaner: Cleaned accumulator 454
19/01/24 18:11:38 INFO ContextCleaner: Cleaned accumulator 459
19/01/24 18:11:38 INFO ContextCleaner: Cleaned accumulator 457
19/01/24 18:11:38 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53103 in memory (size: 117.6 KB, free: 364.3 MB)
19/01/24 18:11:38 INFO ContextCleaner: Cleaned accumulator 456
19/01/24 18:11:38 INFO ContextCleaner: Cleaned accumulator 455
19/01/24 18:11:38 INFO ContextCleaner: Cleaned accumulator 458
19/01/24 18:11:38 INFO MemoryStore: Block taskresult_21 stored as bytes in memory (estimated size 2.3 MB, free 360.5 MB)
19/01/24 18:11:38 INFO BlockManagerInfo: Added taskresult_21 in memory on 127.0.0.1:53103 (size: 2.3 MB, free: 361.9 MB)
19/01/24 18:11:38 INFO Executor: Finished task 0.0 in stage 19.0 (TID 21). 2459786 bytes result sent via BlockManager)
19/01/24 18:11:38 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53103 after 1 ms (0 ms spent in bootstraps)
19/01/24 18:11:38 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 21) in 636 ms on localhost (executor driver) (1/1)
19/01/24 18:11:38 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/01/24 18:11:38 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:200) finished in 0,636 s
19/01/24 18:11:38 INFO DAGScheduler: Job 11 finished: collect at utils.scala:200, took 0,645462 s
19/01/24 18:11:38 INFO BlockManagerInfo: Removed taskresult_21 on 127.0.0.1:53103 in memory (size: 2.3 MB, free: 364.3 MB)
19/01/24 18:11:38 INFO CodeGenerator: Code generated in 11.747553 ms
19/01/24 18:11:38 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53103 in memory (size: 117.6 KB, free: 364.4 MB)
19/01/24 18:13:48 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 18:13:48 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 18:13:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 18:13:48 INFO MemoryStore: MemoryStore cleared
19/01/24 18:13:48 INFO BlockManager: BlockManager stopped
19/01/24 18:13:48 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 18:13:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 18:13:48 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-30dec006-617b-433d-b9e9-1a71574b0476\userFiles-8e205c6c-dbd0-4558-b005-d58c7b2cb9bc
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-30dec006-617b-433d-b9e9-1a71574b0476\userFiles-8e205c6c-dbd0-4558-b005-d58c7b2cb9bc
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:13:48 INFO SparkContext: Successfully stopped SparkContext
19/01/24 18:13:48 INFO ShutdownHookManager: Shutdown hook called
19/01/24 18:13:48 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-30dec006-617b-433d-b9e9-1a71574b0476\userFiles-8e205c6c-dbd0-4558-b005-d58c7b2cb9bc
19/01/24 18:13:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-30dec006-617b-433d-b9e9-1a71574b0476\userFiles-8e205c6c-dbd0-4558-b005-d58c7b2cb9bc
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-30dec006-617b-433d-b9e9-1a71574b0476\userFiles-8e205c6c-dbd0-4558-b005-d58c7b2cb9bc
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:13:48 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-30dec006-617b-433d-b9e9-1a71574b0476
19/01/24 18:13:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-30dec006-617b-433d-b9e9-1a71574b0476
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-30dec006-617b-433d-b9e9-1a71574b0476
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:14:23 INFO SparkContext: Running Spark version 2.2.0
19/01/24 18:14:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 18:14:24 INFO SparkContext: Submitted application: sparklyr
19/01/24 18:14:24 INFO SecurityManager: Changing view acls to: yanis
19/01/24 18:14:24 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 18:14:24 INFO SecurityManager: Changing view acls groups to: 
19/01/24 18:14:24 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 18:14:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 18:14:24 INFO Utils: Successfully started service 'sparkDriver' on port 53194.
19/01/24 18:14:24 INFO SparkEnv: Registering MapOutputTracker
19/01/24 18:14:24 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 18:14:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 18:14:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 18:14:24 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-e927f681-72ed-4638-acd9-2b041a6e5d0f
19/01/24 18:14:24 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 18:14:24 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 18:14:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 18:14:24 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 18:14:24 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:53194/jars/sparklyr-2.2-2.11.jar with timestamp 1548350064493
19/01/24 18:14:24 INFO Executor: Starting executor ID driver on host localhost
19/01/24 18:14:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53235.
19/01/24 18:14:24 INFO NettyBlockTransferService: Server created on 127.0.0.1:53235
19/01/24 18:14:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 18:14:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53235, None)
19/01/24 18:14:24 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53235 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53235, None)
19/01/24 18:14:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53235, None)
19/01/24 18:14:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53235, None)
19/01/24 18:14:24 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 18:14:24 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 18:14:24 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 18:14:24 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 18:14:25 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 18:14:25 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 18:14:25 INFO ObjectStore: ObjectStore, initialize called
19/01/24 18:14:26 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 18:14:26 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 18:14:27 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 18:14:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:14:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:14:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:14:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:14:28 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 18:14:28 INFO ObjectStore: Initialized ObjectStore
19/01/24 18:14:28 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 18:14:28 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 18:14:28 INFO HiveMetaStore: Added admin role in metastore
19/01/24 18:14:28 INFO HiveMetaStore: Added public role in metastore
19/01/24 18:14:28 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 18:14:28 INFO HiveMetaStore: 0: get_all_databases
19/01/24 18:14:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 18:14:28 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 18:14:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 18:14:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:14:28 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/b93e9d7a-449c-4c29-9877-2301e9dc304b_resources
19/01/24 18:14:28 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/b93e9d7a-449c-4c29-9877-2301e9dc304b
19/01/24 18:14:28 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/b93e9d7a-449c-4c29-9877-2301e9dc304b
19/01/24 18:14:28 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/b93e9d7a-449c-4c29-9877-2301e9dc304b/_tmp_space.db
19/01/24 18:14:28 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:14:28 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:14:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:14:29 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 18:14:29 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 18:14:29 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 18:14:29 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/b9b64c2b-2773-40a3-96ca-4241cffa0953_resources
19/01/24 18:14:29 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/b9b64c2b-2773-40a3-96ca-4241cffa0953
19/01/24 18:14:29 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/b9b64c2b-2773-40a3-96ca-4241cffa0953
19/01/24 18:14:29 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/b9b64c2b-2773-40a3-96ca-4241cffa0953/_tmp_space.db
19/01/24 18:14:29 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:14:29 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 18:14:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:14:30 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:14:30 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:14:30 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:14:30 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:14:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:14:30 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:14:31 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 18:14:31 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 18:14:31 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 18:14:31 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:14:31 INFO DAGScheduler: Missing parents: List()
19/01/24 18:14:31 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 18:14:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 18:14:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 18:14:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53235 (size: 3.4 KB, free: 366.3 MB)
19/01/24 18:14:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 18:14:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 18:14:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 18:14:31 INFO Executor: Fetching spark://127.0.0.1:53194/jars/sparklyr-2.2-2.11.jar with timestamp 1548350064493
19/01/24 18:14:31 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53194 after 15 ms (0 ms spent in bootstraps)
19/01/24 18:14:31 INFO Utils: Fetching spark://127.0.0.1:53194/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-c2545db2-658c-4824-b1da-8fe167beab4c\userFiles-941b3f06-004b-4b11-8ab0-625040c24849\fetchFileTemp2331130323454932344.tmp
19/01/24 18:14:31 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-c2545db2-658c-4824-b1da-8fe167beab4c/userFiles-941b3f06-004b-4b11-8ab0-625040c24849/sparklyr-2.2-2.11.jar to class loader
19/01/24 18:14:31 INFO CodeGenerator: Code generated in 174.738931 ms
19/01/24 18:14:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/01/24 18:14:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 508 ms on localhost (executor driver) (1/1)
19/01/24 18:14:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 18:14:31 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,525 s
19/01/24 18:14:31 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,697323 s
19/01/24 18:14:32 INFO SparkSqlParser: Parsing command: reviews
19/01/24 18:14:32 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 18:14:32 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 18:14:32 INFO CodeGenerator: Code generated in 14.18247 ms
19/01/24 18:14:32 INFO CodeGenerator: Code generated in 8.363394 ms
19/01/24 18:14:32 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 18:14:32 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 18:14:32 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 18:14:32 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 18:14:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 18:14:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 18:14:32 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 18:14:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 18:14:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 18:14:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53235 (size: 7.7 KB, free: 366.3 MB)
19/01/24 18:14:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 18:14:32 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:14:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:14:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 18:14:32 INFO CodeGenerator: Code generated in 8.467326 ms
19/01/24 18:14:32 INFO CodeGenerator: Code generated in 20.057341 ms
19/01/24 18:14:32 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.4 MB)
19/01/24 18:14:32 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:53235 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 18:14:32 INFO CodeGenerator: Code generated in 4.719954 ms
19/01/24 18:14:32 INFO CodeGenerator: Code generated in 14.835963 ms
19/01/24 18:14:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 18:14:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 374 ms on localhost (executor driver) (1/1)
19/01/24 18:14:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 18:14:32 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,377 s
19/01/24 18:14:32 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:14:32 INFO DAGScheduler: running: Set()
19/01/24 18:14:32 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 18:14:32 INFO DAGScheduler: failed: Set()
19/01/24 18:14:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 18:14:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:14:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:14:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53235 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:14:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 18:14:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:14:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 18:14:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:14:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/01/24 18:14:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1538 bytes result sent to driver
19/01/24 18:14:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (executor driver) (1/1)
19/01/24 18:14:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 18:14:33 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,030 s
19/01/24 18:14:33 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,448221 s
19/01/24 18:14:33 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 18:14:33 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:14:33 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:14:33 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53235 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 18:14:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53235 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 18:14:33 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 18:14:33 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 18:14:33 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53235 in memory (size: 3.4 KB, free: 364.5 MB)
19/01/24 18:14:33 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:14:33 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 18:14:33 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:14:33 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 18:14:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 18:14:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 18:14:33 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 18:14:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 18:14:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.5 MB)
19/01/24 18:14:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53235 (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:14:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 18:14:33 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:14:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:14:33 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 18:14:33 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:14:33 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1647 bytes result sent to driver
19/01/24 18:14:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 34 ms on localhost (executor driver) (1/1)
19/01/24 18:14:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 18:14:33 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,035 s
19/01/24 18:14:33 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:14:33 INFO DAGScheduler: running: Set()
19/01/24 18:14:33 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 18:14:33 INFO DAGScheduler: failed: Set()
19/01/24 18:14:33 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 18:14:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:14:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:14:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53235 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:14:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:33 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 18:14:33 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:14:33 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 18:14:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:14:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:14:33 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/01/24 18:14:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
19/01/24 18:14:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 18:14:33 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,006 s
19/01/24 18:14:33 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,056766 s
19/01/24 18:14:33 INFO CodeGenerator: Code generated in 5.985001 ms
19/01/24 18:14:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz18`
WHERE (0 = 1)
19/01/24 18:14:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 18:14:35 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d81d03968
19/01/24 18:14:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d81d03968` AS `zzz19`
WHERE (0 = 1)
19/01/24 18:14:35 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d846ba3aeb
19/01/24 18:14:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d846ba3aeb` AS `zzz20`
WHERE (0 = 1)
19/01/24 18:14:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d81d03968`
19/01/24 18:14:36 INFO CodeGenerator: Code generated in 25.145978 ms
19/01/24 18:14:36 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:14:36 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 18:14:36 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:14:36 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 18:14:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 18:14:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 18:14:36 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:14:36 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 18:14:36 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 18:14:36 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53235 (size: 13.0 KB, free: 364.5 MB)
19/01/24 18:14:36 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:36 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 18:14:36 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:14:36 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:14:36 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 18:14:36 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:14:36 INFO CodeGenerator: Code generated in 11.587462 ms
19/01/24 18:14:36 INFO CodeGenerator: Code generated in 11.724944 ms
19/01/24 18:14:36 INFO CodeGenerator: Code generated in 7.810551 ms
19/01/24 18:14:36 INFO CodeGenerator: Code generated in 9.105138 ms
19/01/24 18:14:36 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 18:14:36 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53235 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:14:36 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53235 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:14:36 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1951 bytes result sent to driver
19/01/24 18:14:36 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 676 ms on localhost (executor driver) (1/1)
19/01/24 18:14:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 18:14:36 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 0,677 s
19/01/24 18:14:36 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:14:36 INFO DAGScheduler: running: Set()
19/01/24 18:14:36 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 18:14:36 INFO DAGScheduler: failed: Set()
19/01/24 18:14:36 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:14:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 18:14:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 18:14:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53235 (size: 1887.0 B, free: 364.5 MB)
19/01/24 18:14:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:36 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 18:14:36 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:14:36 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 18:14:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:14:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:14:36 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 18:14:36 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:53235 (size: 686.3 KB, free: 363.8 MB)
19/01/24 18:14:36 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1787 bytes result sent to driver
19/01/24 18:14:36 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 103 ms on localhost (executor driver) (1/1)
19/01/24 18:14:36 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 18:14:36 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,104 s
19/01/24 18:14:36 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 0,810419 s
19/01/24 18:14:36 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:14:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 18:14:36 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:14:36 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 18:14:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 18:14:36 INFO DAGScheduler: Missing parents: List()
19/01/24 18:14:36 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:14:36 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.8 MB)
19/01/24 18:14:36 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.8 MB)
19/01/24 18:14:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53235 (size: 2.2 KB, free: 363.8 MB)
19/01/24 18:14:36 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:36 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 18:14:36 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:14:36 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 18:14:36 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 18:14:36 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 18:14:37 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 40 ms on localhost (executor driver) (1/1)
19/01/24 18:14:37 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 18:14:37 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,040 s
19/01/24 18:14:37 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,053694 s
19/01/24 18:14:37 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 18:14:37 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.6 MB)
19/01/24 18:14:37 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53235 (size: 89.8 KB, free: 363.7 MB)
19/01/24 18:14:37 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 18:14:37 INFO CodeGenerator: Code generated in 34.491435 ms
19/01/24 18:14:37 INFO Instrumentation: NaiveBayes-naive_bayes_57d812166403-926565058-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 18:14:37 INFO Instrumentation: NaiveBayes-naive_bayes_57d812166403-926565058-1: {"smoothing":1.0,"featuresCol":"vectorizer_output","modelType":"multinomial","labelCol":"Sentiment","predictionCol":"prediction","rawPredictionCol":"rawPrediction","probabilityCol":"probability"}
19/01/24 18:14:37 INFO CodeGenerator: Code generated in 22.301535 ms
19/01/24 18:14:37 INFO SparkContext: Starting job: head at NaiveBayes.scala:154
19/01/24 18:14:37 INFO DAGScheduler: Got job 5 (head at NaiveBayes.scala:154) with 1 output partitions
19/01/24 18:14:37 INFO DAGScheduler: Final stage: ResultStage 9 (head at NaiveBayes.scala:154)
19/01/24 18:14:37 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:14:37 INFO DAGScheduler: Missing parents: List()
19/01/24 18:14:37 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154), which has no missing parents
19/01/24 18:14:37 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 113.1 KB, free 362.4 MB)
19/01/24 18:14:37 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 73.0 KB, free 362.4 MB)
19/01/24 18:14:37 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53235 (size: 73.0 KB, free: 363.6 MB)
19/01/24 18:14:37 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:37 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 18:14:37 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:14:37 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:14:37 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 18:14:37 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:14:37 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 1743 bytes result sent to driver
19/01/24 18:14:37 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 57 ms on localhost (executor driver) (1/1)
19/01/24 18:14:37 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 18:14:37 INFO DAGScheduler: ResultStage 9 (head at NaiveBayes.scala:154) finished in 0,058 s
19/01/24 18:14:37 INFO DAGScheduler: Job 5 finished: head at NaiveBayes.scala:154, took 0,067267 s
19/01/24 18:14:37 INFO CodeGenerator: Code generated in 4.972672 ms
19/01/24 18:14:37 INFO Instrumentation: NaiveBayes-naive_bayes_57d812166403-926565058-1: {"numFeatures":8098}
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 178
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 258
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 176
19/01/24 18:14:37 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53235 in memory (size: 73.0 KB, free: 363.7 MB)
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 177
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 261
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 174
19/01/24 18:14:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53235 in memory (size: 13.0 KB, free: 363.7 MB)
19/01/24 18:14:37 INFO BlockManager: Removing RDD 30
19/01/24 18:14:37 INFO ContextCleaner: Cleaned RDD 30
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 259
19/01/24 18:14:37 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 18:14:37 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53235 in memory (size: 1887.0 B, free: 364.4 MB)
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 262
19/01/24 18:14:37 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53235 in memory (size: 2.2 KB, free: 364.4 MB)
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 257
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 175
19/01/24 18:14:37 INFO ContextCleaner: Cleaned accumulator 260
19/01/24 18:14:37 INFO CodeGenerator: Code generated in 21.049615 ms
19/01/24 18:14:37 INFO SparkContext: Starting job: collect at NaiveBayes.scala:174
19/01/24 18:14:37 INFO DAGScheduler: Registering RDD 43 (map at NaiveBayes.scala:162)
19/01/24 18:14:37 INFO DAGScheduler: Got job 6 (collect at NaiveBayes.scala:174) with 1 output partitions
19/01/24 18:14:37 INFO DAGScheduler: Final stage: ResultStage 11 (collect at NaiveBayes.scala:174)
19/01/24 18:14:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/01/24 18:14:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/01/24 18:14:37 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162), which has no missing parents
19/01/24 18:14:37 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 243.7 KB, free 363.0 MB)
19/01/24 18:14:37 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 76.1 KB, free 363.0 MB)
19/01/24 18:14:37 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53235 (size: 76.1 KB, free: 364.3 MB)
19/01/24 18:14:37 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:37 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 18:14:37 WARN TaskSetManager: Stage 10 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:14:37 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:14:37 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 18:14:37 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:14:37 INFO CodeGenerator: Code generated in 6.645788 ms
19/01/24 18:14:37 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1951 bytes result sent to driver
19/01/24 18:14:37 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 370 ms on localhost (executor driver) (1/1)
19/01/24 18:14:37 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 18:14:37 INFO DAGScheduler: ShuffleMapStage 10 (map at NaiveBayes.scala:162) finished in 0,371 s
19/01/24 18:14:37 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:14:37 INFO DAGScheduler: running: Set()
19/01/24 18:14:37 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/01/24 18:14:37 INFO DAGScheduler: failed: Set()
19/01/24 18:14:37 INFO DAGScheduler: Submitting ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163), which has no missing parents
19/01/24 18:14:37 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 244.4 KB, free 362.7 MB)
19/01/24 18:14:37 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 76.4 KB, free 362.7 MB)
19/01/24 18:14:37 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53235 (size: 76.4 KB, free: 364.2 MB)
19/01/24 18:14:37 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/01/24 18:14:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:14:37 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 18:14:37 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:14:37 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 18:14:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:14:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:14:37 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 132320 bytes result sent to driver
19/01/24 18:14:37 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 9 ms on localhost (executor driver) (1/1)
19/01/24 18:14:37 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 18:14:37 INFO DAGScheduler: ResultStage 11 (collect at NaiveBayes.scala:174) finished in 0,010 s
19/01/24 18:14:37 INFO DAGScheduler: Job 6 finished: collect at NaiveBayes.scala:174, took 0,398611 s
19/01/24 18:14:37 INFO Instrumentation: NaiveBayes-naive_bayes_57d812166403-926565058-1: {"numClasses":2}
19/01/24 18:14:37 INFO Instrumentation: NaiveBayes-naive_bayes_57d812166403-926565058-1: training finished
19/01/24 18:15:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d846ba3aeb`
19/01/24 18:15:01 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d8390063a8
19/01/24 18:15:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d8390063a8` AS `zzz21`
WHERE (0 = 1)
19/01/24 18:15:01 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d8390063a8`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:15:01 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:15:01 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:15:01 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d8390063a8`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:15:01 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:15:01 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:15:01 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d8390063a8`
GROUP BY `Sentiment`, `Prediction`
LIMIT 11
19/01/24 18:15:01 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:15:01 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:15:01 INFO CodeGenerator: Code generated in 18.960772 ms
19/01/24 18:15:01 INFO CodeGenerator: Code generated in 44.97467 ms
19/01/24 18:15:01 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:15:01 INFO DAGScheduler: Registering RDD 47 (collect at utils.scala:200)
19/01/24 18:15:01 INFO DAGScheduler: Got job 7 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:15:01 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:200)
19/01/24 18:15:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/01/24 18:15:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/01/24 18:15:01 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[47] at collect at utils.scala:200), which has no missing parents
19/01/24 18:15:01 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 254.9 KB, free 362.4 MB)
19/01/24 18:15:01 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 115.8 KB, free 362.3 MB)
19/01/24 18:15:01 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53235 (size: 115.8 KB, free: 364.1 MB)
19/01/24 18:15:01 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 18:15:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[47] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:15:01 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 18:15:01 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:15:01 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:15:01 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 18:15:01 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:15:01 INFO CodeGenerator: Code generated in 3.947942 ms
19/01/24 18:15:01 INFO CodeGenerator: Code generated in 4.463953 ms
19/01/24 18:15:01 INFO CodeGenerator: Code generated in 4.047133 ms
19/01/24 18:15:01 INFO CodeGenerator: Code generated in 7.077924 ms
19/01/24 18:15:01 INFO CodeGenerator: Code generated in 4.2178 ms
19/01/24 18:15:01 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/01/24 18:15:01 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/01/24 18:15:01 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 2263 bytes result sent to driver
19/01/24 18:15:01 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 280 ms on localhost (executor driver) (1/1)
19/01/24 18:15:01 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 18:15:01 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:200) finished in 0,281 s
19/01/24 18:15:01 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:15:01 INFO DAGScheduler: running: Set()
19/01/24 18:15:01 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/01/24 18:15:01 INFO DAGScheduler: failed: Set()
19/01/24 18:15:01 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 18:15:01 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 236.2 KB, free 362.1 MB)
19/01/24 18:15:01 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 108.9 KB, free 362.0 MB)
19/01/24 18:15:01 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53235 (size: 108.9 KB, free: 364.0 MB)
19/01/24 18:15:01 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/01/24 18:15:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:15:01 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 18:15:01 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:15:01 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:15:01 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 2541 bytes result sent to driver
19/01/24 18:15:01 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 9 ms on localhost (executor driver) (1/1)
19/01/24 18:15:01 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 18:15:01 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:200) finished in 0,009 s
19/01/24 18:15:01 INFO DAGScheduler: Job 7 finished: collect at utils.scala:200, took 0,306133 s
19/01/24 18:15:01 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:15:01 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 149 bytes
19/01/24 18:15:01 INFO DAGScheduler: Got job 8 (collect at utils.scala:200) with 4 output partitions
19/01/24 18:15:01 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:200)
19/01/24 18:15:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/01/24 18:15:01 INFO DAGScheduler: Missing parents: List()
19/01/24 18:15:01 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 18:15:01 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 236.2 KB, free 361.7 MB)
19/01/24 18:15:01 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 108.9 KB, free 361.6 MB)
19/01/24 18:15:01 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53235 (size: 108.9 KB, free: 363.9 MB)
19/01/24 18:15:01 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 18:15:01 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
19/01/24 18:15:01 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/01/24 18:15:01 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:15:01 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:15:01 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:15:01 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 16, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:15:01 INFO Executor: Running task 0.0 in stage 15.0 (TID 13)
19/01/24 18:15:01 INFO Executor: Running task 1.0 in stage 15.0 (TID 14)
19/01/24 18:15:01 INFO Executor: Running task 3.0 in stage 15.0 (TID 16)
19/01/24 18:15:01 INFO Executor: Running task 2.0 in stage 15.0 (TID 15)
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:15:01 INFO Executor: Finished task 0.0 in stage 15.0 (TID 13). 2558 bytes result sent to driver
19/01/24 18:15:01 INFO Executor: Finished task 2.0 in stage 15.0 (TID 15). 2558 bytes result sent to driver
19/01/24 18:15:01 INFO Executor: Finished task 1.0 in stage 15.0 (TID 14). 2558 bytes result sent to driver
19/01/24 18:15:01 INFO Executor: Finished task 3.0 in stage 15.0 (TID 16). 2558 bytes result sent to driver
19/01/24 18:15:01 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 13) in 15 ms on localhost (executor driver) (1/4)
19/01/24 18:15:01 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 15) in 14 ms on localhost (executor driver) (2/4)
19/01/24 18:15:01 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 14) in 14 ms on localhost (executor driver) (3/4)
19/01/24 18:15:01 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 16) in 15 ms on localhost (executor driver) (4/4)
19/01/24 18:15:01 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 18:15:01 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:200) finished in 0,016 s
19/01/24 18:15:01 INFO DAGScheduler: Job 8 finished: collect at utils.scala:200, took 0,024213 s
19/01/24 18:15:01 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:15:01 INFO DAGScheduler: Got job 9 (collect at utils.scala:200) with 3 output partitions
19/01/24 18:15:01 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:200)
19/01/24 18:15:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
19/01/24 18:15:01 INFO DAGScheduler: Missing parents: List()
19/01/24 18:15:01 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 18:15:01 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 236.2 KB, free 361.4 MB)
19/01/24 18:15:01 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 108.9 KB, free 361.3 MB)
19/01/24 18:15:01 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53235 (size: 108.9 KB, free: 363.8 MB)
19/01/24 18:15:01 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/01/24 18:15:01 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 17 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(5, 6, 7))
19/01/24 18:15:01 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
19/01/24 18:15:01 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 17, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:15:01 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 5, ANY, 4726 bytes)
19/01/24 18:15:01 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 19, localhost, executor driver, partition 7, ANY, 4726 bytes)
19/01/24 18:15:01 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
19/01/24 18:15:01 INFO Executor: Running task 1.0 in stage 17.0 (TID 17)
19/01/24 18:15:01 INFO Executor: Running task 2.0 in stage 17.0 (TID 19)
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:15:01 INFO Executor: Finished task 1.0 in stage 17.0 (TID 17). 2515 bytes result sent to driver
19/01/24 18:15:01 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 17) in 8 ms on localhost (executor driver) (1/3)
19/01/24 18:15:01 INFO Executor: Finished task 2.0 in stage 17.0 (TID 19). 2535 bytes result sent to driver
19/01/24 18:15:01 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 2548 bytes result sent to driver
19/01/24 18:15:01 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 19) in 10 ms on localhost (executor driver) (2/3)
19/01/24 18:15:01 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 10 ms on localhost (executor driver) (3/3)
19/01/24 18:15:01 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 18:15:01 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:200) finished in 0,011 s
19/01/24 18:15:01 INFO DAGScheduler: Job 9 finished: collect at utils.scala:200, took 0,018857 s
19/01/24 18:15:01 INFO CodeGenerator: Code generated in 4.727247 ms
19/01/24 18:15:01 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d8390063a8`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:15:01 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:15:01 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:15:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:15:02 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:15:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:15:02 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:15:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:15:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:15:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:15:02 INFO CodeGenerator: Code generated in 4.609823 ms
19/01/24 18:15:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:15:02 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:15:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:15:02 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:15:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:15:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:15:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:15:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:15:02 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:15:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:15:02 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:15:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:15:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:15:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:16:55 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d8390063a8`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:16:55 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:16:55 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 254
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 118
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 341
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 115
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 292
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 291
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 290
19/01/24 18:18:09 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53235 in memory (size: 76.4 KB, free: 363.9 MB)
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 256
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 124
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 255
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 287
19/01/24 18:18:09 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 18:18:09 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53235 in memory (size: 108.9 KB, free: 364.0 MB)
19/01/24 18:18:09 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53235 in memory (size: 115.8 KB, free: 364.1 MB)
19/01/24 18:18:09 INFO ContextCleaner: Cleaned shuffle 3
19/01/24 18:18:09 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53235 in memory (size: 108.9 KB, free: 364.2 MB)
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 288
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 120
19/01/24 18:18:09 INFO ContextCleaner: Cleaned shuffle 1
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 121
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 122
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 119
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 116
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 251
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 123
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 113
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 114
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 289
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 117
19/01/24 18:18:09 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53235 in memory (size: 108.9 KB, free: 364.3 MB)
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 252
19/01/24 18:18:09 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53235 in memory (size: 76.1 KB, free: 364.4 MB)
19/01/24 18:18:09 INFO ContextCleaner: Cleaned accumulator 253
19/01/24 18:18:09 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 18:18:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 18:18:09 INFO MemoryStore: MemoryStore cleared
19/01/24 18:18:09 INFO BlockManager: BlockManager stopped
19/01/24 18:18:09 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 18:18:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 18:18:09 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-c2545db2-658c-4824-b1da-8fe167beab4c\userFiles-941b3f06-004b-4b11-8ab0-625040c24849
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-c2545db2-658c-4824-b1da-8fe167beab4c\userFiles-941b3f06-004b-4b11-8ab0-625040c24849
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:18:09 INFO SparkContext: Successfully stopped SparkContext
19/01/24 18:18:09 INFO ShutdownHookManager: Shutdown hook called
19/01/24 18:18:09 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-c2545db2-658c-4824-b1da-8fe167beab4c
19/01/24 18:18:09 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-c2545db2-658c-4824-b1da-8fe167beab4c
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-c2545db2-658c-4824-b1da-8fe167beab4c
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:18:09 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-c2545db2-658c-4824-b1da-8fe167beab4c\userFiles-941b3f06-004b-4b11-8ab0-625040c24849
19/01/24 18:18:09 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-c2545db2-658c-4824-b1da-8fe167beab4c\userFiles-941b3f06-004b-4b11-8ab0-625040c24849
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-c2545db2-658c-4824-b1da-8fe167beab4c\userFiles-941b3f06-004b-4b11-8ab0-625040c24849
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:18:18 INFO SparkContext: Running Spark version 2.2.0
19/01/24 18:18:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 18:18:18 INFO SparkContext: Submitted application: sparklyr
19/01/24 18:18:18 INFO SecurityManager: Changing view acls to: yanis
19/01/24 18:18:18 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 18:18:18 INFO SecurityManager: Changing view acls groups to: 
19/01/24 18:18:18 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 18:18:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 18:18:18 INFO Utils: Successfully started service 'sparkDriver' on port 53318.
19/01/24 18:18:18 INFO SparkEnv: Registering MapOutputTracker
19/01/24 18:18:18 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 18:18:18 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 18:18:18 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 18:18:18 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-bab0a56a-1547-42e6-8ff9-592f6828b31d
19/01/24 18:18:18 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 18:18:18 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 18:18:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 18:18:18 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 18:18:18 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:53318/jars/sparklyr-2.2-2.11.jar with timestamp 1548350298884
19/01/24 18:18:18 INFO Executor: Starting executor ID driver on host localhost
19/01/24 18:18:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53359.
19/01/24 18:18:18 INFO NettyBlockTransferService: Server created on 127.0.0.1:53359
19/01/24 18:18:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 18:18:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53359, None)
19/01/24 18:18:18 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53359 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53359, None)
19/01/24 18:18:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53359, None)
19/01/24 18:18:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53359, None)
19/01/24 18:18:19 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 18:18:19 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 18:18:19 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 18:18:19 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 18:18:19 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 18:18:20 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 18:18:20 INFO ObjectStore: ObjectStore, initialize called
19/01/24 18:18:20 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 18:18:20 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 18:18:21 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 18:18:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:18:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:18:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:18:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:18:22 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 18:18:22 INFO ObjectStore: Initialized ObjectStore
19/01/24 18:18:22 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 18:18:23 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 18:18:23 INFO HiveMetaStore: Added admin role in metastore
19/01/24 18:18:23 INFO HiveMetaStore: Added public role in metastore
19/01/24 18:18:23 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 18:18:23 INFO HiveMetaStore: 0: get_all_databases
19/01/24 18:18:23 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 18:18:23 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 18:18:23 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 18:18:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:18:23 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/f8e578cc-472c-49d4-9dbc-b58aba6eff45_resources
19/01/24 18:18:23 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/f8e578cc-472c-49d4-9dbc-b58aba6eff45
19/01/24 18:18:23 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/f8e578cc-472c-49d4-9dbc-b58aba6eff45
19/01/24 18:18:23 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/f8e578cc-472c-49d4-9dbc-b58aba6eff45/_tmp_space.db
19/01/24 18:18:23 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:18:23 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:18:23 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:18:23 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 18:18:23 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 18:18:23 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 18:18:23 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/cee98583-12ef-4764-a85b-e65247bb4a79_resources
19/01/24 18:18:23 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/cee98583-12ef-4764-a85b-e65247bb4a79
19/01/24 18:18:23 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/cee98583-12ef-4764-a85b-e65247bb4a79
19/01/24 18:18:23 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/cee98583-12ef-4764-a85b-e65247bb4a79/_tmp_space.db
19/01/24 18:18:23 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:18:23 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 18:18:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:18:25 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:18:25 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:18:25 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:18:25 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:18:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:18:25 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:18:25 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 18:18:25 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 18:18:25 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 18:18:25 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:18:25 INFO DAGScheduler: Missing parents: List()
19/01/24 18:18:25 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 18:18:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 18:18:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 18:18:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53359 (size: 3.4 KB, free: 366.3 MB)
19/01/24 18:18:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 18:18:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 18:18:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 18:18:26 INFO Executor: Fetching spark://127.0.0.1:53318/jars/sparklyr-2.2-2.11.jar with timestamp 1548350298884
19/01/24 18:18:26 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53318 after 15 ms (0 ms spent in bootstraps)
19/01/24 18:18:26 INFO Utils: Fetching spark://127.0.0.1:53318/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-13c9cf02-5939-48bf-aec3-54e6b9b7202f\userFiles-6b9bfc00-0023-418f-9ab4-242cc0752180\fetchFileTemp4862885944848947926.tmp
19/01/24 18:18:26 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-13c9cf02-5939-48bf-aec3-54e6b9b7202f/userFiles-6b9bfc00-0023-418f-9ab4-242cc0752180/sparklyr-2.2-2.11.jar to class loader
19/01/24 18:18:26 INFO CodeGenerator: Code generated in 179.242998 ms
19/01/24 18:18:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/01/24 18:18:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 528 ms on localhost (executor driver) (1/1)
19/01/24 18:18:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 18:18:26 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,547 s
19/01/24 18:18:26 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,718870 s
19/01/24 18:18:26 INFO SparkSqlParser: Parsing command: reviews
19/01/24 18:18:26 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 18:18:26 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 18:18:27 INFO CodeGenerator: Code generated in 14.559906 ms
19/01/24 18:18:27 INFO CodeGenerator: Code generated in 9.165674 ms
19/01/24 18:18:27 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 18:18:27 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 18:18:27 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 18:18:27 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 18:18:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 18:18:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 18:18:27 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 18:18:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 18:18:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 18:18:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53359 (size: 7.7 KB, free: 366.3 MB)
19/01/24 18:18:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 18:18:27 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:18:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:18:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 18:18:27 INFO CodeGenerator: Code generated in 10.514961 ms
19/01/24 18:18:27 INFO CodeGenerator: Code generated in 19.494652 ms
19/01/24 18:18:27 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.4 MB)
19/01/24 18:18:27 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:53359 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 18:18:27 INFO CodeGenerator: Code generated in 3.27731 ms
19/01/24 18:18:27 INFO CodeGenerator: Code generated in 16.189991 ms
19/01/24 18:18:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 18:18:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 383 ms on localhost (executor driver) (1/1)
19/01/24 18:18:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 18:18:27 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,384 s
19/01/24 18:18:27 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:18:27 INFO DAGScheduler: running: Set()
19/01/24 18:18:27 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 18:18:27 INFO DAGScheduler: failed: Set()
19/01/24 18:18:27 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 18:18:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:18:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:18:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53359 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:18:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 18:18:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:18:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 18:18:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:18:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/01/24 18:18:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1538 bytes result sent to driver
19/01/24 18:18:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:18:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 18:18:27 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,030 s
19/01/24 18:18:27 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,477484 s
19/01/24 18:18:27 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 18:18:27 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:18:27 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:18:27 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53359 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 18:18:27 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 18:18:27 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 18:18:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53359 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:18:27 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53359 in memory (size: 3.4 KB, free: 364.5 MB)
19/01/24 18:18:27 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:18:27 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 18:18:27 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:18:27 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 18:18:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 18:18:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 18:18:27 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 18:18:27 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 18:18:27 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.5 MB)
19/01/24 18:18:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53359 (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:18:27 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:27 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 18:18:27 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:18:27 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:18:27 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 18:18:27 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:18:27 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
19/01/24 18:18:27 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 44 ms on localhost (executor driver) (1/1)
19/01/24 18:18:27 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 18:18:27 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,045 s
19/01/24 18:18:27 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:18:27 INFO DAGScheduler: running: Set()
19/01/24 18:18:27 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 18:18:27 INFO DAGScheduler: failed: Set()
19/01/24 18:18:27 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 18:18:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:18:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:18:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53359 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:18:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:27 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 18:18:27 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:18:27 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 18:18:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:18:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:18:27 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/01/24 18:18:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 4 ms on localhost (executor driver) (1/1)
19/01/24 18:18:27 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 18:18:27 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,004 s
19/01/24 18:18:27 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,067940 s
19/01/24 18:18:27 INFO CodeGenerator: Code generated in 6.073617 ms
19/01/24 18:18:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz22`
WHERE (0 = 1)
19/01/24 18:18:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 18:18:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d84e5c5f26
19/01/24 18:18:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d84e5c5f26` AS `zzz23`
WHERE (0 = 1)
19/01/24 18:18:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d86fc8766e
19/01/24 18:18:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d86fc8766e` AS `zzz24`
WHERE (0 = 1)
19/01/24 18:18:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d84e5c5f26`
19/01/24 18:18:30 INFO CodeGenerator: Code generated in 26.858844 ms
19/01/24 18:18:30 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:18:30 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 18:18:30 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:18:30 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 18:18:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 18:18:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 18:18:30 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:18:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 18:18:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 18:18:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53359 (size: 13.0 KB, free: 364.5 MB)
19/01/24 18:18:30 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:30 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 18:18:30 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:18:30 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:18:30 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 18:18:30 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:18:30 INFO CodeGenerator: Code generated in 11.809184 ms
19/01/24 18:18:30 INFO CodeGenerator: Code generated in 12.856521 ms
19/01/24 18:18:30 INFO CodeGenerator: Code generated in 9.164215 ms
19/01/24 18:18:30 INFO CodeGenerator: Code generated in 10.228328 ms
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 122
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 124
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 116
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 119
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 121
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 123
19/01/24 18:18:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53359 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 114
19/01/24 18:18:31 INFO ContextCleaner: Cleaned shuffle 1
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 120
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 118
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 115
19/01/24 18:18:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53359 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 117
19/01/24 18:18:31 INFO ContextCleaner: Cleaned accumulator 113
19/01/24 18:18:31 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1951 bytes result sent to driver
19/01/24 18:18:31 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 764 ms on localhost (executor driver) (1/1)
19/01/24 18:18:31 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 18:18:31 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 0,764 s
19/01/24 18:18:31 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:18:31 INFO DAGScheduler: running: Set()
19/01/24 18:18:31 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 18:18:31 INFO DAGScheduler: failed: Set()
19/01/24 18:18:31 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:18:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 18:18:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 18:18:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53359 (size: 1887.0 B, free: 364.5 MB)
19/01/24 18:18:31 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:31 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 18:18:31 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:18:31 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 18:18:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:18:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:18:31 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 18:18:31 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:53359 (size: 686.3 KB, free: 363.8 MB)
19/01/24 18:18:31 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1787 bytes result sent to driver
19/01/24 18:18:31 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 86 ms on localhost (executor driver) (1/1)
19/01/24 18:18:31 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 18:18:31 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,086 s
19/01/24 18:18:31 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 0,884271 s
19/01/24 18:18:31 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:18:31 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 18:18:31 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:18:31 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 18:18:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 18:18:31 INFO DAGScheduler: Missing parents: List()
19/01/24 18:18:31 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:18:31 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.8 MB)
19/01/24 18:18:31 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.8 MB)
19/01/24 18:18:31 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53359 (size: 2.2 KB, free: 363.8 MB)
19/01/24 18:18:31 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:31 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 18:18:31 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:18:31 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 18:18:31 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 18:18:31 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 18:18:31 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 46 ms on localhost (executor driver) (1/1)
19/01/24 18:18:31 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 18:18:31 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,046 s
19/01/24 18:18:31 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,061810 s
19/01/24 18:18:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 18:18:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.6 MB)
19/01/24 18:18:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53359 (size: 89.8 KB, free: 363.7 MB)
19/01/24 18:18:31 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 18:18:31 INFO CodeGenerator: Code generated in 27.014195 ms
19/01/24 18:18:31 INFO Instrumentation: NaiveBayes-naive_bayes_57d81b782942-711064347-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 18:18:31 INFO Instrumentation: NaiveBayes-naive_bayes_57d81b782942-711064347-1: {"smoothing":1.0,"featuresCol":"vectorizer_output","modelType":"multinomial","labelCol":"Sentiment","predictionCol":"prediction","rawPredictionCol":"rawPrediction","probabilityCol":"probability"}
19/01/24 18:18:32 INFO CodeGenerator: Code generated in 20.083598 ms
19/01/24 18:18:32 INFO SparkContext: Starting job: head at NaiveBayes.scala:154
19/01/24 18:18:32 INFO DAGScheduler: Got job 5 (head at NaiveBayes.scala:154) with 1 output partitions
19/01/24 18:18:32 INFO DAGScheduler: Final stage: ResultStage 9 (head at NaiveBayes.scala:154)
19/01/24 18:18:32 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:18:32 INFO DAGScheduler: Missing parents: List()
19/01/24 18:18:32 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154), which has no missing parents
19/01/24 18:18:32 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 113.1 KB, free 362.4 MB)
19/01/24 18:18:32 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 72.9 KB, free 362.4 MB)
19/01/24 18:18:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53359 (size: 72.9 KB, free: 363.6 MB)
19/01/24 18:18:32 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:32 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 18:18:32 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:18:32 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:18:32 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 18:18:32 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:18:32 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 1743 bytes result sent to driver
19/01/24 18:18:32 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 53 ms on localhost (executor driver) (1/1)
19/01/24 18:18:32 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 18:18:32 INFO DAGScheduler: ResultStage 9 (head at NaiveBayes.scala:154) finished in 0,053 s
19/01/24 18:18:32 INFO DAGScheduler: Job 5 finished: head at NaiveBayes.scala:154, took 0,063216 s
19/01/24 18:18:32 INFO CodeGenerator: Code generated in 5.356306 ms
19/01/24 18:18:32 INFO Instrumentation: NaiveBayes-naive_bayes_57d81b782942-711064347-1: {"numFeatures":8098}
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 178
19/01/24 18:18:32 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53359 in memory (size: 72.9 KB, free: 363.7 MB)
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 261
19/01/24 18:18:32 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53359 in memory (size: 2.2 KB, free: 363.7 MB)
19/01/24 18:18:32 INFO CodeGenerator: Code generated in 27.535676 ms
19/01/24 18:18:32 INFO BlockManager: Removing RDD 30
19/01/24 18:18:32 INFO ContextCleaner: Cleaned RDD 30
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 174
19/01/24 18:18:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53359 in memory (size: 1887.0 B, free: 364.4 MB)
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 259
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 176
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 257
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 177
19/01/24 18:18:32 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53359 in memory (size: 13.0 KB, free: 364.4 MB)
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 258
19/01/24 18:18:32 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 175
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 262
19/01/24 18:18:32 INFO ContextCleaner: Cleaned accumulator 260
19/01/24 18:18:32 INFO SparkContext: Starting job: collect at NaiveBayes.scala:174
19/01/24 18:18:32 INFO DAGScheduler: Registering RDD 43 (map at NaiveBayes.scala:162)
19/01/24 18:18:32 INFO DAGScheduler: Got job 6 (collect at NaiveBayes.scala:174) with 1 output partitions
19/01/24 18:18:32 INFO DAGScheduler: Final stage: ResultStage 11 (collect at NaiveBayes.scala:174)
19/01/24 18:18:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/01/24 18:18:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/01/24 18:18:32 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162), which has no missing parents
19/01/24 18:18:32 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 243.7 KB, free 363.0 MB)
19/01/24 18:18:32 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 76.0 KB, free 363.0 MB)
19/01/24 18:18:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53359 (size: 76.0 KB, free: 364.3 MB)
19/01/24 18:18:32 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:32 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 18:18:32 WARN TaskSetManager: Stage 10 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:18:32 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:18:32 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 18:18:32 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:18:32 INFO CodeGenerator: Code generated in 6.650164 ms
19/01/24 18:18:32 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1951 bytes result sent to driver
19/01/24 18:18:32 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 428 ms on localhost (executor driver) (1/1)
19/01/24 18:18:32 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 18:18:32 INFO DAGScheduler: ShuffleMapStage 10 (map at NaiveBayes.scala:162) finished in 0,428 s
19/01/24 18:18:32 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:18:32 INFO DAGScheduler: running: Set()
19/01/24 18:18:32 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/01/24 18:18:32 INFO DAGScheduler: failed: Set()
19/01/24 18:18:32 INFO DAGScheduler: Submitting ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163), which has no missing parents
19/01/24 18:18:32 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 244.4 KB, free 362.7 MB)
19/01/24 18:18:32 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 76.4 KB, free 362.7 MB)
19/01/24 18:18:32 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53359 (size: 76.4 KB, free: 364.2 MB)
19/01/24 18:18:32 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/01/24 18:18:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:18:32 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 18:18:32 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:18:32 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 18:18:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:18:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:18:32 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 132406 bytes result sent to driver
19/01/24 18:18:32 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 13 ms on localhost (executor driver) (1/1)
19/01/24 18:18:32 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 18:18:32 INFO DAGScheduler: ResultStage 11 (collect at NaiveBayes.scala:174) finished in 0,014 s
19/01/24 18:18:32 INFO DAGScheduler: Job 6 finished: collect at NaiveBayes.scala:174, took 0,463343 s
19/01/24 18:18:32 INFO Instrumentation: NaiveBayes-naive_bayes_57d81b782942-711064347-1: {"numClasses":2}
19/01/24 18:18:32 INFO Instrumentation: NaiveBayes-naive_bayes_57d81b782942-711064347-1: training finished
19/01/24 18:18:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:18:56 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:18:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:18:56 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:18:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:18:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:18:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:18:56 INFO CodeGenerator: Code generated in 7.622381 ms
19/01/24 18:18:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:18:56 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:18:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:18:56 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:18:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:18:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:18:56 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:20:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 18:20:11 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d87c20a65
19/01/24 18:20:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d87c20a65` AS `zzz25`
WHERE (0 = 1)
19/01/24 18:20:11 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d81c8d49f6
19/01/24 18:20:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d81c8d49f6` AS `zzz26`
WHERE (0 = 1)
19/01/24 18:20:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d87c20a65`
19/01/24 18:20:13 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:20:13 INFO DAGScheduler: Registering RDD 50 (flatMap at CountVectorizer.scala:163)
19/01/24 18:20:13 INFO DAGScheduler: Got job 7 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:20:13 INFO DAGScheduler: Final stage: ResultStage 13 (count at CountVectorizer.scala:176)
19/01/24 18:20:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/01/24 18:20:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/01/24 18:20:13 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[50] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 28.5 KB, free 362.6 MB)
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KB, free 362.6 MB)
19/01/24 18:20:13 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53359 (size: 13.0 KB, free: 364.2 MB)
19/01/24 18:20:13 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 18:20:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[50] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:20:13 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 18:20:13 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:20:13 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:20:13 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 18:20:13 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:20:13 INFO CodeGenerator: Code generated in 14.124852 ms
19/01/24 18:20:13 INFO ContextCleaner: Cleaned shuffle 3
19/01/24 18:20:13 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53359 in memory (size: 76.0 KB, free: 364.3 MB)
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 291
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 254
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 292
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 251
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 256
19/01/24 18:20:13 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53359 in memory (size: 76.4 KB, free: 364.4 MB)
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 255
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 289
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 253
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 287
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 252
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 288
19/01/24 18:20:13 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:53359 in memory (size: 89.8 KB, free: 364.5 MB)
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 290
19/01/24 18:20:13 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 1951 bytes result sent to driver
19/01/24 18:20:13 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 292 ms on localhost (executor driver) (1/1)
19/01/24 18:20:13 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 18:20:13 INFO DAGScheduler: ShuffleMapStage 12 (flatMap at CountVectorizer.scala:163) finished in 0,293 s
19/01/24 18:20:13 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:20:13 INFO DAGScheduler: running: Set()
19/01/24 18:20:13 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/01/24 18:20:13 INFO DAGScheduler: failed: Set()
19/01/24 18:20:13 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[53] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 18:20:13 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53359 (size: 1887.0 B, free: 364.5 MB)
19/01/24 18:20:13 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/01/24 18:20:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[53] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:20:13 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 18:20:13 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:20:13 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 18:20:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:20:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:20:13 INFO MemoryStore: Block rdd_53_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 18:20:13 INFO BlockManagerInfo: Added rdd_53_0 in memory on 127.0.0.1:53359 (size: 686.3 KB, free: 363.8 MB)
19/01/24 18:20:13 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 1744 bytes result sent to driver
19/01/24 18:20:13 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 48 ms on localhost (executor driver) (1/1)
19/01/24 18:20:13 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 18:20:13 INFO DAGScheduler: ResultStage 13 (count at CountVectorizer.scala:176) finished in 0,049 s
19/01/24 18:20:13 INFO DAGScheduler: Job 7 finished: count at CountVectorizer.scala:176, took 0,357710 s
19/01/24 18:20:13 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:20:13 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 143 bytes
19/01/24 18:20:13 INFO DAGScheduler: Got job 8 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:20:13 INFO DAGScheduler: Final stage: ResultStage 15 (top at CountVectorizer.scala:179)
19/01/24 18:20:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/01/24 18:20:13 INFO DAGScheduler: Missing parents: List()
19/01/24 18:20:13 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 4.2 KB, free 363.8 MB)
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.8 MB)
19/01/24 18:20:13 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53359 (size: 2.2 KB, free: 363.8 MB)
19/01/24 18:20:13 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 18:20:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:20:13 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/01/24 18:20:13 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:20:13 INFO Executor: Running task 0.0 in stage 15.0 (TID 13)
19/01/24 18:20:13 INFO BlockManager: Found block rdd_53_0 locally
19/01/24 18:20:13 INFO Executor: Finished task 0.0 in stage 15.0 (TID 13). 174391 bytes result sent to driver
19/01/24 18:20:13 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 13) in 20 ms on localhost (executor driver) (1/1)
19/01/24 18:20:13 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 18:20:13 INFO DAGScheduler: ResultStage 15 (top at CountVectorizer.scala:179) finished in 0,021 s
19/01/24 18:20:13 INFO DAGScheduler: Job 8 finished: top at CountVectorizer.scala:179, took 0,027226 s
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.6 MB)
19/01/24 18:20:13 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53359 (size: 89.8 KB, free: 363.7 MB)
19/01/24 18:20:13 INFO SparkContext: Created broadcast 15 from broadcast at CountVectorizer.scala:244
19/01/24 18:20:13 INFO Instrumentation: NaiveBayes-naive_bayes_57d85ddfae4-81585665-2: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 18:20:13 INFO Instrumentation: NaiveBayes-naive_bayes_57d85ddfae4-81585665-2: {"smoothing":1.0,"featuresCol":"vectorizer_output","modelType":"multinomial","labelCol":"Sentiment","predictionCol":"prediction","rawPredictionCol":"rawPrediction","probabilityCol":"probability"}
19/01/24 18:20:13 INFO SparkContext: Starting job: head at NaiveBayes.scala:154
19/01/24 18:20:13 INFO DAGScheduler: Got job 9 (head at NaiveBayes.scala:154) with 1 output partitions
19/01/24 18:20:13 INFO DAGScheduler: Final stage: ResultStage 16 (head at NaiveBayes.scala:154)
19/01/24 18:20:13 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:20:13 INFO DAGScheduler: Missing parents: List()
19/01/24 18:20:13 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[61] at head at NaiveBayes.scala:154), which has no missing parents
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 113.1 KB, free 362.4 MB)
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 72.9 KB, free 362.4 MB)
19/01/24 18:20:13 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53359 (size: 72.9 KB, free: 363.6 MB)
19/01/24 18:20:13 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/01/24 18:20:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[61] at head at NaiveBayes.scala:154) (first 15 tasks are for partitions Vector(0))
19/01/24 18:20:13 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/01/24 18:20:13 WARN TaskSetManager: Stage 16 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:20:13 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:20:13 INFO Executor: Running task 0.0 in stage 16.0 (TID 14)
19/01/24 18:20:13 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:20:13 INFO Executor: Finished task 0.0 in stage 16.0 (TID 14). 1743 bytes result sent to driver
19/01/24 18:20:13 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 14) in 36 ms on localhost (executor driver) (1/1)
19/01/24 18:20:13 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/01/24 18:20:13 INFO DAGScheduler: ResultStage 16 (head at NaiveBayes.scala:154) finished in 0,036 s
19/01/24 18:20:13 INFO DAGScheduler: Job 9 finished: head at NaiveBayes.scala:154, took 0,045477 s
19/01/24 18:20:13 INFO Instrumentation: NaiveBayes-naive_bayes_57d85ddfae4-81585665-2: {"numFeatures":8098}
19/01/24 18:20:13 INFO SparkContext: Starting job: collect at NaiveBayes.scala:174
19/01/24 18:20:13 INFO DAGScheduler: Registering RDD 66 (map at NaiveBayes.scala:162)
19/01/24 18:20:13 INFO DAGScheduler: Got job 10 (collect at NaiveBayes.scala:174) with 1 output partitions
19/01/24 18:20:13 INFO DAGScheduler: Final stage: ResultStage 18 (collect at NaiveBayes.scala:174)
19/01/24 18:20:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/01/24 18:20:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/01/24 18:20:13 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[66] at map at NaiveBayes.scala:162), which has no missing parents
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 243.7 KB, free 362.1 MB)
19/01/24 18:20:13 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 76.0 KB, free 362.1 MB)
19/01/24 18:20:13 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53359 (size: 76.0 KB, free: 363.6 MB)
19/01/24 18:20:13 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/01/24 18:20:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[66] at map at NaiveBayes.scala:162) (first 15 tasks are for partitions Vector(0))
19/01/24 18:20:13 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/01/24 18:20:13 WARN TaskSetManager: Stage 17 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:20:13 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:20:13 INFO Executor: Running task 0.0 in stage 17.0 (TID 15)
19/01/24 18:20:13 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:20:13 INFO ContextCleaner: Cleaned shuffle 4
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 429
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 346
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 343
19/01/24 18:20:13 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53359 in memory (size: 2.2 KB, free: 363.6 MB)
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 344
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 345
19/01/24 18:20:13 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53359 in memory (size: 72.9 KB, free: 363.6 MB)
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 427
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 430
19/01/24 18:20:13 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53359 in memory (size: 1887.0 B, free: 363.6 MB)
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 428
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 425
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 342
19/01/24 18:20:13 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53359 in memory (size: 13.0 KB, free: 363.6 MB)
19/01/24 18:20:13 INFO BlockManager: Removing RDD 53
19/01/24 18:20:13 INFO ContextCleaner: Cleaned RDD 53
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 341
19/01/24 18:20:13 INFO ContextCleaner: Cleaned accumulator 426
19/01/24 18:20:14 INFO Executor: Finished task 0.0 in stage 17.0 (TID 15). 1951 bytes result sent to driver
19/01/24 18:20:14 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 15) in 330 ms on localhost (executor driver) (1/1)
19/01/24 18:20:14 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 18:20:14 INFO DAGScheduler: ShuffleMapStage 17 (map at NaiveBayes.scala:162) finished in 0,331 s
19/01/24 18:20:14 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:20:14 INFO DAGScheduler: running: Set()
19/01/24 18:20:14 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/01/24 18:20:14 INFO DAGScheduler: failed: Set()
19/01/24 18:20:14 INFO DAGScheduler: Submitting ResultStage 18 (ShuffledRDD[67] at aggregateByKey at NaiveBayes.scala:163), which has no missing parents
19/01/24 18:20:14 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 244.4 KB, free 362.7 MB)
19/01/24 18:20:14 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 76.4 KB, free 362.7 MB)
19/01/24 18:20:14 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53359 (size: 76.4 KB, free: 364.2 MB)
19/01/24 18:20:14 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/01/24 18:20:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (ShuffledRDD[67] at aggregateByKey at NaiveBayes.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:20:14 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/01/24 18:20:14 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 16, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:20:14 INFO Executor: Running task 0.0 in stage 18.0 (TID 16)
19/01/24 18:20:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:20:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:20:14 INFO Executor: Finished task 0.0 in stage 18.0 (TID 16). 132320 bytes result sent to driver
19/01/24 18:20:14 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 16) in 8 ms on localhost (executor driver) (1/1)
19/01/24 18:20:14 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/01/24 18:20:14 INFO DAGScheduler: ResultStage 18 (collect at NaiveBayes.scala:174) finished in 0,008 s
19/01/24 18:20:14 INFO DAGScheduler: Job 10 finished: collect at NaiveBayes.scala:174, took 0,356693 s
19/01/24 18:20:14 INFO Instrumentation: NaiveBayes-naive_bayes_57d85ddfae4-81585665-2: {"numClasses":2}
19/01/24 18:20:14 INFO Instrumentation: NaiveBayes-naive_bayes_57d85ddfae4-81585665-2: training finished
19/01/24 18:20:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d81c8d49f6`
19/01/24 18:20:46 INFO SparkSqlParser: Parsing command: sparklyr_tmp_57d84e1440ec
19/01/24 18:20:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d84e1440ec` AS `zzz27`
WHERE (0 = 1)
19/01/24 18:20:47 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d84e1440ec`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:20:47 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:20:47 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:20:47 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d84e1440ec`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:20:47 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:20:47 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:20:47 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d84e1440ec`
GROUP BY `Sentiment`, `Prediction`
LIMIT 11
19/01/24 18:20:47 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:20:47 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:20:47 INFO CodeGenerator: Code generated in 22.074344 ms
19/01/24 18:20:47 INFO CodeGenerator: Code generated in 46.940618 ms
19/01/24 18:20:47 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:20:47 INFO DAGScheduler: Registering RDD 70 (collect at utils.scala:200)
19/01/24 18:20:47 INFO DAGScheduler: Got job 11 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:20:47 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:200)
19/01/24 18:20:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
19/01/24 18:20:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
19/01/24 18:20:47 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[70] at collect at utils.scala:200), which has no missing parents
19/01/24 18:20:47 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 254.9 KB, free 362.4 MB)
19/01/24 18:20:48 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 115.8 KB, free 362.3 MB)
19/01/24 18:20:48 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53359 (size: 115.8 KB, free: 364.1 MB)
19/01/24 18:20:48 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/01/24 18:20:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[70] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:20:48 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/01/24 18:20:48 WARN TaskSetManager: Stage 19 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:20:48 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:20:48 INFO Executor: Running task 0.0 in stage 19.0 (TID 17)
19/01/24 18:20:48 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:20:48 INFO CodeGenerator: Code generated in 3.765606 ms
19/01/24 18:20:48 INFO CodeGenerator: Code generated in 4.778666 ms
19/01/24 18:20:48 INFO CodeGenerator: Code generated in 3.866256 ms
19/01/24 18:20:48 INFO CodeGenerator: Code generated in 7.273754 ms
19/01/24 18:20:48 INFO CodeGenerator: Code generated in 4.009572 ms
19/01/24 18:20:48 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/01/24 18:20:48 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 421
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 456
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 458
19/01/24 18:20:48 INFO ContextCleaner: Cleaned shuffle 5
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 419
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 460
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 457
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 422
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 455
19/01/24 18:20:48 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53359 in memory (size: 76.0 KB, free: 364.2 MB)
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 423
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 424
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 459
19/01/24 18:20:48 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53359 in memory (size: 76.4 KB, free: 364.3 MB)
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 420
19/01/24 18:20:48 INFO ContextCleaner: Cleaned accumulator 509
19/01/24 18:20:48 INFO Executor: Finished task 0.0 in stage 19.0 (TID 17). 2306 bytes result sent to driver
19/01/24 18:20:48 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 17) in 314 ms on localhost (executor driver) (1/1)
19/01/24 18:20:48 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/01/24 18:20:48 INFO DAGScheduler: ShuffleMapStage 19 (collect at utils.scala:200) finished in 0,314 s
19/01/24 18:20:48 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:20:48 INFO DAGScheduler: running: Set()
19/01/24 18:20:48 INFO DAGScheduler: waiting: Set(ResultStage 20)
19/01/24 18:20:48 INFO DAGScheduler: failed: Set()
19/01/24 18:20:48 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[73] at collect at utils.scala:200), which has no missing parents
19/01/24 18:20:48 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 236.1 KB, free 362.7 MB)
19/01/24 18:20:48 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 108.9 KB, free 362.6 MB)
19/01/24 18:20:48 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53359 (size: 108.9 KB, free: 364.2 MB)
19/01/24 18:20:48 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/01/24 18:20:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[73] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:20:48 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/01/24 18:20:48 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 18, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:20:48 INFO Executor: Running task 0.0 in stage 20.0 (TID 18)
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:20:48 INFO Executor: Finished task 0.0 in stage 20.0 (TID 18). 2584 bytes result sent to driver
19/01/24 18:20:48 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 18) in 9 ms on localhost (executor driver) (1/1)
19/01/24 18:20:48 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/01/24 18:20:48 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:200) finished in 0,010 s
19/01/24 18:20:48 INFO DAGScheduler: Job 11 finished: collect at utils.scala:200, took 0,341073 s
19/01/24 18:20:48 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:20:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 149 bytes
19/01/24 18:20:48 INFO DAGScheduler: Got job 12 (collect at utils.scala:200) with 4 output partitions
19/01/24 18:20:48 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:200)
19/01/24 18:20:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
19/01/24 18:20:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:20:48 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[73] at collect at utils.scala:200), which has no missing parents
19/01/24 18:20:48 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 236.1 KB, free 362.3 MB)
19/01/24 18:20:48 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 108.9 KB, free 362.2 MB)
19/01/24 18:20:48 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53359 (size: 108.9 KB, free: 364.1 MB)
19/01/24 18:20:48 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/01/24 18:20:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 22 (MapPartitionsRDD[73] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
19/01/24 18:20:48 INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks
19/01/24 18:20:48 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:20:48 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 20, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:20:48 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 21, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:20:48 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 22, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:20:48 INFO Executor: Running task 0.0 in stage 22.0 (TID 19)
19/01/24 18:20:48 INFO Executor: Running task 2.0 in stage 22.0 (TID 21)
19/01/24 18:20:48 INFO Executor: Running task 3.0 in stage 22.0 (TID 22)
19/01/24 18:20:48 INFO Executor: Running task 1.0 in stage 22.0 (TID 20)
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:20:48 INFO Executor: Finished task 2.0 in stage 22.0 (TID 21). 2558 bytes result sent to driver
19/01/24 18:20:48 INFO Executor: Finished task 0.0 in stage 22.0 (TID 19). 2558 bytes result sent to driver
19/01/24 18:20:48 INFO Executor: Finished task 3.0 in stage 22.0 (TID 22). 2601 bytes result sent to driver
19/01/24 18:20:48 INFO Executor: Finished task 1.0 in stage 22.0 (TID 20). 2558 bytes result sent to driver
19/01/24 18:20:48 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 21) in 12 ms on localhost (executor driver) (1/4)
19/01/24 18:20:48 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 22) in 12 ms on localhost (executor driver) (2/4)
19/01/24 18:20:48 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 19) in 13 ms on localhost (executor driver) (3/4)
19/01/24 18:20:48 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 20) in 13 ms on localhost (executor driver) (4/4)
19/01/24 18:20:48 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/01/24 18:20:48 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:200) finished in 0,014 s
19/01/24 18:20:48 INFO DAGScheduler: Job 12 finished: collect at utils.scala:200, took 0,020227 s
19/01/24 18:20:48 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:20:48 INFO DAGScheduler: Got job 13 (collect at utils.scala:200) with 3 output partitions
19/01/24 18:20:48 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:200)
19/01/24 18:20:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
19/01/24 18:20:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:20:48 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[73] at collect at utils.scala:200), which has no missing parents
19/01/24 18:20:48 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 236.1 KB, free 362.0 MB)
19/01/24 18:20:48 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 108.9 KB, free 361.9 MB)
19/01/24 18:20:48 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53359 (size: 108.9 KB, free: 364.0 MB)
19/01/24 18:20:48 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/01/24 18:20:48 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 24 (MapPartitionsRDD[73] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(5, 6, 7))
19/01/24 18:20:48 INFO TaskSchedulerImpl: Adding task set 24.0 with 3 tasks
19/01/24 18:20:48 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 23, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:20:48 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 5, ANY, 4726 bytes)
19/01/24 18:20:48 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 25, localhost, executor driver, partition 7, ANY, 4726 bytes)
19/01/24 18:20:48 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
19/01/24 18:20:48 INFO Executor: Running task 1.0 in stage 24.0 (TID 23)
19/01/24 18:20:48 INFO Executor: Running task 2.0 in stage 24.0 (TID 25)
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:20:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:20:48 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 2548 bytes result sent to driver
19/01/24 18:20:48 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 8 ms on localhost (executor driver) (1/3)
19/01/24 18:20:48 INFO Executor: Finished task 1.0 in stage 24.0 (TID 23). 2515 bytes result sent to driver
19/01/24 18:20:48 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 23) in 10 ms on localhost (executor driver) (2/3)
19/01/24 18:20:48 INFO Executor: Finished task 2.0 in stage 24.0 (TID 25). 2535 bytes result sent to driver
19/01/24 18:20:48 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 25) in 10 ms on localhost (executor driver) (3/3)
19/01/24 18:20:48 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/01/24 18:20:48 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:200) finished in 0,012 s
19/01/24 18:20:48 INFO DAGScheduler: Job 13 finished: collect at utils.scala:200, took 0,018097 s
19/01/24 18:20:48 INFO CodeGenerator: Code generated in 5.288477 ms
19/01/24 18:20:48 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_57d84e1440ec`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:20:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:20:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:21:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d87c20a65`
19/01/24 18:21:32 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:21:32 INFO DAGScheduler: Registering RDD 79 (flatMap at CountVectorizer.scala:163)
19/01/24 18:21:32 INFO DAGScheduler: Got job 14 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:21:32 INFO DAGScheduler: Final stage: ResultStage 26 (count at CountVectorizer.scala:176)
19/01/24 18:21:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
19/01/24 18:21:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
19/01/24 18:21:32 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[79] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:21:32 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 28.5 KB, free 361.9 MB)
19/01/24 18:21:32 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 13.0 KB, free 361.9 MB)
19/01/24 18:21:32 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53359 (size: 13.0 KB, free: 363.9 MB)
19/01/24 18:21:32 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[79] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:32 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/01/24 18:21:32 WARN TaskSetManager: Stage 25 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:32 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:21:32 INFO Executor: Running task 0.0 in stage 25.0 (TID 26)
19/01/24 18:21:32 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:21:32 INFO CodeGenerator: Code generated in 9.290026 ms
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 513
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 518
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 523
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 525
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 514
19/01/24 18:21:32 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:53359 in memory (size: 108.9 KB, free: 364.1 MB)
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 522
19/01/24 18:21:32 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53359 in memory (size: 108.9 KB, free: 364.2 MB)
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 510
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 521
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 515
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 517
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 524
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 516
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 520
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 519
19/01/24 18:21:32 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53359 in memory (size: 108.9 KB, free: 364.3 MB)
19/01/24 18:21:32 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53359 in memory (size: 115.8 KB, free: 364.4 MB)
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 512
19/01/24 18:21:32 INFO ContextCleaner: Cleaned shuffle 6
19/01/24 18:21:32 INFO ContextCleaner: Cleaned accumulator 511
19/01/24 18:21:32 INFO Executor: Finished task 0.0 in stage 25.0 (TID 26). 1908 bytes result sent to driver
19/01/24 18:21:32 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 26) in 308 ms on localhost (executor driver) (1/1)
19/01/24 18:21:32 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/01/24 18:21:32 INFO DAGScheduler: ShuffleMapStage 25 (flatMap at CountVectorizer.scala:163) finished in 0,308 s
19/01/24 18:21:32 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:21:32 INFO DAGScheduler: running: Set()
19/01/24 18:21:32 INFO DAGScheduler: waiting: Set(ResultStage 26)
19/01/24 18:21:32 INFO DAGScheduler: failed: Set()
19/01/24 18:21:32 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[82] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:21:32 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 3.2 KB, free 363.2 MB)
19/01/24 18:21:32 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1887.0 B, free 363.2 MB)
19/01/24 18:21:32 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53359 (size: 1887.0 B, free: 364.4 MB)
19/01/24 18:21:32 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[82] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:32 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/01/24 18:21:32 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 27, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:21:32 INFO Executor: Running task 0.0 in stage 26.0 (TID 27)
19/01/24 18:21:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:21:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:21:33 INFO MemoryStore: Block rdd_82_0 stored as values in memory (estimated size 686.3 KB, free 362.6 MB)
19/01/24 18:21:33 INFO BlockManagerInfo: Added rdd_82_0 in memory on 127.0.0.1:53359 (size: 686.3 KB, free: 363.7 MB)
19/01/24 18:21:33 INFO Executor: Finished task 0.0 in stage 26.0 (TID 27). 1787 bytes result sent to driver
19/01/24 18:21:33 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 27) in 50 ms on localhost (executor driver) (1/1)
19/01/24 18:21:33 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/01/24 18:21:33 INFO DAGScheduler: ResultStage 26 (count at CountVectorizer.scala:176) finished in 0,051 s
19/01/24 18:21:33 INFO DAGScheduler: Job 14 finished: count at CountVectorizer.scala:176, took 0,371870 s
19/01/24 18:21:33 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:21:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 143 bytes
19/01/24 18:21:33 INFO DAGScheduler: Got job 15 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:21:33 INFO DAGScheduler: Final stage: ResultStage 28 (top at CountVectorizer.scala:179)
19/01/24 18:21:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
19/01/24 18:21:33 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:33 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[83] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:21:33 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 4.2 KB, free 362.6 MB)
19/01/24 18:21:33 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 2.2 KB, free 362.6 MB)
19/01/24 18:21:33 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53359 (size: 2.2 KB, free: 363.7 MB)
19/01/24 18:21:33 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[83] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:33 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/01/24 18:21:33 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:21:33 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
19/01/24 18:21:33 INFO BlockManager: Found block rdd_82_0 locally
19/01/24 18:21:33 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 174348 bytes result sent to driver
19/01/24 18:21:33 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 14 ms on localhost (executor driver) (1/1)
19/01/24 18:21:33 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/01/24 18:21:33 INFO DAGScheduler: ResultStage 28 (top at CountVectorizer.scala:179) finished in 0,014 s
19/01/24 18:21:33 INFO DAGScheduler: Job 15 finished: top at CountVectorizer.scala:179, took 0,019127 s
19/01/24 18:21:33 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 1137.7 KB, free 361.4 MB)
19/01/24 18:21:33 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 89.8 KB, free 361.4 MB)
19/01/24 18:21:33 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53359 (size: 89.8 KB, free: 363.6 MB)
19/01/24 18:21:33 INFO SparkContext: Created broadcast 26 from broadcast at CountVectorizer.scala:244
19/01/24 18:21:33 INFO Instrumentation: NaiveBayes-naive_bayes_57d85ddfae4-1677564490-3: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 18:21:33 INFO Instrumentation: NaiveBayes-naive_bayes_57d85ddfae4-1677564490-3: {"smoothing":1.0,"featuresCol":"vectorizer_output","modelType":"multinomial","labelCol":"Sentiment","predictionCol":"prediction","rawPredictionCol":"rawPrediction","probabilityCol":"probability"}
19/01/24 18:21:33 INFO SparkContext: Starting job: head at NaiveBayes.scala:154
19/01/24 18:21:33 INFO DAGScheduler: Got job 16 (head at NaiveBayes.scala:154) with 1 output partitions
19/01/24 18:21:33 INFO DAGScheduler: Final stage: ResultStage 29 (head at NaiveBayes.scala:154)
19/01/24 18:21:33 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:33 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:33 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[90] at head at NaiveBayes.scala:154), which has no missing parents
19/01/24 18:21:33 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 113.1 KB, free 361.2 MB)
19/01/24 18:21:33 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 72.9 KB, free 361.2 MB)
19/01/24 18:21:33 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:53359 (size: 72.9 KB, free: 363.5 MB)
19/01/24 18:21:33 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[90] at head at NaiveBayes.scala:154) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:33 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/01/24 18:21:33 WARN TaskSetManager: Stage 29 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:33 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:33 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
19/01/24 18:21:33 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:21:33 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 1743 bytes result sent to driver
19/01/24 18:21:33 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:21:33 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/01/24 18:21:33 INFO DAGScheduler: ResultStage 29 (head at NaiveBayes.scala:154) finished in 0,032 s
19/01/24 18:21:33 INFO DAGScheduler: Job 16 finished: head at NaiveBayes.scala:154, took 0,038194 s
19/01/24 18:21:33 INFO Instrumentation: NaiveBayes-naive_bayes_57d85ddfae4-1677564490-3: {"numFeatures":8098}
19/01/24 18:21:33 INFO SparkContext: Starting job: collect at NaiveBayes.scala:174
19/01/24 18:21:33 INFO DAGScheduler: Registering RDD 95 (map at NaiveBayes.scala:162)
19/01/24 18:21:33 INFO DAGScheduler: Got job 17 (collect at NaiveBayes.scala:174) with 1 output partitions
19/01/24 18:21:33 INFO DAGScheduler: Final stage: ResultStage 31 (collect at NaiveBayes.scala:174)
19/01/24 18:21:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
19/01/24 18:21:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 30)
19/01/24 18:21:33 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[95] at map at NaiveBayes.scala:162), which has no missing parents
19/01/24 18:21:33 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 243.7 KB, free 360.9 MB)
19/01/24 18:21:33 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 76.0 KB, free 360.9 MB)
19/01/24 18:21:33 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:53359 (size: 76.0 KB, free: 363.5 MB)
19/01/24 18:21:33 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[95] at map at NaiveBayes.scala:162) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:33 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
19/01/24 18:21:33 WARN TaskSetManager: Stage 30 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:33 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:21:33 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
19/01/24 18:21:33 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 626
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 710
19/01/24 18:21:33 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:53359 in memory (size: 72.9 KB, free: 363.5 MB)
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 627
19/01/24 18:21:33 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:53359 in memory (size: 13.0 KB, free: 363.6 MB)
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 709
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 624
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 706
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 622
19/01/24 18:21:33 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:53359 in memory (size: 1887.0 B, free: 363.6 MB)
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 623
19/01/24 18:21:33 INFO ContextCleaner: Cleaned shuffle 7
19/01/24 18:21:33 INFO BlockManager: Removing RDD 82
19/01/24 18:21:33 INFO ContextCleaner: Cleaned RDD 82
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 707
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 708
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 711
19/01/24 18:21:33 INFO ContextCleaner: Cleaned accumulator 625
19/01/24 18:21:33 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:53359 in memory (size: 2.2 KB, free: 364.2 MB)
19/01/24 18:21:33 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 1908 bytes result sent to driver
19/01/24 18:21:33 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 215 ms on localhost (executor driver) (1/1)
19/01/24 18:21:33 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/01/24 18:21:33 INFO DAGScheduler: ShuffleMapStage 30 (map at NaiveBayes.scala:162) finished in 0,216 s
19/01/24 18:21:33 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:21:33 INFO DAGScheduler: running: Set()
19/01/24 18:21:33 INFO DAGScheduler: waiting: Set(ResultStage 31)
19/01/24 18:21:33 INFO DAGScheduler: failed: Set()
19/01/24 18:21:33 INFO DAGScheduler: Submitting ResultStage 31 (ShuffledRDD[96] at aggregateByKey at NaiveBayes.scala:163), which has no missing parents
19/01/24 18:21:33 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 244.4 KB, free 361.5 MB)
19/01/24 18:21:33 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 76.4 KB, free 361.5 MB)
19/01/24 18:21:33 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:53359 (size: 76.4 KB, free: 364.2 MB)
19/01/24 18:21:33 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (ShuffledRDD[96] at aggregateByKey at NaiveBayes.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:33 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/01/24 18:21:33 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:21:33 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
19/01/24 18:21:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:21:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:21:33 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 132363 bytes result sent to driver
19/01/24 18:21:33 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 6 ms on localhost (executor driver) (1/1)
19/01/24 18:21:33 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/01/24 18:21:33 INFO DAGScheduler: ResultStage 31 (collect at NaiveBayes.scala:174) finished in 0,007 s
19/01/24 18:21:33 INFO DAGScheduler: Job 17 finished: collect at NaiveBayes.scala:174, took 0,234842 s
19/01/24 18:21:33 INFO Instrumentation: NaiveBayes-naive_bayes_57d85ddfae4-1677564490-3: {"numClasses":2}
19/01/24 18:21:33 INFO Instrumentation: NaiveBayes-naive_bayes_57d85ddfae4-1677564490-3: training finished
19/01/24 18:21:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d87c20a65`
19/01/24 18:21:45 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:21:45 INFO DAGScheduler: Registering RDD 102 (flatMap at CountVectorizer.scala:163)
19/01/24 18:21:45 INFO DAGScheduler: Got job 18 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:21:45 INFO DAGScheduler: Final stage: ResultStage 33 (count at CountVectorizer.scala:176)
19/01/24 18:21:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
19/01/24 18:21:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
19/01/24 18:21:45 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[102] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:21:45 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 28.5 KB, free 361.4 MB)
19/01/24 18:21:45 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 13.0 KB, free 361.4 MB)
19/01/24 18:21:45 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:53359 (size: 13.0 KB, free: 364.1 MB)
19/01/24 18:21:45 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[102] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:45 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/01/24 18:21:45 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:53359 in memory (size: 76.4 KB, free: 364.2 MB)
19/01/24 18:21:45 WARN TaskSetManager: Stage 32 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:45 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:21:45 INFO Executor: Running task 0.0 in stage 32.0 (TID 32)
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 702
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 705
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 701
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 700
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 740
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 736
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 704
19/01/24 18:21:45 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:53359 in memory (size: 76.0 KB, free: 364.3 MB)
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 738
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 739
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 737
19/01/24 18:21:45 INFO ContextCleaner: Cleaned shuffle 8
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 703
19/01/24 18:21:45 INFO ContextCleaner: Cleaned accumulator 741
19/01/24 18:21:45 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:21:45 INFO CodeGenerator: Code generated in 6.909811 ms
19/01/24 18:21:45 INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 1908 bytes result sent to driver
19/01/24 18:21:45 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 230 ms on localhost (executor driver) (1/1)
19/01/24 18:21:45 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/01/24 18:21:45 INFO DAGScheduler: ShuffleMapStage 32 (flatMap at CountVectorizer.scala:163) finished in 0,230 s
19/01/24 18:21:45 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:21:45 INFO DAGScheduler: running: Set()
19/01/24 18:21:45 INFO DAGScheduler: waiting: Set(ResultStage 33)
19/01/24 18:21:45 INFO DAGScheduler: failed: Set()
19/01/24 18:21:45 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[105] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:21:45 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 3.2 KB, free 362.0 MB)
19/01/24 18:21:45 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 1887.0 B, free 362.0 MB)
19/01/24 18:21:45 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:53359 (size: 1887.0 B, free: 364.3 MB)
19/01/24 18:21:45 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[105] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:45 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/01/24 18:21:45 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:21:45 INFO Executor: Running task 0.0 in stage 33.0 (TID 33)
19/01/24 18:21:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:21:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:21:45 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:53359 in memory (size: 13.0 KB, free: 364.3 MB)
19/01/24 18:21:45 INFO MemoryStore: Block rdd_105_0 stored as values in memory (estimated size 686.3 KB, free 361.4 MB)
19/01/24 18:21:45 INFO BlockManagerInfo: Added rdd_105_0 in memory on 127.0.0.1:53359 (size: 686.3 KB, free: 363.6 MB)
19/01/24 18:21:45 INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 1830 bytes result sent to driver
19/01/24 18:21:45 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 52 ms on localhost (executor driver) (1/1)
19/01/24 18:21:45 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/01/24 18:21:45 INFO DAGScheduler: ResultStage 33 (count at CountVectorizer.scala:176) finished in 0,052 s
19/01/24 18:21:45 INFO DAGScheduler: Job 18 finished: count at CountVectorizer.scala:176, took 0,292642 s
19/01/24 18:21:45 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:21:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 143 bytes
19/01/24 18:21:45 INFO DAGScheduler: Got job 19 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:21:45 INFO DAGScheduler: Final stage: ResultStage 35 (top at CountVectorizer.scala:179)
19/01/24 18:21:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
19/01/24 18:21:45 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:45 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[106] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:21:45 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 4.2 KB, free 361.4 MB)
19/01/24 18:21:45 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 2.2 KB, free 361.4 MB)
19/01/24 18:21:45 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:53359 (size: 2.2 KB, free: 363.6 MB)
19/01/24 18:21:45 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[106] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:45 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/01/24 18:21:45 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:21:45 INFO Executor: Running task 0.0 in stage 35.0 (TID 34)
19/01/24 18:21:45 INFO BlockManager: Found block rdd_105_0 locally
19/01/24 18:21:45 INFO Executor: Finished task 0.0 in stage 35.0 (TID 34). 174434 bytes result sent to driver
19/01/24 18:21:45 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 34) in 13 ms on localhost (executor driver) (1/1)
19/01/24 18:21:45 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/01/24 18:21:45 INFO DAGScheduler: ResultStage 35 (top at CountVectorizer.scala:179) finished in 0,013 s
19/01/24 18:21:45 INFO DAGScheduler: Job 19 finished: top at CountVectorizer.scala:179, took 0,018418 s
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 1137.7 KB, free 360.3 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 89.8 KB, free 360.2 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:53359 (size: 89.8 KB, free: 363.5 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 33 from broadcast at CountVectorizer.scala:244
19/01/24 18:21:46 INFO Instrumentation: LogisticRegression-logistic_regression_57d867852d94-242328758-4: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
19/01/24 18:21:46 INFO Instrumentation: LogisticRegression-logistic_regression_57d867852d94-242328758-4: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
19/01/24 18:21:46 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:517
19/01/24 18:21:46 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:517) with 1 output partitions
19/01/24 18:21:46 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:517)
19/01/24 18:21:46 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:46 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:46 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[116] at treeAggregate at LogisticRegression.scala:517), which has no missing parents
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 116.1 KB, free 360.1 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 74.7 KB, free 360.0 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:53359 (size: 74.7 KB, free: 363.5 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[116] at treeAggregate at LogisticRegression.scala:517) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:46 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/01/24 18:21:46 WARN TaskSetManager: Stage 36 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:46 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:46 INFO Executor: Running task 0.0 in stage 36.0 (TID 35)
19/01/24 18:21:46 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:21:46 INFO ContextCleaner: Cleaned shuffle 9
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:53359 in memory (size: 1887.0 B, free: 363.5 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:53359 in memory (size: 2.2 KB, free: 363.5 MB)
19/01/24 18:21:46 INFO ContextCleaner: Cleaned accumulator 791
19/01/24 18:21:46 INFO ContextCleaner: Cleaned accumulator 792
19/01/24 18:21:46 INFO ContextCleaner: Cleaned accumulator 794
19/01/24 18:21:46 INFO ContextCleaner: Cleaned accumulator 795
19/01/24 18:21:46 INFO BlockManager: Removing RDD 105
19/01/24 18:21:46 INFO ContextCleaner: Cleaned RDD 105
19/01/24 18:21:46 INFO ContextCleaner: Cleaned accumulator 793
19/01/24 18:21:46 INFO ContextCleaner: Cleaned accumulator 790
19/01/24 18:21:46 INFO MemoryStore: Block rdd_115_0 stored as values in memory (estimated size 2.5 MB, free 358.2 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added rdd_115_0 in memory on 127.0.0.1:53359 (size: 2.5 MB, free: 361.6 MB)
19/01/24 18:21:46 INFO Executor: Finished task 0.0 in stage 36.0 (TID 35). 524154 bytes result sent to driver
19/01/24 18:21:46 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 35) in 269 ms on localhost (executor driver) (1/1)
19/01/24 18:21:46 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/01/24 18:21:46 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:517) finished in 0,269 s
19/01/24 18:21:46 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:517, took 0,298273 s
19/01/24 18:21:46 INFO Instrumentation: LogisticRegression-logistic_regression_57d867852d94-242328758-4: {"numClasses":2}
19/01/24 18:21:46 INFO Instrumentation: LogisticRegression-logistic_regression_57d867852d94-242328758-4: {"numFeatures":8098}
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 63.3 KB, free 358.1 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 7.7 KB, free 358.1 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:53359 (size: 7.7 KB, free: 361.6 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 35 from broadcast at LogisticRegression.scala:600
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 439.0 B, free 358.0 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:53359 (size: 439.0 B, free: 361.6 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 36 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:46 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:46 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:46 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:46 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:46 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:46 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[117] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 74.7 KB, free 357.8 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:53359 (size: 74.7 KB, free: 361.5 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[117] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:46 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/01/24 18:21:46 WARN TaskSetManager: Stage 37 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:46 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:46 INFO Executor: Running task 0.0 in stage 37.0 (TID 36)
19/01/24 18:21:46 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:46 INFO Executor: Finished task 0.0 in stage 37.0 (TID 36). 68236 bytes result sent to driver
19/01/24 18:21:46 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 36) in 45 ms on localhost (executor driver) (1/1)
19/01/24 18:21:46 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/01/24 18:21:46 INFO DAGScheduler: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892) finished in 0,046 s
19/01/24 18:21:46 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1892, took 0,051131 s
19/01/24 18:21:46 INFO TorrentBroadcast: Destroying Broadcast(36) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:53359 in memory (size: 439.0 B, free: 361.5 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 23.5 KB, free 357.8 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:53359 (size: 23.5 KB, free: 361.5 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 38 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:46 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:46 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:46 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:46 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:46 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:46 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[118] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 74.7 KB, free 357.6 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:53359 (size: 74.7 KB, free: 361.4 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[118] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:46 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/01/24 18:21:46 WARN TaskSetManager: Stage 38 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:46 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:46 INFO Executor: Running task 0.0 in stage 38.0 (TID 37)
19/01/24 18:21:46 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:46 INFO Executor: Finished task 0.0 in stage 38.0 (TID 37). 68193 bytes result sent to driver
19/01/24 18:21:46 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 37) in 29 ms on localhost (executor driver) (1/1)
19/01/24 18:21:46 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/01/24 18:21:46 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 18:21:46 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035596 s
19/01/24 18:21:46 INFO TorrentBroadcast: Destroying Broadcast(38) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:53359 in memory (size: 23.5 KB, free: 361.4 MB)
19/01/24 18:21:46 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:46 INFO LBFGS: Val and Grad Norm: 0,330456 (rel: 0,523) 0,367278
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 57.6 KB, free 357.6 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:53359 (size: 57.6 KB, free: 361.4 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 40 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:46 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:46 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:46 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:46 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:46 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:46 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[119] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 74.7 KB, free 357.4 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:53359 (size: 74.7 KB, free: 361.3 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[119] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:46 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/01/24 18:21:46 WARN TaskSetManager: Stage 39 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:46 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:46 INFO Executor: Running task 0.0 in stage 39.0 (TID 38)
19/01/24 18:21:46 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:46 INFO Executor: Finished task 0.0 in stage 39.0 (TID 38). 68193 bytes result sent to driver
19/01/24 18:21:46 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 38) in 27 ms on localhost (executor driver) (1/1)
19/01/24 18:21:46 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/01/24 18:21:46 INFO DAGScheduler: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 18:21:46 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033535 s
19/01/24 18:21:46 INFO TorrentBroadcast: Destroying Broadcast(40) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:53359 in memory (size: 57.6 KB, free: 361.4 MB)
19/01/24 18:21:46 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:46 INFO LBFGS: Val and Grad Norm: 0,213198 (rel: 0,355) 0,167363
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.4 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 42 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:46 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:46 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:46 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:46 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:46 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:46 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[120] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 74.7 KB, free 357.2 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:53359 (size: 74.7 KB, free: 361.2 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[120] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:46 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:53359 in memory (size: 74.7 KB, free: 361.3 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:53359 in memory (size: 74.7 KB, free: 361.4 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:53359 in memory (size: 74.7 KB, free: 361.5 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:53359 in memory (size: 74.7 KB, free: 361.5 MB)
19/01/24 18:21:46 WARN TaskSetManager: Stage 40 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:46 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:46 INFO Executor: Running task 0.0 in stage 40.0 (TID 39)
19/01/24 18:21:46 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:46 INFO Executor: Finished task 0.0 in stage 40.0 (TID 39). 68193 bytes result sent to driver
19/01/24 18:21:46 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 39) in 42 ms on localhost (executor driver) (1/1)
19/01/24 18:21:46 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/01/24 18:21:46 INFO DAGScheduler: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892) finished in 0,042 s
19/01/24 18:21:46 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1892, took 0,047563 s
19/01/24 18:21:46 INFO TorrentBroadcast: Destroying Broadcast(42) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:21:46 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:46 INFO LBFGS: Val and Grad Norm: 0,147331 (rel: 0,309) 0,0949852
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.0 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 44 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:46 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:46 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:46 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:46 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:46 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:46 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[121] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:46 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 74.7 KB, free 357.8 MB)
19/01/24 18:21:46 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:53359 (size: 74.7 KB, free: 361.5 MB)
19/01/24 18:21:46 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[121] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:46 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/01/24 18:21:46 WARN TaskSetManager: Stage 41 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:46 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:46 INFO Executor: Running task 0.0 in stage 41.0 (TID 40)
19/01/24 18:21:46 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:46 INFO Executor: Finished task 0.0 in stage 41.0 (TID 40). 68236 bytes result sent to driver
19/01/24 18:21:46 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 40) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:46 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/01/24 18:21:46 INFO DAGScheduler: ResultStage 41 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:46 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1892, took 0,050495 s
19/01/24 18:21:46 INFO TorrentBroadcast: Destroying Broadcast(44) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:46 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:46 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:46 INFO LBFGS: Val and Grad Norm: 0,100491 (rel: 0,318) 0,0613800
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 57.7 KB, free 357.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:53359 (size: 57.7 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 46 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[122] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 74.7 KB, free 357.6 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:53359 (size: 74.7 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[122] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 42 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 42.0 (TID 41)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 42.0 (TID 41). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 41) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 42 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:21:47 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030551 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(46) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:53359 in memory (size: 57.7 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0724526 (rel: 0,279) 0,0316812
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.6 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 48 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 43 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[123] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 74.7 KB, free 357.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:53359 (size: 74.7 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[123] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 43 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 43.0 (TID 42)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 43.0 (TID 42). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 42) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 43 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:21:47 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030535 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(48) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0587020 (rel: 0,190) 0,0233276
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 50 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 44 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[124] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[124] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 44 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 44.0 (TID 43)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 44.0 (TID 43). 68236 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 43) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 44 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:47 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028312 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(50) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0508755 (rel: 0,133) 0,0191974
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 52 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 45 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[125] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[125] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 45 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 45.0 (TID 44)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 45.0 (TID 44). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 44) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 45 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:47 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026376 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(52) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0492985 (rel: 0,0310) 0,0273011
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.0 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 54 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 30 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 46 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[126] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[126] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 46 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 46.0 (TID 45)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 46.0 (TID 45). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 45) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 46 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:47 INFO DAGScheduler: Job 30 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027267 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(54) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0448300 (rel: 0,0906) 0,0186364
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 57.5 KB, free 356.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 56 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 31 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 47 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[127] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[127] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 47 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 47.0 (TID 46)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:53359 in memory (size: 74.7 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:53359 in memory (size: 74.7 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:53359 in memory (size: 74.7 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:53359 in memory (size: 74.7 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 47.0 (TID 46). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 46) in 33 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 47 (treeAggregate at LogisticRegression.scala:1892) finished in 0,034 s
19/01/24 18:21:47 INFO DAGScheduler: Job 31 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038523 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0396473 (rel: 0,116) 0,0195072
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.0 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 58 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 32 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 48 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[128] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[128] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 48 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 48.0 (TID 47)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 48.0 (TID 47). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 47) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 48 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:47 INFO DAGScheduler: Job 32 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026416 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(58) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 60 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 33 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 49 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[129] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[129] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 49 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 49.0 (TID 48)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 49.0 (TID 48). 68236 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 48) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 49 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:47 INFO DAGScheduler: Job 33 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026711 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(60) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO StrongWolfeLineSearch: Line search t: 0.32886824614418664 fval: 0.03927381963744339 rhs: 0.03964717451086121 cdd: 6.991968417275898E-4
19/01/24 18:21:47 INFO LBFGS: Step Size: 0,3289
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0392738 (rel: 0,00942) 0,0181790
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.6 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 62 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 34 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 50 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[130] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[130] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 50 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 50.0 (TID 49)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 50.0 (TID 49). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 49) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 50 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:47 INFO DAGScheduler: Job 34 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026650 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(62) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0379879 (rel: 0,0327) 0,0145010
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 57.6 KB, free 357.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:53359 (size: 57.6 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 64 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 35 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 51 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[131] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[131] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 51 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 51.0 (TID 50)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 51.0 (TID 50). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 50) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 51 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:47 INFO DAGScheduler: Job 35 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026188 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(64) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:53359 in memory (size: 57.6 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0369358 (rel: 0,0277) 0,0191350
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 66 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 36 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 52 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[132] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[132] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 52 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 52.0 (TID 51)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 52.0 (TID 51). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 51) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 52 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:21:47 INFO DAGScheduler: Job 36 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036771 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(66) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0363885 (rel: 0,0148) 0,0167591
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.0 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 68 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 37 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 53 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[133] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[133] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 53 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 53.0 (TID 52)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 53.0 (TID 52). 68236 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 52) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 53 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:47 INFO DAGScheduler: Job 37 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027407 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(68) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 57.5 KB, free 356.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 70 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 38 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 54 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[134] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[134] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 54 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 54.0 (TID 53)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 54.0 (TID 53). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 53) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 54 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:47 INFO DAGScheduler: Job 38 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026920 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(70) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO StrongWolfeLineSearch: Line search t: 0.4108013193598613 fval: 0.03594493422285328 rhs: 0.03638839827048342 cdd: 3.814229000619686E-4
19/01/24 18:21:47 INFO LBFGS: Step Size: 0,4108
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0359449 (rel: 0,0122) 0,0135038
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 63.3 KB, free 356.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.7 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 72 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 39 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 55 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[135] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 116.3 KB, free 356.5 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.5 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[135] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:47 WARN TaskSetManager: Stage 55 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 55.0 (TID 54)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 55.0 (TID 54). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 54) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 55 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:21:47 INFO DAGScheduler: Job 39 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038562 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(72) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0357242 (rel: 0,00614) 0,00639451
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.0 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 74 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 40 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 56 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[136] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[136] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 56 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 56.0 (TID 55)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 56.0 (TID 55). 68236 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 55) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 56 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:21:47 INFO DAGScheduler: Job 40 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030448 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(74) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0353285 (rel: 0,0111) 0,00918555
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 76 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 41 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 57 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[137] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[137] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 57 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 57.0 (TID 56)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 57.0 (TID 56). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 56) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 57 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:47 INFO DAGScheduler: Job 41 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026985 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(76) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0349337 (rel: 0,0112) 0,00751039
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.6 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 78 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 42 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 58 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[138] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[138] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 58 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 58.0 (TID 57)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 58.0 (TID 57). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 57) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 58 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:47 INFO DAGScheduler: Job 42 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026766 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(78) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 80 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 43 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 59 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[139] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[139] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 59 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 59.0 (TID 58)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 59.0 (TID 58). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 58) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 59 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:21:47 INFO DAGScheduler: Job 43 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030969 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(80) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO StrongWolfeLineSearch: Line search t: 0.17279326617073676 fval: 0.03482345995373003 rhs: 0.03493363733470484 cdd: 9.033313740993744E-4
19/01/24 18:21:47 INFO LBFGS: Step Size: 0,1728
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0348235 (rel: 0,00315) 0,0355699
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 82 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 44 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 60 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[140] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[140] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 60 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 60.0 (TID 59)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 60.0 (TID 59). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 59) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 60 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:47 INFO DAGScheduler: Job 44 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027965 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(82) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0341632 (rel: 0,0190) 0,00651399
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.0 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 84 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 45 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 61 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[141] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[141] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 61 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 61.0 (TID 60)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 61.0 (TID 60). 68236 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 60) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 61 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:47 INFO DAGScheduler: Job 45 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028476 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(84) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0339435 (rel: 0,00643) 0,00558368
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 57.5 KB, free 356.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 86 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 46 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 62 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[142] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[142] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 62 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 62.0 (TID 61)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 62.0 (TID 61). 68236 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 61) in 34 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 62 (treeAggregate at LogisticRegression.scala:1892) finished in 0,034 s
19/01/24 18:21:47 INFO DAGScheduler: Job 46 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038446 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(86) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0334690 (rel: 0,0140) 0,00643648
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.0 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 88 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 47 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 63 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[143] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[143] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 63 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 63.0 (TID 62)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 63.0 (TID 62). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 62) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 63 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:47 INFO DAGScheduler: Job 47 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026283 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(88) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0326367 (rel: 0,0249) 0,0142538
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.8 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 90 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 48 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 64 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[144] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[144] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 64 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 64.0 (TID 63)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 64.0 (TID 63). 68236 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 63) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 64 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:47 INFO DAGScheduler: Job 48 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027064 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(90) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0322304 (rel: 0,0124) 0,00481859
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.6 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 92 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 49 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 65 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[145] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[145] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 65 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 65.0 (TID 64)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 65.0 (TID 64). 68236 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 64) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 65 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:47 INFO DAGScheduler: Job 49 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026681 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(92) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0320398 (rel: 0,00592) 0,00458256
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.4 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 94 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 50 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 66 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[146] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[146] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
19/01/24 18:21:47 WARN TaskSetManager: Stage 66 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:47 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:47 INFO Executor: Running task 0.0 in stage 66.0 (TID 65)
19/01/24 18:21:47 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:47 INFO Executor: Finished task 0.0 in stage 66.0 (TID 65). 68193 bytes result sent to driver
19/01/24 18:21:47 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 65) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:47 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
19/01/24 18:21:47 INFO DAGScheduler: ResultStage 66 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:47 INFO DAGScheduler: Job 50 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027223 s
19/01/24 18:21:47 INFO TorrentBroadcast: Destroying Broadcast(94) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:47 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:47 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:47 INFO LBFGS: Val and Grad Norm: 0,0317947 (rel: 0,00765) 0,0150047
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 57.3 KB, free 357.2 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 96 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:47 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:47 INFO DAGScheduler: Got job 51 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:47 INFO DAGScheduler: Final stage: ResultStage 67 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:47 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:47 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:47 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[147] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:47 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:47 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:47 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[147] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:47 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 67 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 67.0 (TID 66)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 67.0 (TID 66). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 66) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 67 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:48 INFO DAGScheduler: Job 51 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026873 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(96) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0315248 (rel: 0,00849) 0,00508445
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 98 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 52 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 68 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[148] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[148] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 68 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 68.0 (TID 67)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 68.0 (TID 67). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 67) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 68 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:48 INFO DAGScheduler: Job 52 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028472 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(98) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0314268 (rel: 0,00311) 0,00583252
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 100 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 53 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 69 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[149] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[149] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 69 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 69.0 (TID 68)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 69.0 (TID 68). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 68) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 69 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:48 INFO DAGScheduler: Job 53 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027744 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(100) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0312075 (rel: 0,00698) 0,00464233
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 63.3 KB, free 356.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.7 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 102 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 54 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 70 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[150] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 116.3 KB, free 356.5 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.5 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[150] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 WARN TaskSetManager: Stage 70 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 70.0 (TID 69)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 70.0 (TID 69). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 69) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 70 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:21:48 INFO DAGScheduler: Job 54 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038240 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(102) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0309571 (rel: 0,00802) 0,00454268
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 57.3 KB, free 358.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 104 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 55 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 71 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[151] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[151] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 71 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 71.0 (TID 70)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 71.0 (TID 70). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 70) in 20 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 71 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:48 INFO DAGScheduler: Job 55 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025401 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(104) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0307409 (rel: 0,00698) 0,00503477
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 106 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 56 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 72 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[152] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[152] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 72 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 72.0 (TID 71)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 72.0 (TID 71). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 71) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 72 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:48 INFO DAGScheduler: Job 56 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026920 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(106) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0304751 (rel: 0,00864) 0,00428555
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.6 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 108 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 57 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 73 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[153] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[153] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 73 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 73.0 (TID 72)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 73.0 (TID 72). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 72) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 73 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:48 INFO DAGScheduler: Job 57 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028504 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(108) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0302014 (rel: 0,00898) 0,00396539
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 57.3 KB, free 357.4 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 110 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 58 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 74 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[154] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[154] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 74 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 74.0 (TID 73)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 74.0 (TID 73). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 73) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 74 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:48 INFO DAGScheduler: Job 58 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027957 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(110) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0298543 (rel: 0,0115) 0,00537635
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 112 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 59 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 75 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[155] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[155] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 75 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 75.0 (TID 74)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 75.0 (TID 74). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 74) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 75 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:48 INFO DAGScheduler: Job 59 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028199 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(112) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0296887 (rel: 0,00554) 0,0116162
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 114 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 60 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 76 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[156] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[156] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 76 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 76.0 (TID 75)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 76.0 (TID 75). 68236 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 75) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 76 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:48 INFO DAGScheduler: Job 60 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028331 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(114) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0295122 (rel: 0,00595) 0,00539889
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 116 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 61 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 77 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[157] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[157] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 77 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 77.0 (TID 76)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 77.0 (TID 76). 68236 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 76) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 77 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 18:21:48 INFO DAGScheduler: Job 61 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035093 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(116) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0294075 (rel: 0,00355) 0,00319102
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 118 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 62 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 78 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[158] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[158] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 78 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 78.0 (TID 77)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 78.0 (TID 77). 68150 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 77) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 78 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:48 INFO DAGScheduler: Job 62 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026528 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(118) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0293339 (rel: 0,00250) 0,00352100
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 120 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 63 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 79 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[159] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[159] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 79 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 79.0 (TID 78)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 79.0 (TID 78). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 78) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 79 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:48 INFO DAGScheduler: Job 63 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037558 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(120) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0292944 (rel: 0,00135) 0,0111846
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.6 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 122 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 64 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 80 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[160] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[160] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 80 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 80.0 (TID 79)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 80.0 (TID 79). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 79) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 80 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:48 INFO DAGScheduler: Job 64 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026208 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(122) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0292388 (rel: 0,00190) 0,00613614
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.4 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 124 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 65 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 81 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[161] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[161] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 81 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 81.0 (TID 80)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 81.0 (TID 80). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 80) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 81 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:21:48 INFO DAGScheduler: Job 65 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029988 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(124) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0291668 (rel: 0,00246) 0,00573039
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 126 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 66 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 82 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[162] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[162] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 82 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 82.0 (TID 81)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 82.0 (TID 81). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 81) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 82 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:48 INFO DAGScheduler: Job 66 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026659 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(126) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0291146 (rel: 0,00179) 0,00597272
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 128 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 67 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 83 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[163] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[163] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 83 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 83.0 (TID 82)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 83.0 (TID 82). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 82) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 83 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:48 INFO DAGScheduler: Job 67 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025814 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(128) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0289667 (rel: 0,00508) 0,00414288
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 57.3 KB, free 356.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 130 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 68 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 84 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[164] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[164] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 84 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 84.0 (TID 83)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 84.0 (TID 83). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 83) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 84 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:48 INFO DAGScheduler: Job 68 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027175 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(130) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0288259 (rel: 0,00486) 0,00436637
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 63.3 KB, free 356.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.7 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 132 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 69 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 85 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[165] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 116.3 KB, free 356.5 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.5 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[165] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 WARN TaskSetManager: Stage 85 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 85.0 (TID 84)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 85.0 (TID 84). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 84) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 85 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 18:21:48 INFO DAGScheduler: Job 69 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038835 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(132) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0287244 (rel: 0,00352) 0,00223707
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 134 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 70 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 86 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[166] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[166] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 86 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 86.0 (TID 85)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 86.0 (TID 85). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 85) in 20 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 86 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:48 INFO DAGScheduler: Job 70 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025878 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(134) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0286589 (rel: 0,00228) 0,00213336
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 57.3 KB, free 357.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 136 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 71 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 87 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[167] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[167] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 87 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 87.0 (TID 86)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 87.0 (TID 86). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 86) in 20 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 87 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:48 INFO DAGScheduler: Job 71 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026244 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(136) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0285803 (rel: 0,00274) 0,00415048
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 57.3 KB, free 357.6 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 138 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 72 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 88 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[168] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[168] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 88 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 88.0 (TID 87)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 88.0 (TID 87). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 87) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 88 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:48 INFO DAGScheduler: Job 72 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027008 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(138) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.4 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 140 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 73 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 89 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[169] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[169] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 89 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 89.0 (TID 88)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 89.0 (TID 88). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 88) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 89 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:48 INFO DAGScheduler: Job 73 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028353 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(140) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO StrongWolfeLineSearch: Line search t: 0.4267145302663191 fval: 0.02848748920414812 rhs: 0.028580243313891446 cdd: 5.6037400286210854E-8
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO LBFGS: Step Size: 0,4267
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0284875 (rel: 0,00325) 0,00586295
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 142 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 74 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 90 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[170] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[170] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 90 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 90.0 (TID 89)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 90.0 (TID 89). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 89) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 90 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:48 INFO DAGScheduler: Job 74 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026695 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(142) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0283739 (rel: 0,00399) 0,00531647
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 144 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 75 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 91 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[171] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[171] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 91 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 91.0 (TID 90)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 91.0 (TID 90). 68193 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 90) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 91 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:48 INFO DAGScheduler: Job 75 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026845 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(144) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0282870 (rel: 0,00306) 0,00553462
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 146 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 76 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 92 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[172] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[172] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 92 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 92.0 (TID 91)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:48 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO Executor: Finished task 0.0 in stage 92.0 (TID 91). 68279 bytes result sent to driver
19/01/24 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 91) in 34 ms on localhost (executor driver) (1/1)
19/01/24 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
19/01/24 18:21:48 INFO DAGScheduler: ResultStage 92 (treeAggregate at LogisticRegression.scala:1892) finished in 0,034 s
19/01/24 18:21:48 INFO DAGScheduler: Job 76 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039928 s
19/01/24 18:21:48 INFO TorrentBroadcast: Destroying Broadcast(146) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:48 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:48 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:21:48 INFO LBFGS: Val and Grad Norm: 0,0282548 (rel: 0,00114) 0,00397435
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.0 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 148 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:48 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:48 INFO DAGScheduler: Got job 77 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:48 INFO DAGScheduler: Final stage: ResultStage 93 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:48 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[173] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:48 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:48 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:48 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[173] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:48 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
19/01/24 18:21:48 WARN TaskSetManager: Stage 93 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:48 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:48 INFO Executor: Running task 0.0 in stage 93.0 (TID 92)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 93.0 (TID 92). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 92) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 93 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:49 INFO DAGScheduler: Job 77 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027551 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(148) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0282183 (rel: 0,00129) 0,00289874
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 150 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 78 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 94 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[174] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[174] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 94 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 94.0 (TID 93)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 94.0 (TID 93). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 93) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 94 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:49 INFO DAGScheduler: Job 78 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026104 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(150) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0281719 (rel: 0,00164) 0,00445034
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.6 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 152 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 79 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 95 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[175] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[175] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 95 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 95.0 (TID 94)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 95.0 (TID 94). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 94) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 95 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:49 INFO DAGScheduler: Job 79 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026945 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(152) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0281092 (rel: 0,00223) 0,00521472
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 57.3 KB, free 357.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 154 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 80 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 96 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[176] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[176] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 96 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 96.0 (TID 95)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 96.0 (TID 95). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 95) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 96 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:21:49 INFO DAGScheduler: Job 80 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029293 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(154) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0280739 (rel: 0,00125) 0,00627099
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 57.3 KB, free 357.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 156 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 81 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 97 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[177] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[177] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 97 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 97.0 (TID 96)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 97.0 (TID 96). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 96) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 97 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:49 INFO DAGScheduler: Job 81 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028392 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(156) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0280154 (rel: 0,00208) 0,00209270
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.0 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 158 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 82 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 98 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[178] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[178] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 98 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 98.0 (TID 97)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 98.0 (TID 97). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 97) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 98 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:49 INFO DAGScheduler: Job 82 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026081 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(158) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0279933 (rel: 0,000787) 0,00174697
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 160 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 83 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 99 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[179] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[179] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 99 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 99.0 (TID 98)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 99.0 (TID 98). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 98) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 99 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:21:49 INFO DAGScheduler: Job 83 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029206 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(160) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0279381 (rel: 0,00197) 0,00168608
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 63.3 KB, free 356.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.7 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 162 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 84 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 100 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[180] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 116.3 KB, free 356.5 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.5 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[180] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:49 WARN TaskSetManager: Stage 100 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 100.0 (TID 99)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 100.0 (TID 99). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 99) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 100 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:21:49 INFO DAGScheduler: Job 84 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035433 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(162) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0278585 (rel: 0,00285) 0,00163783
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.0 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 164 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 85 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 101 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[181] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[181] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 101 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 101.0 (TID 100)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 101.0 (TID 100). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 100) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 101 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:49 INFO DAGScheduler: Job 85 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027560 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(164) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0277578 (rel: 0,00361) 0,00180832
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 166 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 86 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 102 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[182] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[182] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 102 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 102.0 (TID 101)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 102.0 (TID 101). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 101) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 102 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 18:21:49 INFO DAGScheduler: Job 86 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034035 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(166) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.6 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 168 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 87 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 103 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[183] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[183] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 103 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 103.0 (TID 102)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 103.0 (TID 102). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 102) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 103 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:21:49 INFO DAGScheduler: Job 87 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030130 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(168) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO StrongWolfeLineSearch: Line search t: 0.1 fval: 0.027738693432296787 rhs: 0.027757797712281675 cdd: -5.903516402336295E-6
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO LBFGS: Step Size: 0,1000
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0277387 (rel: 0,000688) 0,00422118
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 170 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 88 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 104 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[184] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[184] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 104 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 104.0 (TID 103)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 104.0 (TID 103). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 103) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 104 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:49 INFO DAGScheduler: Job 88 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028229 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(170) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0276637 (rel: 0,00270) 0,00155316
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 172 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 89 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 105 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[185] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[185] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 105 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 105.0 (TID 104)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 105.0 (TID 104). 68150 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 104) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 105 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:49 INFO DAGScheduler: Job 89 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026338 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(172) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0276344 (rel: 0,00106) 0,00261385
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.0 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 174 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 90 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 106 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[186] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[186] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 106 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 106.0 (TID 105)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 106.0 (TID 105). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 105) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 106 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:49 INFO DAGScheduler: Job 90 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026218 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(174) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0276142 (rel: 0,000733) 0,00179582
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 176 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 91 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 107 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[187] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[187] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 107 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 107.0 (TID 106)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 107.0 (TID 106). 68279 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 106) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 107 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 18:21:49 INFO DAGScheduler: Job 91 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035178 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(176) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0275970 (rel: 0,000620) 0,00226395
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.0 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 178 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 92 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 108 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[188] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[188] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 108 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 108.0 (TID 107)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 108.0 (TID 107). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 107) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 108 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:49 INFO DAGScheduler: Job 92 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026344 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(178) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0275743 (rel: 0,000825) 0,00167558
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 180 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 93 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 109 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[189] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[189] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 109 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 109.0 (TID 108)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 109.0 (TID 108). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 108) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 109 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:49 INFO DAGScheduler: Job 93 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026083 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(180) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 63.3 KB, free 357.6 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.6 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 182 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 94 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 110 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[190] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[190] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 110 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 110.0 (TID 109)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 110.0 (TID 109). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 109) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 110 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:49 INFO DAGScheduler: Job 94 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026196 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(182) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO StrongWolfeLineSearch: Line search t: 0.4769797418924374 fval: 0.0275444991324947 rhs: 0.02757426596461796 cdd: 3.9424837397726215E-8
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO LBFGS: Step Size: 0,4770
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0275445 (rel: 0,00108) 0,00616549
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 184 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 95 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 111 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[191] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[191] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 111 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 111.0 (TID 110)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 111.0 (TID 110). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 110) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 111 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:49 INFO DAGScheduler: Job 95 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026379 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(184) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0275073 (rel: 0,00135) 0,00214546
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 186 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 96 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 112 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[192] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[192] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 112 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 112.0 (TID 111)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 112.0 (TID 111). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 111) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 112 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:49 INFO DAGScheduler: Job 96 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027171 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(186) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0274931 (rel: 0,000516) 0,00158449
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 57.3 KB, free 357.0 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 188 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 97 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 113 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[193] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 189 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[193] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 113 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 113.0 (TID 112)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 113.0 (TID 112). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 112) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 113 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:21:49 INFO DAGScheduler: Job 97 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029042 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(188) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0274843 (rel: 0,000320) 0,00180161
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 57.5 KB, free 356.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 190 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 98 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 114 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[194] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[194] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 114 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 114.0 (TID 113)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 114.0 (TID 113). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 113) in 31 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 114 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 18:21:49 INFO DAGScheduler: Job 98 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035924 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(190) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0274576 (rel: 0,000971) 0,00158743
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 63.3 KB, free 356.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 57.5 KB, free 356.7 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 192 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 99 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 115 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[195] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 116.3 KB, free 356.5 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.5 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[195] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 115 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 115.0 (TID 114)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 115.0 (TID 114). 68236 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 114) in 37 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 115 (treeAggregate at LogisticRegression.scala:1892) finished in 0,037 s
19/01/24 18:21:49 INFO DAGScheduler: Job 99 finished: treeAggregate at LogisticRegression.scala:1892, took 0,042675 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(192) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0274144 (rel: 0,00158) 0,00393116
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.0 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 194 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 100 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 116 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[196] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[196] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 116 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 116.0 (TID 115)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 116.0 (TID 115). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 115) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 116 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:21:49 INFO DAGScheduler: Job 100 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030279 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(194) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0273875 (rel: 0,000982) 0,00432852
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.8 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 196 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 101 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 117 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[197] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[197] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 117 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 117.0 (TID 116)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 117.0 (TID 116). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 116) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 117 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:49 INFO DAGScheduler: Job 101 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025928 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(196) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0273598 (rel: 0,00101) 0,00188127
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 57.3 KB, free 357.6 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 198 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 102 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 118 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[198] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[198] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 118 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 118.0 (TID 117)
19/01/24 18:21:49 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:49 INFO Executor: Finished task 0.0 in stage 118.0 (TID 117). 68193 bytes result sent to driver
19/01/24 18:21:49 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 117) in 20 ms on localhost (executor driver) (1/1)
19/01/24 18:21:49 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
19/01/24 18:21:49 INFO DAGScheduler: ResultStage 118 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:49 INFO DAGScheduler: Job 102 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025428 s
19/01/24 18:21:49 INFO TorrentBroadcast: Destroying Broadcast(198) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:49 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:49 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:21:49 INFO LBFGS: Val and Grad Norm: 0,0273468 (rel: 0,000476) 0,00116889
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.4 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 200 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:49 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:49 INFO DAGScheduler: Got job 103 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:49 INFO DAGScheduler: Final stage: ResultStage 119 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:49 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:49 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[199] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:49 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:49 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:49 INFO SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[199] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:49 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
19/01/24 18:21:49 WARN TaskSetManager: Stage 119 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:49 INFO Executor: Running task 0.0 in stage 119.0 (TID 118)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 119.0 (TID 118). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 118) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 119 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 103 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025520 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(200) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0273375 (rel: 0,000339) 0,00133102
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 202 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 104 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 120 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[200] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[200] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 120 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 119, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 120.0 (TID 119)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 120.0 (TID 119). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 119) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 120 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 104 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026073 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(202) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 63.3 KB, free 357.0 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 204 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 105 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 121 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[201] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[201] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 121 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 121.0 (TID 120)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 121.0 (TID 120). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 120) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 121 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 105 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025508 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(204) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO StrongWolfeLineSearch: Line search t: 0.44238853046279136 fval: 0.027322638685121102 rhs: 0.02733753822231949 cdd: 4.543171550924762E-8
19/01/24 18:21:50 INFO LBFGS: Step Size: 0,4424
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0273226 (rel: 0,000545) 0,00359478
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 206 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 106 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 122 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[202] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 207 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[202] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 122 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 122.0 (TID 121)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 122.0 (TID 121). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 121) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 122 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:50 INFO DAGScheduler: Job 106 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026054 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(206) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0273029 (rel: 0,000724) 0,00144224
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 63.3 KB, free 356.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.7 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 208 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 107 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 123 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[203] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 116.3 KB, free 356.6 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[203] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 WARN TaskSetManager: Stage 123 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 123.0 (TID 122)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 123.0 (TID 122). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 122) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 123 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:21:50 INFO DAGScheduler: Job 107 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034883 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(208) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0272873 (rel: 0,000571) 0,00140178
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 210 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 108 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 124 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[204] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 124 (MapPartitionsRDD[204] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 124 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 123, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 124.0 (TID 123)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 124.0 (TID 123). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 123) in 20 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 124 (treeAggregate at LogisticRegression.scala:1892) finished in 0,020 s
19/01/24 18:21:50 INFO DAGScheduler: Job 108 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025068 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(210) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 212 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 109 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 125 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[205] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 213 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[205] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 125.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 125 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 124, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 125.0 (TID 124)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 125.0 (TID 124). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 124) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 125 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 109 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026046 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(212) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO StrongWolfeLineSearch: Line search t: 0.18124034043854675 fval: 0.02727528205684075 rhs: 0.027287265460974944 cdd: -5.034893050342904E-7
19/01/24 18:21:50 INFO LBFGS: Step Size: 0,1812
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0272753 (rel: 0,000439) 0,00379483
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.6 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 214 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 110 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 126 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[206] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[206] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 126 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 125, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 126.0 (TID 125)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 126.0 (TID 125). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 125) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 126 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:50 INFO DAGScheduler: Job 110 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025968 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(214) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0272599 (rel: 0,000564) 0,00212009
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.4 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 216 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 111 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 127 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[207] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 217 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[207] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 127 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 126, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 127.0 (TID 126)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 127.0 (TID 126). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 126) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 127 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:50 INFO DAGScheduler: Job 111 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025980 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(216) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0272480 (rel: 0,000436) 0,00117490
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 218 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 112 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 128 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[208] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[208] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 128 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 127, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 128.0 (TID 127)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 128.0 (TID 127). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 127) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 128 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:50 INFO DAGScheduler: Job 112 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026708 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(218) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0272368 (rel: 0,000412) 0,00132283
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 220 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 113 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 129 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[209] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[209] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 129 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 128, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 129.0 (TID 128)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 129.0 (TID 128). 68236 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 128) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 129 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 18:21:50 INFO DAGScheduler: Job 113 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034954 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(220) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0272191 (rel: 0,000649) 0,00202239
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 57.3 KB, free 356.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 222 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 114 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 130 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[210] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[210] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 130 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 130.0 (TID 129)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 130.0 (TID 129). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 129) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 130 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:21:50 INFO DAGScheduler: Job 114 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030350 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(222) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0272060 (rel: 0,000484) 0,00307922
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 63.3 KB, free 357.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 57.3 KB, free 357.4 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 224 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 115 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 131 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[211] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 225 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[211] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 131 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 130, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 131.0 (TID 130)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 131.0 (TID 130). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 130) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 131 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:50 INFO DAGScheduler: Job 115 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026602 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(224) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0271824 (rel: 0,000867) 0,00153555
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 226 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 116 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 132 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[212] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 227 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[212] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 132 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 131, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 132.0 (TID 131)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 132.0 (TID 131). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 131) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 132 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:50 INFO DAGScheduler: Job 116 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027146 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(226) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0271749 (rel: 0,000274) 0,00102271
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.6 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 228 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 117 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 133 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[213] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 229 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[213] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 133 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 132, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 133.0 (TID 132)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 133.0 (TID 132). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 132) in 20 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 133 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 117 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025735 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(228) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0271630 (rel: 0,000438) 0,000860860
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.4 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 230 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 118 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 134 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[214] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 231 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[214] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 134 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 134.0 (TID 133)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 134.0 (TID 133). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 133) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 134 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 118 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025616 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(230) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 57.5 KB, free 357.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 232 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 119 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 135 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[215] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[215] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 135.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 135 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 135.0 (TID 134)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 135.0 (TID 134). 68236 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 134) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 135 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 119 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025339 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(232) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO StrongWolfeLineSearch: Line search t: 0.19604525695405883 fval: 0.02715561387700296 rhs: 0.027163021359093393 cdd: -2.620166538343346E-8
19/01/24 18:21:50 INFO LBFGS: Step Size: 0,1960
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0271556 (rel: 0,000273) 0,00187077
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 234 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 120 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 136 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[216] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[216] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 136 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 135, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 136.0 (TID 135)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 136.0 (TID 135). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 135) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 136 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 120 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025224 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(234) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0271413 (rel: 0,000526) 0,00152413
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_234_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 57.3 KB, free 356.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 236 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 121 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 137 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[217] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_237 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 237 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[217] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 137.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 137 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 136, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 137.0 (TID 136)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 137.0 (TID 136). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 136) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 137 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 121 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025426 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(236) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0271041 (rel: 0,00137) 0,00202190
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_236_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_238 stored as values in memory (estimated size 63.3 KB, free 356.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.7 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 238 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 122 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 138 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[218] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_239 stored as values in memory (estimated size 116.3 KB, free 356.5 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.5 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[218] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 138 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 137, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 138.0 (TID 137)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_233_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_237_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_235_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 138.0 (TID 137). 68279 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 137) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 138 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:21:50 INFO DAGScheduler: Job 122 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031064 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(238) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_238_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_240 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 240 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 123 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 139 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[219] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_241 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 241 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[219] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 139 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 138, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 139.0 (TID 138)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 139.0 (TID 138). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 138) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 139 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:21:50 INFO DAGScheduler: Job 123 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029683 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(240) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO StrongWolfeLineSearch: Line search t: 0.5007448344415253 fval: 0.027092939336304526 rhs: 0.027104070568816956 cdd: -4.9042881056530016E-9
19/01/24 18:21:50 INFO LBFGS: Step Size: 0,5007
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_240_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0270929 (rel: 0,000411) 0,00189099
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_242 stored as values in memory (estimated size 63.3 KB, free 357.8 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 242 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 124 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 140 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 140 (MapPartitionsRDD[220] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_243 stored as values in memory (estimated size 116.3 KB, free 357.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.6 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 243 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[220] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 140.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 140 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 139, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 140.0 (TID 139)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 140.0 (TID 139). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 139) in 27 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 140 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 18:21:50 INFO DAGScheduler: Job 124 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032337 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(242) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_242_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0270825 (rel: 0,000385) 0,00131139
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_244 stored as values in memory (estimated size 63.3 KB, free 357.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.6 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 244 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 125 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 141 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[221] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_245 stored as values in memory (estimated size 116.3 KB, free 357.5 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.4 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[221] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 141 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 140, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 141.0 (TID 140)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 141.0 (TID 140). 68236 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 140) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 141 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:50 INFO DAGScheduler: Job 125 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027674 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(244) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_244_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0270734 (rel: 0,000337) 0,00167538
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_246 stored as values in memory (estimated size 63.3 KB, free 357.5 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.4 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 246 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 126 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 142 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 142 (MapPartitionsRDD[222] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_247 stored as values in memory (estimated size 116.3 KB, free 357.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 247 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 142 (MapPartitionsRDD[222] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 142.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 142 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 141, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 142.0 (TID 141)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 142.0 (TID 141). 68236 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 141) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 142 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:50 INFO DAGScheduler: Job 126 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026593 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(246) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_246_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0270557 (rel: 0,000654) 0,00129150
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_248 stored as values in memory (estimated size 63.3 KB, free 357.3 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 57.3 KB, free 357.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on 127.0.0.1:53359 (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 248 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 127 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 143 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[223] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_249 stored as values in memory (estimated size 116.3 KB, free 357.1 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 249 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[223] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 143.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 143 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 142, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 143.0 (TID 142)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 143.0 (TID 142). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 142) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 143 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 127 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026689 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(248) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_248_piece0 on 127.0.0.1:53359 in memory (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0270527 (rel: 0,000112) 0,00487597
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_250 stored as values in memory (estimated size 63.3 KB, free 357.1 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 57.4 KB, free 357.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 250 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 128 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 144 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[224] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_251 stored as values in memory (estimated size 116.3 KB, free 356.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 251 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[224] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 144.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 144 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 143, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 144.0 (TID 143)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 144.0 (TID 143). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 143) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 144 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:21:50 INFO DAGScheduler: Job 128 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025883 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(250) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_250_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0270365 (rel: 0,000598) 0,00244017
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_252 stored as values in memory (estimated size 63.3 KB, free 356.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 252 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 129 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 145 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[225] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_253 stored as values in memory (estimated size 116.3 KB, free 356.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.7 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 253 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[225] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 145 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 144, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 145.0 (TID 144)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 145.0 (TID 144). 68193 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 144) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 145 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:21:50 INFO DAGScheduler: Job 129 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025611 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(252) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_252_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0270285 (rel: 0,000294) 0,00115072
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_254 stored as values in memory (estimated size 63.3 KB, free 356.7 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 57.4 KB, free 356.7 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on 127.0.0.1:53359 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 254 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 130 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 146 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 146 (MapPartitionsRDD[226] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_255 stored as values in memory (estimated size 116.3 KB, free 356.5 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 74.8 KB, free 356.5 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_255_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 255 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 146 (MapPartitionsRDD[226] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 146.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 146 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 145, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 146.0 (TID 145)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_239_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_251_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_245_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_243_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_247_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_253_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_249_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_241_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:50 INFO Executor: Finished task 0.0 in stage 146.0 (TID 145). 68279 bytes result sent to driver
19/01/24 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 145) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
19/01/24 18:21:50 INFO DAGScheduler: ResultStage 146 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:21:50 INFO DAGScheduler: Job 130 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036605 s
19/01/24 18:21:50 INFO TorrentBroadcast: Destroying Broadcast(254) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:50 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:50 INFO LBFGS: Val and Grad Norm: 0,0270226 (rel: 0,000218) 0,000931583
19/01/24 18:21:50 INFO BlockManagerInfo: Removed broadcast_254_piece0 on 127.0.0.1:53359 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_256 stored as values in memory (estimated size 63.3 KB, free 358.0 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.0 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_256_piece0 in memory on 127.0.0.1:53359 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 256 from broadcast at LogisticRegression.scala:1879
19/01/24 18:21:50 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:21:50 INFO DAGScheduler: Got job 131 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:21:50 INFO DAGScheduler: Final stage: ResultStage 147 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:21:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:21:50 INFO DAGScheduler: Missing parents: List()
19/01/24 18:21:50 INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[227] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_257 stored as values in memory (estimated size 116.3 KB, free 357.9 MB)
19/01/24 18:21:50 INFO MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 74.8 KB, free 357.8 MB)
19/01/24 18:21:50 INFO BlockManagerInfo: Added broadcast_257_piece0 in memory on 127.0.0.1:53359 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:21:50 INFO SparkContext: Created broadcast 257 from broadcast at DAGScheduler.scala:1006
19/01/24 18:21:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[227] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:21:50 INFO TaskSchedulerImpl: Adding task set 147.0 with 1 tasks
19/01/24 18:21:50 WARN TaskSetManager: Stage 147 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:21:50 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 146, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:21:50 INFO Executor: Running task 0.0 in stage 147.0 (TID 146)
19/01/24 18:21:51 INFO BlockManager: Found block rdd_115_0 locally
19/01/24 18:21:51 INFO Executor: Finished task 0.0 in stage 147.0 (TID 146). 68236 bytes result sent to driver
19/01/24 18:21:51 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 146) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:21:51 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
19/01/24 18:21:51 INFO DAGScheduler: ResultStage 147 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:21:51 INFO DAGScheduler: Job 131 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027526 s
19/01/24 18:21:51 INFO TorrentBroadcast: Destroying Broadcast(256) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:21:51 INFO LBFGS: Step Size: 1,000
19/01/24 18:21:51 INFO BlockManagerInfo: Removed broadcast_256_piece0 on 127.0.0.1:53359 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:21:51 INFO LBFGS: Val and Grad Norm: 0,0270067 (rel: 0,000588) 0,000915275
19/01/24 18:21:51 INFO LBFGS: Converged because max iterations reached
19/01/24 18:21:51 INFO TorrentBroadcast: Destroying Broadcast(35) (from destroy at LogisticRegression.scala:796)
19/01/24 18:21:51 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:53359 in memory (size: 7.7 KB, free: 361.5 MB)
19/01/24 18:21:51 INFO MapPartitionsRDD: Removing RDD 115 from persistence list
19/01/24 18:21:51 INFO BlockManager: Removing RDD 115
19/01/24 18:21:51 INFO CodeGenerator: Code generated in 18.137341 ms
19/01/24 18:21:51 INFO Instrumentation: LogisticRegression-logistic_regression_57d867852d94-242328758-4: training finished
19/01/24 18:23:39 INFO SparkSqlParser: Parsing command: SELECT * FROM reviews LIMIT 5
19/01/24 18:23:39 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:23:39 INFO DAGScheduler: Got job 132 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:23:39 INFO DAGScheduler: Final stage: ResultStage 148 (collect at utils.scala:200)
19/01/24 18:23:39 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:23:39 INFO DAGScheduler: Missing parents: List()
19/01/24 18:23:39 INFO DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[234] at collect at utils.scala:200), which has no missing parents
19/01/24 18:23:39 INFO MemoryStore: Block broadcast_258 stored as values in memory (estimated size 11.1 KB, free 360.5 MB)
19/01/24 18:23:39 INFO MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 5.7 KB, free 360.5 MB)
19/01/24 18:23:39 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on 127.0.0.1:53359 (size: 5.7 KB, free: 364.1 MB)
19/01/24 18:23:39 INFO SparkContext: Created broadcast 258 from broadcast at DAGScheduler.scala:1006
19/01/24 18:23:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[234] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:23:39 INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks
19/01/24 18:23:39 WARN TaskSetManager: Stage 148 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:23:39 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 147, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:23:39 INFO Executor: Running task 0.0 in stage 148.0 (TID 147)
19/01/24 18:23:39 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:23:39 INFO Executor: 1 block locks were not released by TID = 147:
[rdd_9_0]
19/01/24 18:23:39 INFO Executor: Finished task 0.0 in stage 148.0 (TID 147). 1818 bytes result sent to driver
19/01/24 18:23:39 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 147) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:23:39 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
19/01/24 18:23:39 INFO DAGScheduler: ResultStage 148 (collect at utils.scala:200) finished in 0,024 s
19/01/24 18:23:39 INFO DAGScheduler: Job 132 finished: collect at utils.scala:200, took 0,028365 s
19/01/24 18:23:39 INFO CodeGenerator: Code generated in 5.024091 ms
19/01/24 18:23:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_57d87c20a65`
19/01/24 18:23:54 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:23:54 INFO DAGScheduler: Registering RDD 240 (flatMap at CountVectorizer.scala:163)
19/01/24 18:23:54 INFO DAGScheduler: Got job 133 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:23:54 INFO DAGScheduler: Final stage: ResultStage 150 (count at CountVectorizer.scala:176)
19/01/24 18:23:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 149)
19/01/24 18:23:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 149)
19/01/24 18:23:54 INFO DAGScheduler: Submitting ShuffleMapStage 149 (MapPartitionsRDD[240] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_259 stored as values in memory (estimated size 28.5 KB, free 360.5 MB)
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 13.0 KB, free 360.5 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Added broadcast_259_piece0 in memory on 127.0.0.1:53359 (size: 13.0 KB, free: 364.1 MB)
19/01/24 18:23:54 INFO SparkContext: Created broadcast 259 from broadcast at DAGScheduler.scala:1006
19/01/24 18:23:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 149 (MapPartitionsRDD[240] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:23:54 INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks
19/01/24 18:23:54 WARN TaskSetManager: Stage 149 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:23:54 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 148, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:23:54 INFO Executor: Running task 0.0 in stage 149.0 (TID 148)
19/01/24 18:23:54 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:23:54 INFO CodeGenerator: Code generated in 8.076762 ms
19/01/24 18:23:54 INFO BlockManagerInfo: Removed broadcast_255_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 364.1 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Removed broadcast_257_piece0 on 127.0.0.1:53359 in memory (size: 74.8 KB, free: 364.2 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Removed broadcast_258_piece0 on 127.0.0.1:53359 in memory (size: 5.7 KB, free: 364.2 MB)
19/01/24 18:23:54 INFO Executor: Finished task 0.0 in stage 149.0 (TID 148). 1908 bytes result sent to driver
19/01/24 18:23:54 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 148) in 238 ms on localhost (executor driver) (1/1)
19/01/24 18:23:54 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
19/01/24 18:23:54 INFO DAGScheduler: ShuffleMapStage 149 (flatMap at CountVectorizer.scala:163) finished in 0,238 s
19/01/24 18:23:54 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:23:54 INFO DAGScheduler: running: Set()
19/01/24 18:23:54 INFO DAGScheduler: waiting: Set(ResultStage 150)
19/01/24 18:23:54 INFO DAGScheduler: failed: Set()
19/01/24 18:23:54 INFO DAGScheduler: Submitting ResultStage 150 (MapPartitionsRDD[243] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_260 stored as values in memory (estimated size 3.2 KB, free 360.8 MB)
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 1887.0 B, free 360.8 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Added broadcast_260_piece0 in memory on 127.0.0.1:53359 (size: 1887.0 B, free: 364.2 MB)
19/01/24 18:23:54 INFO SparkContext: Created broadcast 260 from broadcast at DAGScheduler.scala:1006
19/01/24 18:23:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[243] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:23:54 INFO TaskSchedulerImpl: Adding task set 150.0 with 1 tasks
19/01/24 18:23:54 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 149, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:23:54 INFO Executor: Running task 0.0 in stage 150.0 (TID 149)
19/01/24 18:23:54 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:23:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:23:54 INFO MemoryStore: Block rdd_243_0 stored as values in memory (estimated size 686.3 KB, free 360.2 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Added rdd_243_0 in memory on 127.0.0.1:53359 (size: 686.3 KB, free: 363.5 MB)
19/01/24 18:23:54 INFO Executor: Finished task 0.0 in stage 150.0 (TID 149). 1744 bytes result sent to driver
19/01/24 18:23:54 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 149) in 33 ms on localhost (executor driver) (1/1)
19/01/24 18:23:54 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
19/01/24 18:23:54 INFO DAGScheduler: ResultStage 150 (count at CountVectorizer.scala:176) finished in 0,034 s
19/01/24 18:23:54 INFO DAGScheduler: Job 133 finished: count at CountVectorizer.scala:176, took 0,278477 s
19/01/24 18:23:54 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:23:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 143 bytes
19/01/24 18:23:54 INFO DAGScheduler: Got job 134 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:23:54 INFO DAGScheduler: Final stage: ResultStage 152 (top at CountVectorizer.scala:179)
19/01/24 18:23:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 151)
19/01/24 18:23:54 INFO DAGScheduler: Missing parents: List()
19/01/24 18:23:54 INFO DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[244] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_261 stored as values in memory (estimated size 4.2 KB, free 360.2 MB)
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 2.2 KB, free 360.2 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Added broadcast_261_piece0 in memory on 127.0.0.1:53359 (size: 2.2 KB, free: 363.5 MB)
19/01/24 18:23:54 INFO SparkContext: Created broadcast 261 from broadcast at DAGScheduler.scala:1006
19/01/24 18:23:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[244] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:23:54 INFO TaskSchedulerImpl: Adding task set 152.0 with 1 tasks
19/01/24 18:23:54 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 150, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:23:54 INFO Executor: Running task 0.0 in stage 152.0 (TID 150)
19/01/24 18:23:54 INFO BlockManager: Found block rdd_243_0 locally
19/01/24 18:23:54 INFO Executor: Finished task 0.0 in stage 152.0 (TID 150). 174434 bytes result sent to driver
19/01/24 18:23:54 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 150) in 13 ms on localhost (executor driver) (1/1)
19/01/24 18:23:54 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
19/01/24 18:23:54 INFO DAGScheduler: ResultStage 152 (top at CountVectorizer.scala:179) finished in 0,013 s
19/01/24 18:23:54 INFO DAGScheduler: Job 134 finished: top at CountVectorizer.scala:179, took 0,016023 s
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_262 stored as values in memory (estimated size 1137.7 KB, free 359.0 MB)
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 89.8 KB, free 359.0 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Added broadcast_262_piece0 in memory on 127.0.0.1:53359 (size: 89.8 KB, free: 363.4 MB)
19/01/24 18:23:54 INFO SparkContext: Created broadcast 262 from broadcast at CountVectorizer.scala:244
19/01/24 18:23:54 INFO CodeGenerator: Code generated in 8.016591 ms
19/01/24 18:23:54 INFO CodeGenerator: Code generated in 9.092375 ms
19/01/24 18:23:54 INFO SparkContext: Starting job: take at Classifier.scala:111
19/01/24 18:23:54 INFO DAGScheduler: Registering RDD 247 (take at Classifier.scala:111)
19/01/24 18:23:54 INFO DAGScheduler: Got job 135 (take at Classifier.scala:111) with 1 output partitions
19/01/24 18:23:54 INFO DAGScheduler: Final stage: ResultStage 154 (take at Classifier.scala:111)
19/01/24 18:23:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 153)
19/01/24 18:23:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 153)
19/01/24 18:23:54 INFO DAGScheduler: Submitting ShuffleMapStage 153 (MapPartitionsRDD[247] at take at Classifier.scala:111), which has no missing parents
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_263 stored as values in memory (estimated size 25.0 KB, free 358.9 MB)
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_263_piece0 stored as bytes in memory (estimated size 11.3 KB, free 358.9 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Added broadcast_263_piece0 in memory on 127.0.0.1:53359 (size: 11.3 KB, free: 363.4 MB)
19/01/24 18:23:54 INFO SparkContext: Created broadcast 263 from broadcast at DAGScheduler.scala:1006
19/01/24 18:23:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 153 (MapPartitionsRDD[247] at take at Classifier.scala:111) (first 15 tasks are for partitions Vector(0))
19/01/24 18:23:54 INFO TaskSchedulerImpl: Adding task set 153.0 with 1 tasks
19/01/24 18:23:54 WARN TaskSetManager: Stage 153 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:23:54 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 151, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:23:54 INFO Executor: Running task 0.0 in stage 153.0 (TID 151)
19/01/24 18:23:54 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:23:54 INFO Executor: Finished task 0.0 in stage 153.0 (TID 151). 2256 bytes result sent to driver
19/01/24 18:23:54 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 151) in 45 ms on localhost (executor driver) (1/1)
19/01/24 18:23:54 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
19/01/24 18:23:54 INFO DAGScheduler: ShuffleMapStage 153 (take at Classifier.scala:111) finished in 0,045 s
19/01/24 18:23:54 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:23:54 INFO DAGScheduler: running: Set()
19/01/24 18:23:54 INFO DAGScheduler: waiting: Set(ResultStage 154)
19/01/24 18:23:54 INFO DAGScheduler: failed: Set()
19/01/24 18:23:54 INFO DAGScheduler: Submitting ResultStage 154 (MapPartitionsRDD[250] at take at Classifier.scala:111), which has no missing parents
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_264 stored as values in memory (estimated size 7.2 KB, free 358.9 MB)
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_264_piece0 stored as bytes in memory (estimated size 3.9 KB, free 358.9 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Added broadcast_264_piece0 in memory on 127.0.0.1:53359 (size: 3.9 KB, free: 363.4 MB)
19/01/24 18:23:54 INFO SparkContext: Created broadcast 264 from broadcast at DAGScheduler.scala:1006
19/01/24 18:23:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[250] at take at Classifier.scala:111) (first 15 tasks are for partitions Vector(0))
19/01/24 18:23:54 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks
19/01/24 18:23:54 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 152, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:23:54 INFO Executor: Running task 0.0 in stage 154.0 (TID 152)
19/01/24 18:23:54 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:23:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:23:54 INFO Executor: Finished task 0.0 in stage 154.0 (TID 152). 1422 bytes result sent to driver
19/01/24 18:23:54 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 152) in 3 ms on localhost (executor driver) (1/1)
19/01/24 18:23:54 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
19/01/24 18:23:54 INFO DAGScheduler: ResultStage 154 (take at Classifier.scala:111) finished in 0,004 s
19/01/24 18:23:54 INFO DAGScheduler: Job 135 finished: take at Classifier.scala:111, took 0,054981 s
19/01/24 18:23:54 INFO CodeGenerator: Code generated in 4.710472 ms
19/01/24 18:23:54 INFO RandomForestClassifier: org.apache.spark.ml.classification.RandomForestClassifier inferred 2 classes for labelCol=random_forest_classifier_57d8ba33229__labelCol since numClasses was not specified in the column metadata.
19/01/24 18:23:54 INFO CodeGenerator: Code generated in 13.44328 ms
19/01/24 18:23:54 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_57d8ba33229-1458069942-5: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 18:23:54 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_57d8ba33229-1458069942-5: {"subsamplingRate":1.0,"impurity":"gini","featuresCol":"vectorizer_output","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"Sentiment","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"rawPredictionCol":"rawPrediction","probabilityCol":"probability","numTrees":20}
19/01/24 18:23:54 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:112
19/01/24 18:23:54 INFO DAGScheduler: Got job 136 (take at DecisionTreeMetadata.scala:112) with 1 output partitions
19/01/24 18:23:54 INFO DAGScheduler: Final stage: ResultStage 155 (take at DecisionTreeMetadata.scala:112)
19/01/24 18:23:54 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:23:54 INFO DAGScheduler: Missing parents: List()
19/01/24 18:23:54 INFO DAGScheduler: Submitting ResultStage 155 (MapPartitionsRDD[257] at map at DecisionTreeMetadata.scala:112), which has no missing parents
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_265 stored as values in memory (estimated size 115.2 KB, free 358.8 MB)
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_265_piece0 stored as bytes in memory (estimated size 74.3 KB, free 358.7 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Added broadcast_265_piece0 in memory on 127.0.0.1:53359 (size: 74.3 KB, free: 363.4 MB)
19/01/24 18:23:54 INFO SparkContext: Created broadcast 265 from broadcast at DAGScheduler.scala:1006
19/01/24 18:23:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 155 (MapPartitionsRDD[257] at map at DecisionTreeMetadata.scala:112) (first 15 tasks are for partitions Vector(0))
19/01/24 18:23:54 INFO TaskSchedulerImpl: Adding task set 155.0 with 1 tasks
19/01/24 18:23:54 WARN TaskSetManager: Stage 155 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:23:54 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 153, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:23:54 INFO Executor: Running task 0.0 in stage 155.0 (TID 153)
19/01/24 18:23:54 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:23:54 INFO CodeGenerator: Code generated in 4.176956 ms
19/01/24 18:23:54 INFO Executor: Finished task 0.0 in stage 155.0 (TID 153). 1625 bytes result sent to driver
19/01/24 18:23:54 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 153) in 47 ms on localhost (executor driver) (1/1)
19/01/24 18:23:54 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
19/01/24 18:23:54 INFO DAGScheduler: ResultStage 155 (take at DecisionTreeMetadata.scala:112) finished in 0,047 s
19/01/24 18:23:54 INFO DAGScheduler: Job 136 finished: take at DecisionTreeMetadata.scala:112, took 0,052244 s
19/01/24 18:23:54 INFO SparkContext: Starting job: count at DecisionTreeMetadata.scala:118
19/01/24 18:23:54 INFO DAGScheduler: Got job 137 (count at DecisionTreeMetadata.scala:118) with 1 output partitions
19/01/24 18:23:54 INFO DAGScheduler: Final stage: ResultStage 156 (count at DecisionTreeMetadata.scala:118)
19/01/24 18:23:54 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:23:54 INFO DAGScheduler: Missing parents: List()
19/01/24 18:23:54 INFO DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[256] at retag at RandomForest.scala:103), which has no missing parents
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_266 stored as values in memory (estimated size 114.8 KB, free 358.6 MB)
19/01/24 18:23:54 INFO MemoryStore: Block broadcast_266_piece0 stored as bytes in memory (estimated size 74.1 KB, free 358.5 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Added broadcast_266_piece0 in memory on 127.0.0.1:53359 (size: 74.1 KB, free: 363.3 MB)
19/01/24 18:23:54 INFO SparkContext: Created broadcast 266 from broadcast at DAGScheduler.scala:1006
19/01/24 18:23:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[256] at retag at RandomForest.scala:103) (first 15 tasks are for partitions Vector(0))
19/01/24 18:23:54 INFO TaskSchedulerImpl: Adding task set 156.0 with 1 tasks
19/01/24 18:23:54 WARN TaskSetManager: Stage 156 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:23:54 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 154, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:23:54 INFO Executor: Running task 0.0 in stage 156.0 (TID 154)
19/01/24 18:23:54 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3681
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3690
19/01/24 18:23:54 INFO BlockManagerInfo: Removed broadcast_261_piece0 on 127.0.0.1:53359 in memory (size: 2.2 KB, free: 363.3 MB)
19/01/24 18:23:54 INFO BlockManagerInfo: Removed broadcast_264_piece0 on 127.0.0.1:53359 in memory (size: 3.9 KB, free: 363.3 MB)
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3604
19/01/24 18:23:54 INFO BlockManagerInfo: Removed broadcast_259_piece0 on 127.0.0.1:53359 in memory (size: 13.0 KB, free: 363.3 MB)
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3677
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3682
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3599
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3683
19/01/24 18:23:54 INFO BlockManager: Removing RDD 243
19/01/24 18:23:54 INFO ContextCleaner: Cleaned RDD 243
19/01/24 18:23:54 INFO ContextCleaner: Cleaned shuffle 11
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3678
19/01/24 18:23:54 INFO BlockManagerInfo: Removed broadcast_265_piece0 on 127.0.0.1:53359 in memory (size: 74.3 KB, free: 364.0 MB)
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3600
19/01/24 18:23:54 INFO BlockManagerInfo: Removed broadcast_260_piece0 on 127.0.0.1:53359 in memory (size: 1887.0 B, free: 364.0 MB)
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3687
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3693
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3688
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3679
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3685
19/01/24 18:23:54 INFO BlockManagerInfo: Removed broadcast_263_piece0 on 127.0.0.1:53359 in memory (size: 11.3 KB, free: 364.1 MB)
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3684
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3691
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3692
19/01/24 18:23:54 INFO ContextCleaner: Cleaned shuffle 10
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3689
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3680
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3603
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3686
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3601
19/01/24 18:23:54 INFO ContextCleaner: Cleaned accumulator 3602
19/01/24 18:23:54 INFO Executor: Finished task 0.0 in stage 156.0 (TID 154). 1719 bytes result sent to driver
19/01/24 18:23:54 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 154) in 223 ms on localhost (executor driver) (1/1)
19/01/24 18:23:54 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
19/01/24 18:23:54 INFO DAGScheduler: ResultStage 156 (count at DecisionTreeMetadata.scala:118) finished in 0,225 s
19/01/24 18:23:54 INFO DAGScheduler: Job 137 finished: count at DecisionTreeMetadata.scala:118, took 0,229331 s
19/01/24 18:23:54 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_57d8ba33229-1458069942-5: {"numFeatures":8098}
19/01/24 18:23:54 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_57d8ba33229-1458069942-5: {"numClasses":2}
19/01/24 18:23:55 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:928
19/01/24 18:23:55 INFO DAGScheduler: Registering RDD 259 (flatMap at RandomForest.scala:921)
19/01/24 18:23:55 INFO DAGScheduler: Got job 138 (collectAsMap at RandomForest.scala:928) with 1 output partitions
19/01/24 18:23:55 INFO DAGScheduler: Final stage: ResultStage 158 (collectAsMap at RandomForest.scala:928)
19/01/24 18:23:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 157)
19/01/24 18:23:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 157)
19/01/24 18:23:55 INFO DAGScheduler: Submitting ShuffleMapStage 157 (MapPartitionsRDD[259] at flatMap at RandomForest.scala:921), which has no missing parents
19/01/24 18:23:55 INFO MemoryStore: Block broadcast_267 stored as values in memory (estimated size 199.7 KB, free 359.3 MB)
19/01/24 18:23:55 INFO MemoryStore: Block broadcast_267_piece0 stored as bytes in memory (estimated size 108.1 KB, free 359.2 MB)
19/01/24 18:23:55 INFO BlockManagerInfo: Added broadcast_267_piece0 in memory on 127.0.0.1:53359 (size: 108.1 KB, free: 363.9 MB)
19/01/24 18:23:55 INFO SparkContext: Created broadcast 267 from broadcast at DAGScheduler.scala:1006
19/01/24 18:23:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 157 (MapPartitionsRDD[259] at flatMap at RandomForest.scala:921) (first 15 tasks are for partitions Vector(0))
19/01/24 18:23:55 INFO TaskSchedulerImpl: Adding task set 157.0 with 1 tasks
19/01/24 18:23:55 WARN TaskSetManager: Stage 157 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:23:55 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 155, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914234 bytes)
19/01/24 18:23:55 INFO Executor: Running task 0.0 in stage 157.0 (TID 155)
19/01/24 18:23:55 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:23:55 INFO BlockManagerInfo: Removed broadcast_266_piece0 on 127.0.0.1:53359 in memory (size: 74.1 KB, free: 364.0 MB)
19/01/24 18:24:11 INFO Executor: Finished task 0.0 in stage 157.0 (TID 155). 1822 bytes result sent to driver
19/01/24 18:24:11 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 155) in 16074 ms on localhost (executor driver) (1/1)
19/01/24 18:24:11 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
19/01/24 18:24:11 INFO DAGScheduler: ShuffleMapStage 157 (flatMap at RandomForest.scala:921) finished in 16,075 s
19/01/24 18:24:11 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:24:11 INFO DAGScheduler: running: Set()
19/01/24 18:24:11 INFO DAGScheduler: waiting: Set(ResultStage 158)
19/01/24 18:24:11 INFO DAGScheduler: failed: Set()
19/01/24 18:24:11 INFO DAGScheduler: Submitting ResultStage 158 (MapPartitionsRDD[261] at map at RandomForest.scala:923), which has no missing parents
19/01/24 18:24:11 INFO MemoryStore: Block broadcast_268 stored as values in memory (estimated size 233.7 KB, free 359.2 MB)
19/01/24 18:24:11 INFO MemoryStore: Block broadcast_268_piece0 stored as bytes in memory (estimated size 109.7 KB, free 359.0 MB)
19/01/24 18:24:11 INFO BlockManagerInfo: Added broadcast_268_piece0 in memory on 127.0.0.1:53359 (size: 109.7 KB, free: 363.9 MB)
19/01/24 18:24:11 INFO SparkContext: Created broadcast 268 from broadcast at DAGScheduler.scala:1006
19/01/24 18:24:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (MapPartitionsRDD[261] at map at RandomForest.scala:923) (first 15 tasks are for partitions Vector(0))
19/01/24 18:24:11 INFO TaskSchedulerImpl: Adding task set 158.0 with 1 tasks
19/01/24 18:24:11 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 156, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:24:11 INFO Executor: Running task 0.0 in stage 158.0 (TID 156)
19/01/24 18:24:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:24:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:24:11 INFO BlockManager: Removing RDD 115
19/01/24 18:24:11 INFO ContextCleaner: Cleaned RDD 115
19/01/24 18:24:11 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:53359 in memory (size: 89.8 KB, free: 364.0 MB)
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 869
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 874
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 870
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 873
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 875
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 876
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 868
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 871
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 872
19/01/24 18:24:11 INFO BlockManagerInfo: Removed broadcast_267_piece0 on 127.0.0.1:53359 in memory (size: 108.1 KB, free: 364.1 MB)
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 879
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 3574
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 878
19/01/24 18:24:11 INFO ContextCleaner: Cleaned accumulator 877
19/01/24 18:24:14 ERROR Executor: Exception in task 0.0 in stage 158.0 (TID 156)
java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
19/01/24 18:24:14 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 156,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
19/01/24 18:24:14 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 18:24:14 WARN TaskSetManager: Lost task 0.0 in stage 158.0 (TID 156, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)

19/01/24 18:24:14 ERROR TaskSetManager: Task 0 in stage 158.0 failed 1 times; aborting job
19/01/24 18:24:14 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
19/01/24 18:24:14 INFO TaskSchedulerImpl: Cancelling stage 158
19/01/24 18:24:14 INFO DAGScheduler: ResultStage 158 (collectAsMap at RandomForest.scala:928) failed in 2,930 s due to Job aborted due to stage failure: Task 0 in stage 158.0 failed 1 times, most recent failure: Lost task 0.0 in stage 158.0 (TID 156, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)

Driver stacktrace:
19/01/24 18:24:14 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 18:24:14 INFO DAGScheduler: Job 138 failed: collectAsMap at RandomForest.scala:928, took 19,020353 s
19/01/24 18:24:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 18:24:14 INFO MemoryStore: MemoryStore cleared
19/01/24 18:24:14 INFO BlockManager: BlockManager stopped
19/01/24 18:24:14 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 18:24:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 18:24:14 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-13c9cf02-5939-48bf-aec3-54e6b9b7202f\userFiles-6b9bfc00-0023-418f-9ab4-242cc0752180
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-13c9cf02-5939-48bf-aec3-54e6b9b7202f\userFiles-6b9bfc00-0023-418f-9ab4-242cc0752180
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:24:14 INFO SparkContext: Successfully stopped SparkContext
19/01/24 18:24:14 INFO ShutdownHookManager: Shutdown hook called
19/01/24 18:24:14 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-13c9cf02-5939-48bf-aec3-54e6b9b7202f
19/01/24 18:24:14 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-13c9cf02-5939-48bf-aec3-54e6b9b7202f
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-13c9cf02-5939-48bf-aec3-54e6b9b7202f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:24:14 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-13c9cf02-5939-48bf-aec3-54e6b9b7202f\userFiles-6b9bfc00-0023-418f-9ab4-242cc0752180
19/01/24 18:24:14 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-13c9cf02-5939-48bf-aec3-54e6b9b7202f\userFiles-6b9bfc00-0023-418f-9ab4-242cc0752180
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-13c9cf02-5939-48bf-aec3-54e6b9b7202f\userFiles-6b9bfc00-0023-418f-9ab4-242cc0752180
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:25:56 INFO SparkContext: Running Spark version 2.2.0
19/01/24 18:25:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 18:25:57 INFO SparkContext: Submitted application: sparklyr
19/01/24 18:25:57 INFO SecurityManager: Changing view acls to: yanis
19/01/24 18:25:57 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 18:25:57 INFO SecurityManager: Changing view acls groups to: 
19/01/24 18:25:57 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 18:25:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 18:25:57 INFO Utils: Successfully started service 'sparkDriver' on port 53469.
19/01/24 18:25:57 INFO SparkEnv: Registering MapOutputTracker
19/01/24 18:25:57 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 18:25:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 18:25:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 18:25:57 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-b01534e1-d631-449d-817b-ffa596d24c9d
19/01/24 18:25:57 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 18:25:57 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 18:25:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 18:25:57 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 18:25:57 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:53469/jars/sparklyr-2.2-2.11.jar with timestamp 1548350757430
19/01/24 18:25:57 INFO Executor: Starting executor ID driver on host localhost
19/01/24 18:25:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53510.
19/01/24 18:25:57 INFO NettyBlockTransferService: Server created on 127.0.0.1:53510
19/01/24 18:25:57 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 18:25:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53510, None)
19/01/24 18:25:57 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53510 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53510, None)
19/01/24 18:25:57 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53510, None)
19/01/24 18:25:57 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53510, None)
19/01/24 18:25:57 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 18:25:57 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 18:25:57 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 18:25:57 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 18:25:58 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 18:25:58 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 18:25:58 INFO ObjectStore: ObjectStore, initialize called
19/01/24 18:25:58 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 18:25:58 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 18:25:59 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 18:26:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:26:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:26:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:26:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:26:01 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 18:26:01 INFO ObjectStore: Initialized ObjectStore
19/01/24 18:26:01 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 18:26:01 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 18:26:01 INFO HiveMetaStore: Added admin role in metastore
19/01/24 18:26:01 INFO HiveMetaStore: Added public role in metastore
19/01/24 18:26:01 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 18:26:01 INFO HiveMetaStore: 0: get_all_databases
19/01/24 18:26:01 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 18:26:01 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 18:26:01 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 18:26:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:26:01 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/674d083f-65f2-4155-ae8a-557cc0e4547b_resources
19/01/24 18:26:01 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/674d083f-65f2-4155-ae8a-557cc0e4547b
19/01/24 18:26:01 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/674d083f-65f2-4155-ae8a-557cc0e4547b
19/01/24 18:26:01 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/674d083f-65f2-4155-ae8a-557cc0e4547b/_tmp_space.db
19/01/24 18:26:01 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:26:02 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:26:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:26:02 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 18:26:02 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 18:26:02 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 18:26:02 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/4b81e0ac-9999-40b6-bc25-155703b1ff0f_resources
19/01/24 18:26:02 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/4b81e0ac-9999-40b6-bc25-155703b1ff0f
19/01/24 18:26:02 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/4b81e0ac-9999-40b6-bc25-155703b1ff0f
19/01/24 18:26:02 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/4b81e0ac-9999-40b6-bc25-155703b1ff0f/_tmp_space.db
19/01/24 18:26:02 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:26:02 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 18:26:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:26:03 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:26:03 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:26:03 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:26:03 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:26:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:26:03 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:26:04 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 18:26:04 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 18:26:04 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 18:26:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:26:04 INFO DAGScheduler: Missing parents: List()
19/01/24 18:26:04 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 18:26:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 18:26:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 18:26:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53510 (size: 3.4 KB, free: 366.3 MB)
19/01/24 18:26:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 18:26:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 18:26:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 18:26:04 INFO Executor: Fetching spark://127.0.0.1:53469/jars/sparklyr-2.2-2.11.jar with timestamp 1548350757430
19/01/24 18:26:04 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53469 after 15 ms (0 ms spent in bootstraps)
19/01/24 18:26:04 INFO Utils: Fetching spark://127.0.0.1:53469/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-2fa59193-483a-4b3b-8929-81474329c33b\userFiles-1b80d16c-cdc9-4a6c-bc0f-63af7514929c\fetchFileTemp3257442087514529091.tmp
19/01/24 18:26:04 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-2fa59193-483a-4b3b-8929-81474329c33b/userFiles-1b80d16c-cdc9-4a6c-bc0f-63af7514929c/sparklyr-2.2-2.11.jar to class loader
19/01/24 18:26:04 INFO CodeGenerator: Code generated in 153.792519 ms
19/01/24 18:26:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/01/24 18:26:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 501 ms on localhost (executor driver) (1/1)
19/01/24 18:26:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 18:26:05 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,518 s
19/01/24 18:26:05 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,707866 s
19/01/24 18:26:05 INFO SparkSqlParser: Parsing command: reviews
19/01/24 18:26:05 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 18:26:05 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 18:26:05 INFO CodeGenerator: Code generated in 13.907508 ms
19/01/24 18:26:05 INFO CodeGenerator: Code generated in 8.068739 ms
19/01/24 18:26:05 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 18:26:05 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 18:26:05 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 18:26:05 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 18:26:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 18:26:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 18:26:05 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 18:26:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 18:26:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 18:26:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53510 (size: 7.7 KB, free: 366.3 MB)
19/01/24 18:26:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 18:26:05 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:26:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:26:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 18:26:06 INFO CodeGenerator: Code generated in 10.056568 ms
19/01/24 18:26:06 INFO CodeGenerator: Code generated in 20.143404 ms
19/01/24 18:26:06 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.4 MB)
19/01/24 18:26:06 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:53510 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 18:26:06 INFO CodeGenerator: Code generated in 4.630609 ms
19/01/24 18:26:06 INFO CodeGenerator: Code generated in 17.152727 ms
19/01/24 18:26:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 18:26:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 397 ms on localhost (executor driver) (1/1)
19/01/24 18:26:06 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 18:26:06 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,398 s
19/01/24 18:26:06 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:26:06 INFO DAGScheduler: running: Set()
19/01/24 18:26:06 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 18:26:06 INFO DAGScheduler: failed: Set()
19/01/24 18:26:06 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 18:26:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:26:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:26:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53510 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:26:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 18:26:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:26:06 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 18:26:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/01/24 18:26:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
19/01/24 18:26:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (executor driver) (1/1)
19/01/24 18:26:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 18:26:06 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,029 s
19/01/24 18:26:06 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,468292 s
19/01/24 18:26:06 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 18:26:06 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:26:06 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:26:06 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53510 in memory (size: 3.4 KB, free: 364.5 MB)
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 18:26:06 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 18:26:06 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53510 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:26:06 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53510 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 18:26:06 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 18:26:06 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:26:06 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 18:26:06 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:26:06 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 18:26:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 18:26:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 18:26:06 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 18:26:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 18:26:06 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.5 MB)
19/01/24 18:26:06 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53510 (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:26:06 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:06 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 18:26:06 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:26:06 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:26:06 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 18:26:06 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:26:06 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
19/01/24 18:26:06 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 44 ms on localhost (executor driver) (1/1)
19/01/24 18:26:06 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 18:26:06 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,044 s
19/01/24 18:26:06 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:26:06 INFO DAGScheduler: running: Set()
19/01/24 18:26:06 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 18:26:06 INFO DAGScheduler: failed: Set()
19/01/24 18:26:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 18:26:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:26:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:26:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53510 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:26:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 18:26:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:26:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 18:26:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:26:06 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/01/24 18:26:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
19/01/24 18:26:06 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 18:26:06 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,007 s
19/01/24 18:26:06 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,068006 s
19/01/24 18:26:06 INFO CodeGenerator: Code generated in 8.540261 ms
19/01/24 18:26:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz1`
WHERE (0 = 1)
19/01/24 18:26:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 18:26:11 INFO SparkSqlParser: Parsing command: sparklyr_tmp_5854104426c1
19/01/24 18:26:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_5854104426c1` AS `zzz2`
WHERE (0 = 1)
19/01/24 18:26:11 INFO SparkSqlParser: Parsing command: sparklyr_tmp_585425f42217
19/01/24 18:26:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_585425f42217` AS `zzz3`
WHERE (0 = 1)
19/01/24 18:26:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_5854104426c1`
19/01/24 18:26:11 INFO CodeGenerator: Code generated in 28.002821 ms
19/01/24 18:26:12 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:26:12 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 18:26:12 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:26:12 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 18:26:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 18:26:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 18:26:12 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:26:12 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 18:26:12 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 18:26:12 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53510 (size: 13.0 KB, free: 364.5 MB)
19/01/24 18:26:12 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:12 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 18:26:12 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:26:12 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:26:12 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 18:26:12 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:26:12 INFO CodeGenerator: Code generated in 13.317103 ms
19/01/24 18:26:12 INFO CodeGenerator: Code generated in 12.228556 ms
19/01/24 18:26:12 INFO CodeGenerator: Code generated in 9.957012 ms
19/01/24 18:26:12 INFO CodeGenerator: Code generated in 10.173627 ms
19/01/24 18:26:12 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53510 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:26:12 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 18:26:12 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53510 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:26:12 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1951 bytes result sent to driver
19/01/24 18:26:12 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 707 ms on localhost (executor driver) (1/1)
19/01/24 18:26:12 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 18:26:12 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 0,707 s
19/01/24 18:26:12 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:26:12 INFO DAGScheduler: running: Set()
19/01/24 18:26:12 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 18:26:12 INFO DAGScheduler: failed: Set()
19/01/24 18:26:12 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:26:12 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 18:26:12 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 18:26:12 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53510 (size: 1887.0 B, free: 364.5 MB)
19/01/24 18:26:12 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:12 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 18:26:12 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:26:12 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 18:26:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:26:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:26:12 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 18:26:12 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:53510 (size: 686.3 KB, free: 363.8 MB)
19/01/24 18:26:12 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1830 bytes result sent to driver
19/01/24 18:26:12 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 109 ms on localhost (executor driver) (1/1)
19/01/24 18:26:12 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 18:26:12 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,110 s
19/01/24 18:26:12 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 0,843437 s
19/01/24 18:26:12 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:26:12 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 18:26:12 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:26:12 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 18:26:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 18:26:12 INFO DAGScheduler: Missing parents: List()
19/01/24 18:26:12 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:26:12 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.8 MB)
19/01/24 18:26:12 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.8 MB)
19/01/24 18:26:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53510 (size: 2.2 KB, free: 363.8 MB)
19/01/24 18:26:12 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:12 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 18:26:12 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:26:12 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 18:26:12 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 18:26:12 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 18:26:13 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 47 ms on localhost (executor driver) (1/1)
19/01/24 18:26:13 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 18:26:13 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,047 s
19/01/24 18:26:13 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,062483 s
19/01/24 18:26:13 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 18:26:13 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.6 MB)
19/01/24 18:26:13 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53510 (size: 89.8 KB, free: 363.7 MB)
19/01/24 18:26:13 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 18:26:13 INFO CodeGenerator: Code generated in 24.394754 ms
19/01/24 18:26:13 INFO Instrumentation: NaiveBayes-naive_bayes_585465e2644-778736619-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 18:26:13 INFO Instrumentation: NaiveBayes-naive_bayes_585465e2644-778736619-1: {"smoothing":1.0,"featuresCol":"vectorizer_output","modelType":"multinomial","labelCol":"Sentiment","predictionCol":"prediction","rawPredictionCol":"rawPrediction","probabilityCol":"probability"}
19/01/24 18:26:13 INFO CodeGenerator: Code generated in 16.884692 ms
19/01/24 18:26:13 INFO SparkContext: Starting job: head at NaiveBayes.scala:154
19/01/24 18:26:13 INFO DAGScheduler: Got job 5 (head at NaiveBayes.scala:154) with 1 output partitions
19/01/24 18:26:13 INFO DAGScheduler: Final stage: ResultStage 9 (head at NaiveBayes.scala:154)
19/01/24 18:26:13 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:26:13 INFO DAGScheduler: Missing parents: List()
19/01/24 18:26:13 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154), which has no missing parents
19/01/24 18:26:13 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 113.1 KB, free 362.4 MB)
19/01/24 18:26:13 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 72.9 KB, free 362.4 MB)
19/01/24 18:26:13 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53510 (size: 72.9 KB, free: 363.6 MB)
19/01/24 18:26:13 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:13 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 18:26:13 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:26:13 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:26:13 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 18:26:13 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:26:13 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 1743 bytes result sent to driver
19/01/24 18:26:13 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 80 ms on localhost (executor driver) (1/1)
19/01/24 18:26:13 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 18:26:13 INFO DAGScheduler: ResultStage 9 (head at NaiveBayes.scala:154) finished in 0,081 s
19/01/24 18:26:13 INFO DAGScheduler: Job 5 finished: head at NaiveBayes.scala:154, took 0,089043 s
19/01/24 18:26:13 INFO CodeGenerator: Code generated in 5.733743 ms
19/01/24 18:26:13 INFO Instrumentation: NaiveBayes-naive_bayes_585465e2644-778736619-1: {"numFeatures":8098}
19/01/24 18:26:13 INFO CodeGenerator: Code generated in 25.702104 ms
19/01/24 18:26:13 INFO ContextCleaner: Cleaned accumulator 260
19/01/24 18:26:13 INFO ContextCleaner: Cleaned accumulator 261
19/01/24 18:26:13 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53510 in memory (size: 72.9 KB, free: 363.7 MB)
19/01/24 18:26:13 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53510 in memory (size: 1887.0 B, free: 363.7 MB)
19/01/24 18:26:13 INFO ContextCleaner: Cleaned accumulator 257
19/01/24 18:26:13 INFO ContextCleaner: Cleaned accumulator 259
19/01/24 18:26:13 INFO ContextCleaner: Cleaned accumulator 258
19/01/24 18:26:13 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53510 in memory (size: 2.2 KB, free: 363.7 MB)
19/01/24 18:26:13 INFO ContextCleaner: Cleaned accumulator 262
19/01/24 18:26:13 INFO SparkContext: Starting job: collect at NaiveBayes.scala:174
19/01/24 18:26:13 INFO DAGScheduler: Registering RDD 43 (map at NaiveBayes.scala:162)
19/01/24 18:26:13 INFO DAGScheduler: Got job 6 (collect at NaiveBayes.scala:174) with 1 output partitions
19/01/24 18:26:13 INFO DAGScheduler: Final stage: ResultStage 11 (collect at NaiveBayes.scala:174)
19/01/24 18:26:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/01/24 18:26:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/01/24 18:26:13 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162), which has no missing parents
19/01/24 18:26:13 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 243.7 KB, free 362.3 MB)
19/01/24 18:26:13 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 76.0 KB, free 362.3 MB)
19/01/24 18:26:13 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53510 (size: 76.0 KB, free: 363.6 MB)
19/01/24 18:26:13 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:13 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 18:26:13 WARN TaskSetManager: Stage 10 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:26:13 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:26:13 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 18:26:13 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:26:13 INFO CodeGenerator: Code generated in 6.10899 ms
19/01/24 18:26:14 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1865 bytes result sent to driver
19/01/24 18:26:14 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 427 ms on localhost (executor driver) (1/1)
19/01/24 18:26:14 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 18:26:14 INFO DAGScheduler: ShuffleMapStage 10 (map at NaiveBayes.scala:162) finished in 0,428 s
19/01/24 18:26:14 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:26:14 INFO DAGScheduler: running: Set()
19/01/24 18:26:14 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/01/24 18:26:14 INFO DAGScheduler: failed: Set()
19/01/24 18:26:14 INFO DAGScheduler: Submitting ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163), which has no missing parents
19/01/24 18:26:14 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 244.4 KB, free 362.0 MB)
19/01/24 18:26:14 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 76.4 KB, free 361.9 MB)
19/01/24 18:26:14 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53510 (size: 76.4 KB, free: 363.6 MB)
19/01/24 18:26:14 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:14 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 18:26:14 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:26:14 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 18:26:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:26:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:26:14 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 132363 bytes result sent to driver
19/01/24 18:26:14 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 10 ms on localhost (executor driver) (1/1)
19/01/24 18:26:14 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 18:26:14 INFO DAGScheduler: ResultStage 11 (collect at NaiveBayes.scala:174) finished in 0,011 s
19/01/24 18:26:14 INFO DAGScheduler: Job 6 finished: collect at NaiveBayes.scala:174, took 0,460239 s
19/01/24 18:26:14 INFO Instrumentation: NaiveBayes-naive_bayes_585465e2644-778736619-1: {"numClasses":2}
19/01/24 18:26:14 INFO Instrumentation: NaiveBayes-naive_bayes_585465e2644-778736619-1: training finished
19/01/24 18:26:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_585425f42217`
19/01/24 18:26:37 INFO SparkSqlParser: Parsing command: sparklyr_tmp_5854439d410e
19/01/24 18:26:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_5854439d410e` AS `zzz4`
WHERE (0 = 1)
19/01/24 18:26:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:26:37 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:26:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:26:37 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:26:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:26:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:26:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:26:37 INFO CodeGenerator: Code generated in 6.23152 ms
19/01/24 18:26:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:26:37 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:26:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:26:37 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:26:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:26:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:26:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:26:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:26:38 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:26:38 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:26:38 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:26:38 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:26:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:26:38 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:26:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_5854104426c1`
19/01/24 18:26:44 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:26:44 INFO DAGScheduler: Registering RDD 50 (flatMap at CountVectorizer.scala:163)
19/01/24 18:26:44 INFO DAGScheduler: Got job 7 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:26:44 INFO DAGScheduler: Final stage: ResultStage 13 (count at CountVectorizer.scala:176)
19/01/24 18:26:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/01/24 18:26:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/01/24 18:26:44 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[50] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 28.5 KB, free 361.9 MB)
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KB, free 361.9 MB)
19/01/24 18:26:44 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53510 (size: 13.0 KB, free: 363.5 MB)
19/01/24 18:26:44 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[50] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:44 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 18:26:44 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:26:44 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:26:44 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 18:26:44 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:26:44 INFO CodeGenerator: Code generated in 13.774402 ms
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 291
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 253
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 292
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 289
19/01/24 18:26:44 INFO ContextCleaner: Cleaned shuffle 3
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 287
19/01/24 18:26:44 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53510 in memory (size: 76.0 KB, free: 363.6 MB)
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 288
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 290
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 251
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 252
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 255
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 256
19/01/24 18:26:44 INFO ContextCleaner: Cleaned accumulator 254
19/01/24 18:26:44 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53510 in memory (size: 76.4 KB, free: 363.7 MB)
19/01/24 18:26:44 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 1951 bytes result sent to driver
19/01/24 18:26:44 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 346 ms on localhost (executor driver) (1/1)
19/01/24 18:26:44 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 18:26:44 INFO DAGScheduler: ShuffleMapStage 12 (flatMap at CountVectorizer.scala:163) finished in 0,347 s
19/01/24 18:26:44 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:26:44 INFO DAGScheduler: running: Set()
19/01/24 18:26:44 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/01/24 18:26:44 INFO DAGScheduler: failed: Set()
19/01/24 18:26:44 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[53] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.2 KB, free 362.5 MB)
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 1887.0 B, free 362.5 MB)
19/01/24 18:26:44 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53510 (size: 1887.0 B, free: 363.7 MB)
19/01/24 18:26:44 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[53] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:44 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 18:26:44 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:26:44 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 18:26:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:26:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:26:44 INFO MemoryStore: Block rdd_53_0 stored as values in memory (estimated size 686.3 KB, free 361.9 MB)
19/01/24 18:26:44 INFO BlockManagerInfo: Added rdd_53_0 in memory on 127.0.0.1:53510 (size: 686.3 KB, free: 363.0 MB)
19/01/24 18:26:44 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 1787 bytes result sent to driver
19/01/24 18:26:44 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 54 ms on localhost (executor driver) (1/1)
19/01/24 18:26:44 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 18:26:44 INFO DAGScheduler: ResultStage 13 (count at CountVectorizer.scala:176) finished in 0,054 s
19/01/24 18:26:44 INFO DAGScheduler: Job 7 finished: count at CountVectorizer.scala:176, took 0,415735 s
19/01/24 18:26:44 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:26:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 143 bytes
19/01/24 18:26:44 INFO DAGScheduler: Got job 8 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:26:44 INFO DAGScheduler: Final stage: ResultStage 15 (top at CountVectorizer.scala:179)
19/01/24 18:26:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/01/24 18:26:44 INFO DAGScheduler: Missing parents: List()
19/01/24 18:26:44 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 4.2 KB, free 361.8 MB)
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.2 KB, free 361.8 MB)
19/01/24 18:26:44 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53510 (size: 2.2 KB, free: 363.0 MB)
19/01/24 18:26:44 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:44 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/01/24 18:26:44 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:26:44 INFO Executor: Running task 0.0 in stage 15.0 (TID 13)
19/01/24 18:26:44 INFO BlockManager: Found block rdd_53_0 locally
19/01/24 18:26:44 INFO Executor: Finished task 0.0 in stage 15.0 (TID 13). 174348 bytes result sent to driver
19/01/24 18:26:44 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 13) in 15 ms on localhost (executor driver) (1/1)
19/01/24 18:26:44 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 18:26:44 INFO DAGScheduler: ResultStage 15 (top at CountVectorizer.scala:179) finished in 0,016 s
19/01/24 18:26:44 INFO DAGScheduler: Job 8 finished: top at CountVectorizer.scala:179, took 0,022124 s
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 1137.7 KB, free 360.7 MB)
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 89.8 KB, free 360.6 MB)
19/01/24 18:26:44 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53510 (size: 89.8 KB, free: 362.9 MB)
19/01/24 18:26:44 INFO SparkContext: Created broadcast 15 from broadcast at CountVectorizer.scala:244
19/01/24 18:26:44 INFO CodeGenerator: Code generated in 11.431382 ms
19/01/24 18:26:44 INFO CodeGenerator: Code generated in 14.808248 ms
19/01/24 18:26:44 INFO SparkContext: Starting job: take at Classifier.scala:111
19/01/24 18:26:44 INFO DAGScheduler: Registering RDD 57 (take at Classifier.scala:111)
19/01/24 18:26:44 INFO DAGScheduler: Got job 9 (take at Classifier.scala:111) with 1 output partitions
19/01/24 18:26:44 INFO DAGScheduler: Final stage: ResultStage 17 (take at Classifier.scala:111)
19/01/24 18:26:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
19/01/24 18:26:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
19/01/24 18:26:44 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[57] at take at Classifier.scala:111), which has no missing parents
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 25.0 KB, free 360.6 MB)
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 11.3 KB, free 360.6 MB)
19/01/24 18:26:44 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53510 (size: 11.3 KB, free: 362.9 MB)
19/01/24 18:26:44 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[57] at take at Classifier.scala:111) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:44 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/01/24 18:26:44 WARN TaskSetManager: Stage 16 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:26:44 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:26:44 INFO Executor: Running task 0.0 in stage 16.0 (TID 14)
19/01/24 18:26:44 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:26:44 INFO Executor: Finished task 0.0 in stage 16.0 (TID 14). 2256 bytes result sent to driver
19/01/24 18:26:44 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 14) in 60 ms on localhost (executor driver) (1/1)
19/01/24 18:26:44 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/01/24 18:26:44 INFO DAGScheduler: ShuffleMapStage 16 (take at Classifier.scala:111) finished in 0,061 s
19/01/24 18:26:44 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:26:44 INFO DAGScheduler: running: Set()
19/01/24 18:26:44 INFO DAGScheduler: waiting: Set(ResultStage 17)
19/01/24 18:26:44 INFO DAGScheduler: failed: Set()
19/01/24 18:26:44 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[60] at take at Classifier.scala:111), which has no missing parents
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.2 KB, free 360.6 MB)
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.9 KB, free 360.6 MB)
19/01/24 18:26:44 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53510 (size: 3.9 KB, free: 362.9 MB)
19/01/24 18:26:44 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[60] at take at Classifier.scala:111) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:44 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/01/24 18:26:44 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:26:44 INFO Executor: Running task 0.0 in stage 17.0 (TID 15)
19/01/24 18:26:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:26:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:26:44 INFO Executor: Finished task 0.0 in stage 17.0 (TID 15). 1465 bytes result sent to driver
19/01/24 18:26:44 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 15) in 6 ms on localhost (executor driver) (1/1)
19/01/24 18:26:44 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 18:26:44 INFO DAGScheduler: ResultStage 17 (take at Classifier.scala:111) finished in 0,006 s
19/01/24 18:26:44 INFO DAGScheduler: Job 9 finished: take at Classifier.scala:111, took 0,077875 s
19/01/24 18:26:44 INFO CodeGenerator: Code generated in 4.36768 ms
19/01/24 18:26:44 INFO RandomForestClassifier: org.apache.spark.ml.classification.RandomForestClassifier inferred 2 classes for labelCol=random_forest_classifier_58547c474837__labelCol since numClasses was not specified in the column metadata.
19/01/24 18:26:44 INFO CodeGenerator: Code generated in 16.350447 ms
19/01/24 18:26:44 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_58547c474837-1518715725-2: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 18:26:44 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_58547c474837-1518715725-2: {"subsamplingRate":1.0,"impurity":"gini","featuresCol":"vectorizer_output","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"Sentiment","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"rawPredictionCol":"rawPrediction","probabilityCol":"probability","numTrees":20}
19/01/24 18:26:44 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:112
19/01/24 18:26:44 INFO DAGScheduler: Got job 10 (take at DecisionTreeMetadata.scala:112) with 1 output partitions
19/01/24 18:26:44 INFO DAGScheduler: Final stage: ResultStage 18 (take at DecisionTreeMetadata.scala:112)
19/01/24 18:26:44 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:26:44 INFO DAGScheduler: Missing parents: List()
19/01/24 18:26:44 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[67] at map at DecisionTreeMetadata.scala:112), which has no missing parents
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 115.2 KB, free 360.5 MB)
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 74.3 KB, free 360.4 MB)
19/01/24 18:26:44 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53510 (size: 74.3 KB, free: 362.8 MB)
19/01/24 18:26:44 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[67] at map at DecisionTreeMetadata.scala:112) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:44 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/01/24 18:26:44 WARN TaskSetManager: Stage 18 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:26:44 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:26:44 INFO Executor: Running task 0.0 in stage 18.0 (TID 16)
19/01/24 18:26:44 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:26:44 INFO CodeGenerator: Code generated in 5.816888 ms
19/01/24 18:26:44 INFO Executor: Finished task 0.0 in stage 18.0 (TID 16). 1625 bytes result sent to driver
19/01/24 18:26:44 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 16) in 57 ms on localhost (executor driver) (1/1)
19/01/24 18:26:44 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/01/24 18:26:44 INFO DAGScheduler: ResultStage 18 (take at DecisionTreeMetadata.scala:112) finished in 0,058 s
19/01/24 18:26:44 INFO DAGScheduler: Job 10 finished: take at DecisionTreeMetadata.scala:112, took 0,068166 s
19/01/24 18:26:44 INFO SparkContext: Starting job: count at DecisionTreeMetadata.scala:118
19/01/24 18:26:44 INFO DAGScheduler: Got job 11 (count at DecisionTreeMetadata.scala:118) with 1 output partitions
19/01/24 18:26:44 INFO DAGScheduler: Final stage: ResultStage 19 (count at DecisionTreeMetadata.scala:118)
19/01/24 18:26:44 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:26:44 INFO DAGScheduler: Missing parents: List()
19/01/24 18:26:44 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[66] at retag at RandomForest.scala:103), which has no missing parents
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 114.8 KB, free 360.3 MB)
19/01/24 18:26:44 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 74.1 KB, free 360.2 MB)
19/01/24 18:26:44 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53510 (size: 74.1 KB, free: 362.8 MB)
19/01/24 18:26:44 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[66] at retag at RandomForest.scala:103) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:44 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/01/24 18:26:44 WARN TaskSetManager: Stage 19 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:26:44 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:26:44 INFO Executor: Running task 0.0 in stage 19.0 (TID 17)
19/01/24 18:26:44 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:26:45 INFO ContextCleaner: Cleaned shuffle 5
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 344
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 342
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 345
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 421
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 423
19/01/24 18:26:45 INFO BlockManager: Removing RDD 53
19/01/24 18:26:45 INFO ContextCleaner: Cleaned RDD 53
19/01/24 18:26:45 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53510 in memory (size: 11.3 KB, free: 363.5 MB)
19/01/24 18:26:45 INFO ContextCleaner: Cleaned shuffle 4
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 430
19/01/24 18:26:45 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53510 in memory (size: 2.2 KB, free: 363.5 MB)
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 429
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 435
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 420
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 346
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 428
19/01/24 18:26:45 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53510 in memory (size: 1887.0 B, free: 363.5 MB)
19/01/24 18:26:45 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53510 in memory (size: 74.3 KB, free: 363.5 MB)
19/01/24 18:26:45 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53510 in memory (size: 13.0 KB, free: 363.5 MB)
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 424
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 432
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 433
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 422
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 425
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 427
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 431
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 419
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 341
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 343
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 426
19/01/24 18:26:45 INFO ContextCleaner: Cleaned accumulator 434
19/01/24 18:26:45 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53510 in memory (size: 3.9 KB, free: 363.5 MB)
19/01/24 18:26:45 INFO Executor: Finished task 0.0 in stage 19.0 (TID 17). 1719 bytes result sent to driver
19/01/24 18:26:45 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 17) in 359 ms on localhost (executor driver) (1/1)
19/01/24 18:26:45 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/01/24 18:26:45 INFO DAGScheduler: ResultStage 19 (count at DecisionTreeMetadata.scala:118) finished in 0,359 s
19/01/24 18:26:45 INFO DAGScheduler: Job 11 finished: count at DecisionTreeMetadata.scala:118, took 0,366672 s
19/01/24 18:26:45 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_58547c474837-1518715725-2: {"numFeatures":8098}
19/01/24 18:26:45 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_58547c474837-1518715725-2: {"numClasses":2}
19/01/24 18:26:45 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:928
19/01/24 18:26:45 INFO DAGScheduler: Registering RDD 69 (flatMap at RandomForest.scala:921)
19/01/24 18:26:45 INFO DAGScheduler: Got job 12 (collectAsMap at RandomForest.scala:928) with 1 output partitions
19/01/24 18:26:45 INFO DAGScheduler: Final stage: ResultStage 21 (collectAsMap at RandomForest.scala:928)
19/01/24 18:26:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/01/24 18:26:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/01/24 18:26:45 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[69] at flatMap at RandomForest.scala:921), which has no missing parents
19/01/24 18:26:45 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 199.7 KB, free 361.0 MB)
19/01/24 18:26:45 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 108.0 KB, free 360.9 MB)
19/01/24 18:26:45 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53510 (size: 108.0 KB, free: 363.4 MB)
19/01/24 18:26:45 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/01/24 18:26:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[69] at flatMap at RandomForest.scala:921) (first 15 tasks are for partitions Vector(0))
19/01/24 18:26:45 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/01/24 18:26:45 WARN TaskSetManager: Stage 20 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:26:45 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914234 bytes)
19/01/24 18:26:45 INFO Executor: Running task 0.0 in stage 20.0 (TID 18)
19/01/24 18:26:45 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:26:46 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53510 in memory (size: 74.1 KB, free: 363.5 MB)
19/01/24 18:27:02 INFO Executor: Finished task 0.0 in stage 20.0 (TID 18). 1865 bytes result sent to driver
19/01/24 18:27:02 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 18) in 17078 ms on localhost (executor driver) (1/1)
19/01/24 18:27:02 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/01/24 18:27:02 INFO DAGScheduler: ShuffleMapStage 20 (flatMap at RandomForest.scala:921) finished in 17,078 s
19/01/24 18:27:02 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:27:02 INFO DAGScheduler: running: Set()
19/01/24 18:27:02 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/01/24 18:27:02 INFO DAGScheduler: failed: Set()
19/01/24 18:27:02 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[71] at map at RandomForest.scala:923), which has no missing parents
19/01/24 18:27:02 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 233.7 KB, free 360.8 MB)
19/01/24 18:27:02 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 109.7 KB, free 360.7 MB)
19/01/24 18:27:02 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53510 (size: 109.7 KB, free: 363.4 MB)
19/01/24 18:27:02 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/01/24 18:27:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[71] at map at RandomForest.scala:923) (first 15 tasks are for partitions Vector(0))
19/01/24 18:27:02 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/01/24 18:27:02 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 19, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:27:02 INFO Executor: Running task 0.0 in stage 21.0 (TID 19)
19/01/24 18:27:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:27:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 114
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 123
19/01/24 18:27:03 INFO ContextCleaner: Cleaned shuffle 1
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 122
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 178
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 113
19/01/24 18:27:03 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53510 in memory (size: 108.0 KB, free: 363.5 MB)
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 121
19/01/24 18:27:03 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 120
19/01/24 18:27:03 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53510 in memory (size: 13.0 KB, free: 363.5 MB)
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 175
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 117
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 124
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 176
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 116
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 174
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 177
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 119
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 115
19/01/24 18:27:03 INFO BlockManager: Removing RDD 30
19/01/24 18:27:03 INFO ContextCleaner: Cleaned RDD 30
19/01/24 18:27:03 INFO ContextCleaner: Cleaned accumulator 118
19/01/24 18:27:04 ERROR Executor: Exception in task 0.0 in stage 21.0 (TID 19)
java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
19/01/24 18:27:04 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 19,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
19/01/24 18:27:04 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 18:27:04 WARN TaskSetManager: Lost task 0.0 in stage 21.0 (TID 19, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)

19/01/24 18:27:04 ERROR TaskSetManager: Task 0 in stage 21.0 failed 1 times; aborting job
19/01/24 18:27:04 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/01/24 18:27:05 INFO TaskSchedulerImpl: Cancelling stage 21
19/01/24 18:27:05 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 18:27:05 INFO DAGScheduler: ResultStage 21 (collectAsMap at RandomForest.scala:928) failed in 2,567 s due to Job aborted due to stage failure: Task 0 in stage 21.0 failed 1 times, most recent failure: Lost task 0.0 in stage 21.0 (TID 19, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)

Driver stacktrace:
19/01/24 18:27:05 INFO DAGScheduler: Job 12 failed: collectAsMap at RandomForest.scala:928, took 19,667930 s
19/01/24 18:27:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 18:27:05 INFO MemoryStore: MemoryStore cleared
19/01/24 18:27:05 INFO BlockManager: BlockManager stopped
19/01/24 18:27:05 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 18:27:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 18:27:05 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-2fa59193-483a-4b3b-8929-81474329c33b\userFiles-1b80d16c-cdc9-4a6c-bc0f-63af7514929c
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-2fa59193-483a-4b3b-8929-81474329c33b\userFiles-1b80d16c-cdc9-4a6c-bc0f-63af7514929c
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:27:05 INFO SparkContext: Successfully stopped SparkContext
19/01/24 18:27:05 INFO ShutdownHookManager: Shutdown hook called
19/01/24 18:27:05 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-2fa59193-483a-4b3b-8929-81474329c33b
19/01/24 18:27:05 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-2fa59193-483a-4b3b-8929-81474329c33b
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-2fa59193-483a-4b3b-8929-81474329c33b
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:27:05 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-2fa59193-483a-4b3b-8929-81474329c33b\userFiles-1b80d16c-cdc9-4a6c-bc0f-63af7514929c
19/01/24 18:27:05 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-2fa59193-483a-4b3b-8929-81474329c33b\userFiles-1b80d16c-cdc9-4a6c-bc0f-63af7514929c
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-2fa59193-483a-4b3b-8929-81474329c33b\userFiles-1b80d16c-cdc9-4a6c-bc0f-63af7514929c
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:29:00 INFO SparkContext: Running Spark version 2.2.0
19/01/24 18:29:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 18:29:00 INFO SparkContext: Submitted application: sparklyr
19/01/24 18:29:00 INFO SecurityManager: Changing view acls to: yanis
19/01/24 18:29:00 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 18:29:00 INFO SecurityManager: Changing view acls groups to: 
19/01/24 18:29:00 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 18:29:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 18:29:00 INFO Utils: Successfully started service 'sparkDriver' on port 53654.
19/01/24 18:29:00 INFO SparkEnv: Registering MapOutputTracker
19/01/24 18:29:00 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 18:29:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 18:29:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 18:29:00 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-6fa56585-ac56-4507-9293-8a2213c61f5f
19/01/24 18:29:00 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 18:29:01 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 18:29:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 18:29:01 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 18:29:01 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:53654/jars/sparklyr-2.2-2.11.jar with timestamp 1548350941239
19/01/24 18:29:01 INFO Executor: Starting executor ID driver on host localhost
19/01/24 18:29:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53695.
19/01/24 18:29:01 INFO NettyBlockTransferService: Server created on 127.0.0.1:53695
19/01/24 18:29:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 18:29:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53695, None)
19/01/24 18:29:01 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53695 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53695, None)
19/01/24 18:29:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53695, None)
19/01/24 18:29:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53695, None)
19/01/24 18:29:01 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 18:29:01 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 18:29:01 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 18:29:01 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 18:29:02 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 18:29:02 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 18:29:02 INFO ObjectStore: ObjectStore, initialize called
19/01/24 18:29:02 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 18:29:02 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 18:29:03 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 18:29:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:29:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:29:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:29:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:29:05 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 18:29:05 INFO ObjectStore: Initialized ObjectStore
19/01/24 18:29:05 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 18:29:05 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 18:29:05 INFO HiveMetaStore: Added admin role in metastore
19/01/24 18:29:05 INFO HiveMetaStore: Added public role in metastore
19/01/24 18:29:05 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 18:29:05 INFO HiveMetaStore: 0: get_all_databases
19/01/24 18:29:05 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 18:29:05 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 18:29:05 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 18:29:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:29:05 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/7cbdeb17-d428-424a-adb9-b47f89915ac8_resources
19/01/24 18:29:05 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/7cbdeb17-d428-424a-adb9-b47f89915ac8
19/01/24 18:29:05 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/7cbdeb17-d428-424a-adb9-b47f89915ac8
19/01/24 18:29:05 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/7cbdeb17-d428-424a-adb9-b47f89915ac8/_tmp_space.db
19/01/24 18:29:05 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:29:05 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:05 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:05 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 18:29:05 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 18:29:05 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 18:29:05 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/8a8bf4b2-a5a2-4032-8724-980d909da5bd_resources
19/01/24 18:29:05 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/8a8bf4b2-a5a2-4032-8724-980d909da5bd
19/01/24 18:29:06 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/8a8bf4b2-a5a2-4032-8724-980d909da5bd
19/01/24 18:29:06 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/8a8bf4b2-a5a2-4032-8724-980d909da5bd/_tmp_space.db
19/01/24 18:29:06 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:29:06 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 18:29:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:29:07 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:07 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:07 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:07 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:29:07 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:29:07 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 18:29:07 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 18:29:07 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 18:29:07 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:07 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 18:29:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 18:29:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 18:29:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53695 (size: 3.4 KB, free: 366.3 MB)
19/01/24 18:29:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 18:29:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 18:29:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 18:29:08 INFO Executor: Fetching spark://127.0.0.1:53654/jars/sparklyr-2.2-2.11.jar with timestamp 1548350941239
19/01/24 18:29:08 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53654 after 17 ms (0 ms spent in bootstraps)
19/01/24 18:29:08 INFO Utils: Fetching spark://127.0.0.1:53654/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-8affd81b-7397-4556-a2e6-8b31601dad31\userFiles-d011e361-25d7-4b7e-adb4-1f2f9c7fd298\fetchFileTemp4530128546912895069.tmp
19/01/24 18:29:08 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-8affd81b-7397-4556-a2e6-8b31601dad31/userFiles-d011e361-25d7-4b7e-adb4-1f2f9c7fd298/sparklyr-2.2-2.11.jar to class loader
19/01/24 18:29:08 INFO CodeGenerator: Code generated in 150.401067 ms
19/01/24 18:29:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/01/24 18:29:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 487 ms on localhost (executor driver) (1/1)
19/01/24 18:29:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 18:29:08 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,504 s
19/01/24 18:29:08 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,692623 s
19/01/24 18:29:09 INFO SparkSqlParser: Parsing command: reviews
19/01/24 18:29:09 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 18:29:09 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 18:29:09 INFO CodeGenerator: Code generated in 14.799495 ms
19/01/24 18:29:09 INFO CodeGenerator: Code generated in 8.628876 ms
19/01/24 18:29:09 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 18:29:09 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 18:29:09 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 18:29:09 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 18:29:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 18:29:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 18:29:09 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 18:29:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 18:29:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 18:29:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53695 (size: 7.7 KB, free: 366.3 MB)
19/01/24 18:29:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 18:29:09 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:29:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 18:29:09 INFO CodeGenerator: Code generated in 8.333491 ms
19/01/24 18:29:09 INFO CodeGenerator: Code generated in 20.221809 ms
19/01/24 18:29:09 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.4 MB)
19/01/24 18:29:09 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:53695 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 18:29:09 INFO CodeGenerator: Code generated in 4.713025 ms
19/01/24 18:29:09 INFO CodeGenerator: Code generated in 20.701353 ms
19/01/24 18:29:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 18:29:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 377 ms on localhost (executor driver) (1/1)
19/01/24 18:29:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 18:29:09 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,379 s
19/01/24 18:29:09 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:29:09 INFO DAGScheduler: running: Set()
19/01/24 18:29:09 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 18:29:09 INFO DAGScheduler: failed: Set()
19/01/24 18:29:09 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 18:29:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:29:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:29:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53695 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:29:09 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 18:29:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:29:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 18:29:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:29:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/01/24 18:29:09 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1538 bytes result sent to driver
19/01/24 18:29:09 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:29:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 18:29:09 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,030 s
19/01/24 18:29:09 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,452769 s
19/01/24 18:29:09 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 18:29:09 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:09 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:09 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53695 in memory (size: 3.4 KB, free: 364.5 MB)
19/01/24 18:29:10 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53695 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:29:10 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53695 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 18:29:10 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 18:29:10 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 18:29:10 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:29:10 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 18:29:10 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:29:10 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 18:29:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 18:29:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 18:29:10 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 18:29:10 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 18:29:10 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.5 MB)
19/01/24 18:29:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53695 (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:29:10 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:10 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 18:29:10 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:10 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:29:10 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 18:29:10 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:29:10 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
19/01/24 18:29:10 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 35 ms on localhost (executor driver) (1/1)
19/01/24 18:29:10 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 18:29:10 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,035 s
19/01/24 18:29:10 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:29:10 INFO DAGScheduler: running: Set()
19/01/24 18:29:10 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 18:29:10 INFO DAGScheduler: failed: Set()
19/01/24 18:29:10 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 18:29:10 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:29:10 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:29:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53695 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:29:10 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:10 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 18:29:10 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:29:10 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 18:29:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:29:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:29:10 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/01/24 18:29:10 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 4 ms on localhost (executor driver) (1/1)
19/01/24 18:29:10 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 18:29:10 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,004 s
19/01/24 18:29:10 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,056530 s
19/01/24 18:29:10 INFO CodeGenerator: Code generated in 6.085652 ms
19/01/24 18:29:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz1`
WHERE (0 = 1)
19/01/24 18:29:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 18:29:12 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c85b5643fe
19/01/24 18:29:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c85b5643fe` AS `zzz2`
WHERE (0 = 1)
19/01/24 18:29:12 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c839681fe5
19/01/24 18:29:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c839681fe5` AS `zzz3`
WHERE (0 = 1)
19/01/24 18:29:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c85b5643fe`
19/01/24 18:29:13 INFO CodeGenerator: Code generated in 27.830696 ms
19/01/24 18:29:13 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:29:13 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 18:29:13 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:29:13 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 18:29:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 18:29:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 18:29:13 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:29:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 18:29:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 18:29:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53695 (size: 13.0 KB, free: 364.5 MB)
19/01/24 18:29:13 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:13 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 18:29:13 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:13 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:29:13 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 18:29:13 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:29:13 INFO CodeGenerator: Code generated in 15.076282 ms
19/01/24 18:29:13 INFO CodeGenerator: Code generated in 11.749376 ms
19/01/24 18:29:13 INFO CodeGenerator: Code generated in 9.055542 ms
19/01/24 18:29:13 INFO CodeGenerator: Code generated in 13.249273 ms
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 124
19/01/24 18:29:13 INFO ContextCleaner: Cleaned shuffle 1
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 122
19/01/24 18:29:13 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53695 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 115
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 114
19/01/24 18:29:13 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53695 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 113
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 119
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 123
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 120
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 116
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 117
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 121
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 118
19/01/24 18:29:13 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 18:29:13 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1951 bytes result sent to driver
19/01/24 18:29:13 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 704 ms on localhost (executor driver) (1/1)
19/01/24 18:29:13 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 18:29:13 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 0,704 s
19/01/24 18:29:13 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:29:13 INFO DAGScheduler: running: Set()
19/01/24 18:29:13 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 18:29:13 INFO DAGScheduler: failed: Set()
19/01/24 18:29:13 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:29:13 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 18:29:13 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 18:29:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53695 (size: 1887.0 B, free: 364.5 MB)
19/01/24 18:29:13 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:13 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 18:29:13 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:29:13 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 18:29:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:29:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:29:13 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 18:29:13 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:53695 (size: 686.3 KB, free: 363.8 MB)
19/01/24 18:29:13 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1830 bytes result sent to driver
19/01/24 18:29:13 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 114 ms on localhost (executor driver) (1/1)
19/01/24 18:29:13 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 18:29:13 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,115 s
19/01/24 18:29:13 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 0,847613 s
19/01/24 18:29:13 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:29:13 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 18:29:13 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:29:13 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 18:29:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 18:29:13 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:13 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:29:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.8 MB)
19/01/24 18:29:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.8 MB)
19/01/24 18:29:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53695 (size: 2.2 KB, free: 363.8 MB)
19/01/24 18:29:13 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:13 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 18:29:13 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:29:13 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 18:29:13 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 18:29:14 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 18:29:14 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 45 ms on localhost (executor driver) (1/1)
19/01/24 18:29:14 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 18:29:14 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,045 s
19/01/24 18:29:14 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,057665 s
19/01/24 18:29:14 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 18:29:14 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.6 MB)
19/01/24 18:29:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53695 (size: 89.8 KB, free: 363.7 MB)
19/01/24 18:29:14 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 18:29:14 INFO CodeGenerator: Code generated in 23.712086 ms
19/01/24 18:29:14 INFO CodeGenerator: Code generated in 18.027939 ms
19/01/24 18:29:14 INFO Instrumentation: LogisticRegression-logistic_regression_4c8628a5a2a-1424242246-1: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
19/01/24 18:29:14 INFO Instrumentation: LogisticRegression-logistic_regression_4c8628a5a2a-1424242246-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
19/01/24 18:29:14 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:517
19/01/24 18:29:14 INFO DAGScheduler: Got job 5 (treeAggregate at LogisticRegression.scala:517) with 1 output partitions
19/01/24 18:29:14 INFO DAGScheduler: Final stage: ResultStage 9 (treeAggregate at LogisticRegression.scala:517)
19/01/24 18:29:14 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:14 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:14 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at treeAggregate at LogisticRegression.scala:517), which has no missing parents
19/01/24 18:29:14 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 116.1 KB, free 362.4 MB)
19/01/24 18:29:14 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 74.7 KB, free 362.4 MB)
19/01/24 18:29:14 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 363.6 MB)
19/01/24 18:29:14 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at treeAggregate at LogisticRegression.scala:517) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:14 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 18:29:14 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:14 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:14 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 18:29:14 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:29:14 INFO CodeGenerator: Code generated in 6.701219 ms
19/01/24 18:29:14 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53695 in memory (size: 1887.0 B, free: 363.6 MB)
19/01/24 18:29:14 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53695 in memory (size: 2.2 KB, free: 363.6 MB)
19/01/24 18:29:14 INFO MemoryStore: Block rdd_40_0 stored as values in memory (estimated size 2.5 MB, free 359.8 MB)
19/01/24 18:29:14 INFO BlockManagerInfo: Added rdd_40_0 in memory on 127.0.0.1:53695 (size: 2.5 MB, free: 361.1 MB)
19/01/24 18:29:14 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 524197 bytes result sent to driver
19/01/24 18:29:14 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 550 ms on localhost (executor driver) (1/1)
19/01/24 18:29:14 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 18:29:14 INFO DAGScheduler: ResultStage 9 (treeAggregate at LogisticRegression.scala:517) finished in 0,550 s
19/01/24 18:29:14 INFO DAGScheduler: Job 5 finished: treeAggregate at LogisticRegression.scala:517, took 0,561267 s
19/01/24 18:29:14 INFO Instrumentation: LogisticRegression-logistic_regression_4c8628a5a2a-1424242246-1: {"numClasses":2}
19/01/24 18:29:14 INFO Instrumentation: LogisticRegression-logistic_regression_4c8628a5a2a-1424242246-1: {"numFeatures":8098}
19/01/24 18:29:14 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 63.3 KB, free 359.8 MB)
19/01/24 18:29:14 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.7 KB, free 359.8 MB)
19/01/24 18:29:14 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53695 (size: 7.7 KB, free: 361.1 MB)
19/01/24 18:29:14 INFO SparkContext: Created broadcast 10 from broadcast at LogisticRegression.scala:600
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.2 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 439.0 B, free 359.9 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53695 (size: 439.0 B, free: 361.2 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 11 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 6 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 10 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 116.2 KB, free 359.8 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.7 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.1 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 10 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 68236 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 46 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 10 (treeAggregate at LogisticRegression.scala:1892) finished in 0,048 s
19/01/24 18:29:15 INFO DAGScheduler: Job 6 finished: treeAggregate at LogisticRegression.scala:1892, took 0,056281 s
19/01/24 18:29:15 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/01/24 18:29:15 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(11) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53695 in memory (size: 439.0 B, free: 361.1 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.5 KB, free 359.7 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53695 (size: 23.5 KB, free: 361.1 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 13 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 7 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 11 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[43] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 116.2 KB, free 359.6 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[43] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 11 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 68193 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 11 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 18:29:15 INFO DAGScheduler: Job 7 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038043 s
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(13) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53695 in memory (size: 23.5 KB, free: 361.0 MB)
19/01/24 18:29:15 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:15 INFO LBFGS: Val and Grad Norm: 0,330456 (rel: 0,523) 0,367278
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 57.6 KB, free 359.5 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53695 (size: 57.6 KB, free: 361.0 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 15 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 8 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 12 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 68236 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 35 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 12 (treeAggregate at LogisticRegression.scala:1892) finished in 0,035 s
19/01/24 18:29:15 INFO DAGScheduler: Job 8 finished: treeAggregate at LogisticRegression.scala:1892, took 0,042310 s
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(15) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53695 in memory (size: 57.6 KB, free: 360.9 MB)
19/01/24 18:29:15 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:15 INFO LBFGS: Val and Grad Norm: 0,213198 (rel: 0,355) 0,167363
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.3 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 17 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 9 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 13 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[45] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[45] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 13 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 68236 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 36 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 13 (treeAggregate at LogisticRegression.scala:1892) finished in 0,037 s
19/01/24 18:29:15 INFO DAGScheduler: Job 9 finished: treeAggregate at LogisticRegression.scala:1892, took 0,048048 s
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(17) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:15 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:15 INFO LBFGS: Val and Grad Norm: 0,147331 (rel: 0,309) 0,0949852
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.1 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.8 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 19 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 10 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 14 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 14 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 14.0 (TID 13)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 14.0 (TID 13). 68279 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 13) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 14 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 18:29:15 INFO DAGScheduler: Job 10 finished: treeAggregate at LogisticRegression.scala:1892, took 0,040744 s
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(19) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.8 MB)
19/01/24 18:29:15 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:15 INFO LBFGS: Val and Grad Norm: 0,100491 (rel: 0,318) 0,0613800
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 57.7 KB, free 358.9 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53695 (size: 57.7 KB, free: 360.7 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 21 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 11 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 15 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[47] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[47] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 15 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 15.0 (TID 14)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 15.0 (TID 14). 68279 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 14) in 34 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 15 (treeAggregate at LogisticRegression.scala:1892) finished in 0,035 s
19/01/24 18:29:15 INFO DAGScheduler: Job 11 finished: treeAggregate at LogisticRegression.scala:1892, took 0,043277 s
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(21) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53695 in memory (size: 57.7 KB, free: 360.7 MB)
19/01/24 18:29:15 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:15 INFO LBFGS: Val and Grad Norm: 0,0724526 (rel: 0,279) 0,0316812
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.7 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 23 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 16 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 16 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 16.0 (TID 15)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 16.0 (TID 15). 68279 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 15) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 16 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 18:29:15 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037617 s
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(23) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.6 MB)
19/01/24 18:29:15 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:15 INFO LBFGS: Val and Grad Norm: 0,0587020 (rel: 0,190) 0,0233276
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.5 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.6 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 25 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 17 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[49] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[49] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:15 WARN TaskSetManager: Stage 17 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 17.0 (TID 16)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 17.0 (TID 16). 68236 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 16) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 17 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 18:29:15 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1892, took 0,042292 s
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(25) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:29:15 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:15 INFO LBFGS: Val and Grad Norm: 0,0508755 (rel: 0,133) 0,0191974
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.7 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 27 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 18 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 18 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 18.0 (TID 17)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 18.0 (TID 17). 68193 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 17) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 18 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 18:29:15 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038624 s
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(27) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:15 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:15 INFO LBFGS: Val and Grad Norm: 0,0492985 (rel: 0,0310) 0,0273011
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.5 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 29 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 19 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[51] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[51] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 19 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 19.0 (TID 18)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 19.0 (TID 18). 68193 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 18) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 19 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 18:29:15 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035897 s
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(29) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:15 INFO LBFGS: Val and Grad Norm: 0,0448300 (rel: 0,0906) 0,0186364
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.3 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 31 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 20 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 20 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 20.0 (TID 19)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:15 INFO Executor: Finished task 0.0 in stage 20.0 (TID 19). 68193 bytes result sent to driver
19/01/24 18:29:15 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 19) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:29:15 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/01/24 18:29:15 INFO DAGScheduler: ResultStage 20 (treeAggregate at LogisticRegression.scala:1892) finished in 0,034 s
19/01/24 18:29:15 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1892, took 0,040567 s
19/01/24 18:29:15 INFO TorrentBroadcast: Destroying Broadcast(31) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:15 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:15 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:15 INFO LBFGS: Val and Grad Norm: 0,0396473 (rel: 0,116) 0,0195072
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.1 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.8 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 33 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:15 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:15 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:15 INFO DAGScheduler: Final stage: ResultStage 21 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:15 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:15 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[53] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:15 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:15 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:15 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[53] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:15 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/01/24 18:29:15 WARN TaskSetManager: Stage 21 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:15 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:15 INFO Executor: Running task 0.0 in stage 21.0 (TID 20)
19/01/24 18:29:15 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 21.0 (TID 20). 68193 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 20) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 21 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 18:29:16 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035942 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(33) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.8 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.9 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 35 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 22 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 22.0 (TID 21)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 22.0 (TID 21). 68236 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 21) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:16 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032426 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(35) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO StrongWolfeLineSearch: Line search t: 0.32886824614418664 fval: 0.03927381963744339 rhs: 0.03964717451086121 cdd: 6.991968417275898E-4
19/01/24 18:29:16 INFO LBFGS: Step Size: 0,3289
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0392738 (rel: 0,00942) 0,0181790
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 37 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[55] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[55] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 23 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 23.0 (TID 22)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 23.0 (TID 22). 68236 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 22) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 18:29:16 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035993 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(37) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0379879 (rel: 0,0327) 0,0145010
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 57.6 KB, free 358.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:53695 (size: 57.6 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 39 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 24 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 24.0 (TID 23)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 24.0 (TID 23). 68193 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 23) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:16 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033073 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(39) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:53695 in memory (size: 57.6 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0369358 (rel: 0,0277) 0,0191350
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.3 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.5 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 41 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[57] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[57] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:16 WARN TaskSetManager: Stage 25 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 25.0 (TID 24)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 25.0 (TID 24). 68236 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 24) in 35 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892) finished in 0,036 s
19/01/24 18:29:16 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1892, took 0,049202 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(41) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0363885 (rel: 0,0148) 0,0167591
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 43 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 26 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 26.0 (TID 25)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 26.0 (TID 25). 68193 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 25) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:29:16 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038876 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(43) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 45 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[59] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[59] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 27 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 27.0 (TID 26)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 27.0 (TID 26). 68193 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 26) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 18:29:16 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033059 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(45) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO StrongWolfeLineSearch: Line search t: 0.4108013193598613 fval: 0.03594493422285328 rhs: 0.03638839827048342 cdd: 3.814229000619686E-4
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:16 INFO LBFGS: Step Size: 0,4108
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0359449 (rel: 0,0122) 0,0135038
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.3 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 47 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 28 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 28.0 (TID 27)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 28.0 (TID 27). 68193 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 27) in 45 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892) finished in 0,045 s
19/01/24 18:29:16 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1892, took 0,057058 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(47) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0357242 (rel: 0,00614) 0,00639451
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.0 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 49 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 29 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 29.0 (TID 28)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 29.0 (TID 28). 68236 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 28) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892) finished in 0,033 s
19/01/24 18:29:16 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1892, took 0,075065 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(49) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0353285 (rel: 0,0111) 0,00918555
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.9 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 51 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 30 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 30.0 (TID 29)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 30.0 (TID 29). 68279 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 29) in 57 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892) finished in 0,057 s
19/01/24 18:29:16 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1892, took 0,072777 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(51) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0349337 (rel: 0,0112) 0,00751039
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 53 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 31 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 31.0 (TID 30)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 31.0 (TID 30). 68193 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 30) in 36 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892) finished in 0,037 s
19/01/24 18:29:16 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1892, took 0,046473 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(53) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 55 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 32 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 32.0 (TID 31)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 32.0 (TID 31). 68236 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 31) in 33 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892) finished in 0,033 s
19/01/24 18:29:16 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1892, took 0,042015 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(55) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO StrongWolfeLineSearch: Line search t: 0.17279326617073676 fval: 0.03482345995373003 rhs: 0.03493363733470484 cdd: 9.033313740993744E-4
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO LBFGS: Step Size: 0,1728
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0348235 (rel: 0,00315) 0,0355699
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.3 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 57 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:16 WARN TaskSetManager: Stage 33 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 33.0 (TID 32)
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 33.0 (TID 32). 68236 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 32) in 31 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:29:16 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037819 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(57) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0341632 (rel: 0,0190) 0,00651399
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 59 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 30 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 34 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 34.0 (TID 33)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 34.0 (TID 33). 68193 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 33) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:16 INFO DAGScheduler: Job 30 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027845 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(59) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0339435 (rel: 0,00643) 0,00558368
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 61 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 31 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 35 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 35.0 (TID 34)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 35.0 (TID 34). 68236 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 34) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:16 INFO DAGScheduler: Job 31 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027178 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(61) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0334690 (rel: 0,0140) 0,00643648
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.3 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 63 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 32 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 36 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 36.0 (TID 35)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 36.0 (TID 35). 68193 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 35) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:16 INFO DAGScheduler: Job 32 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027433 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(63) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0326367 (rel: 0,0249) 0,0142538
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.1 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.8 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 65 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 33 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 37 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 37.0 (TID 36)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 37.0 (TID 36). 68236 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 36) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:16 INFO DAGScheduler: Job 33 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030646 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(65) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.8 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0322304 (rel: 0,0124) 0,00481859
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.9 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 67 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 34 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 38 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 38.0 (TID 37)
19/01/24 18:29:16 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:16 INFO Executor: Finished task 0.0 in stage 38.0 (TID 37). 68193 bytes result sent to driver
19/01/24 18:29:16 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 37) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:29:16 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/01/24 18:29:16 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:29:16 INFO DAGScheduler: Job 34 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033694 s
19/01/24 18:29:16 INFO TorrentBroadcast: Destroying Broadcast(67) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:16 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:16 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO LBFGS: Val and Grad Norm: 0,0320398 (rel: 0,00592) 0,00458256
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.7 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 69 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:16 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:16 INFO DAGScheduler: Got job 35 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:16 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:16 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:16 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:16 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:16 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:16 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:16 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:16 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/01/24 18:29:16 WARN TaskSetManager: Stage 39 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:16 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:16 INFO Executor: Running task 0.0 in stage 39.0 (TID 38)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 39.0 (TID 38). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 38) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:29:17 INFO DAGScheduler: Job 35 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033372 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(69) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0317947 (rel: 0,00765) 0,0150047
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 57.3 KB, free 358.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 71 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 36 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 40 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 40.0 (TID 39)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 40.0 (TID 39). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 39) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:17 INFO DAGScheduler: Job 36 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031471 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(71) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0315248 (rel: 0,00849) 0,00508445
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.5 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 73 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 37 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 41 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 41.0 (TID 40)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 41.0 (TID 40). 68236 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 40) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 41 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 18:29:17 INFO DAGScheduler: Job 37 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035813 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(73) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0314268 (rel: 0,00311) 0,00583252
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 75 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 38 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 42 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 42.0 (TID 41)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 42.0 (TID 41). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 41) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 42 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:17 INFO DAGScheduler: Job 38 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027126 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(75) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0312075 (rel: 0,00698) 0,00464233
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 77 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 39 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 43 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[75] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[75] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 43 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 43.0 (TID 42)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 43.0 (TID 42). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 42) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 43 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:17 INFO DAGScheduler: Job 39 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027727 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(77) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0309571 (rel: 0,00802) 0,00454268
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 79 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 40 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 44 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 44 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 44.0 (TID 43)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 44.0 (TID 43). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 43) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 44 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:29:17 INFO DAGScheduler: Job 40 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030605 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(79) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0307409 (rel: 0,00698) 0,00503477
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 81 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 41 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 45 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[77] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[77] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 45 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 45.0 (TID 44)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 45.0 (TID 44). 68236 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 44) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 45 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:29:17 INFO DAGScheduler: Job 41 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032032 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(81) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0304751 (rel: 0,00864) 0,00428555
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.9 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 83 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 42 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 46 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[78] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[78] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 46 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 46.0 (TID 45)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 46.0 (TID 45). 68236 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 45) in 27 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 46 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 18:29:17 INFO DAGScheduler: Job 42 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033500 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(83) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0302014 (rel: 0,00898) 0,00396539
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 57.3 KB, free 358.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 85 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 43 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 47 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[79] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[79] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 47 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 47.0 (TID 46)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 47.0 (TID 46). 68236 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 46) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 47 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:17 INFO DAGScheduler: Job 43 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032259 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(85) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0298543 (rel: 0,0115) 0,00537635
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 87 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 44 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 48 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[80] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[80] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 48 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 48.0 (TID 47)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 48.0 (TID 47). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 47) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 48 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:17 INFO DAGScheduler: Job 44 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032343 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(87) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0296887 (rel: 0,00554) 0,0116162
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 89 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 45 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 49 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[81] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[81] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 49 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 49.0 (TID 48)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 49.0 (TID 48). 68236 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 48) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 49 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:17 INFO DAGScheduler: Job 45 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039738 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(89) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0295122 (rel: 0,00595) 0,00539889
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 63.3 KB, free 358.2 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.2 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.4 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 91 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 46 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 50 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[82] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.1 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[82] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 50 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 50.0 (TID 49)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 50.0 (TID 49). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 49) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 50 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:17 INFO DAGScheduler: Job 46 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027865 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(91) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0294075 (rel: 0,00355) 0,00319102
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 93 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 47 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 51 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[83] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[83] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 51 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 51.0 (TID 50)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 51.0 (TID 50). 68236 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 50) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 51 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:17 INFO DAGScheduler: Job 47 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027040 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(93) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0293339 (rel: 0,00250) 0,00352100
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 95 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 48 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 52 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[84] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[84] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 52 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 52.0 (TID 51)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 52.0 (TID 51). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 51) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 52 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:17 INFO DAGScheduler: Job 48 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028500 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(95) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0292944 (rel: 0,00135) 0,0111846
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 97 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 49 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 53 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[85] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[85] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 53 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 53.0 (TID 52)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 53.0 (TID 52). 68150 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 52) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 53 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:17 INFO DAGScheduler: Job 49 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026912 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(97) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0292388 (rel: 0,00190) 0,00613614
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 99 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 50 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 54 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 54 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 54.0 (TID 53)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 54.0 (TID 53). 68236 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 53) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 54 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:17 INFO DAGScheduler: Job 50 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027481 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(99) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0291668 (rel: 0,00246) 0,00573039
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.9 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 101 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 51 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 55 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 55 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 55.0 (TID 54)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 55.0 (TID 54). 68236 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 54) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 55 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:17 INFO DAGScheduler: Job 51 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032160 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(101) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0291146 (rel: 0,00179) 0,00597272
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 103 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 52 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 56 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 56 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 56.0 (TID 55)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 56.0 (TID 55). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 55) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 56 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:17 INFO DAGScheduler: Job 52 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030279 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(103) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0289667 (rel: 0,00508) 0,00414288
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 57.3 KB, free 358.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 105 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 53 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 57 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 57 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 57.0 (TID 56)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 57.0 (TID 56). 68236 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 56) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 57 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:17 INFO DAGScheduler: Job 53 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031413 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(105) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0288259 (rel: 0,00486) 0,00436637
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 107 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 54 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 58 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 58 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 58.0 (TID 57)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 58.0 (TID 57). 68236 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 57) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 58 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:29:17 INFO DAGScheduler: Job 54 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039313 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(107) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0287244 (rel: 0,00352) 0,00223707
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 109 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 55 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 59 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 59 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 59.0 (TID 58)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 59.0 (TID 58). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 58) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 59 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:17 INFO DAGScheduler: Job 55 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026838 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(109) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0286589 (rel: 0,00228) 0,00213336
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.5 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 361.0 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 111 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 56 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 60 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 60 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 60.0 (TID 59)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 60.0 (TID 59). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 59) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 60 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:17 INFO DAGScheduler: Job 56 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027707 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(111) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0285803 (rel: 0,00274) 0,00415048
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.3 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 113 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 57 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 61 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 61 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 61.0 (TID 60)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 61.0 (TID 60). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 60) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 61 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:17 INFO DAGScheduler: Job 57 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027784 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(113) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.1 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 115 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 58 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 62 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 62 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 62.0 (TID 61)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 62.0 (TID 61). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 61) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 62 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:17 INFO DAGScheduler: Job 58 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028136 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(115) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO StrongWolfeLineSearch: Line search t: 0.4267145302663191 fval: 0.02848748920414812 rhs: 0.028580243313891446 cdd: 5.6037400286210854E-8
19/01/24 18:29:17 INFO LBFGS: Step Size: 0,4267
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.8 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0284875 (rel: 0,00325) 0,00586295
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.9 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 117 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:17 INFO DAGScheduler: Got job 59 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:17 INFO DAGScheduler: Final stage: ResultStage 63 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:17 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:17 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:17 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
19/01/24 18:29:17 WARN TaskSetManager: Stage 63 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:17 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:17 INFO Executor: Running task 0.0 in stage 63.0 (TID 62)
19/01/24 18:29:17 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:17 INFO Executor: Finished task 0.0 in stage 63.0 (TID 62). 68193 bytes result sent to driver
19/01/24 18:29:17 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 62) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:17 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
19/01/24 18:29:17 INFO DAGScheduler: ResultStage 63 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:17 INFO DAGScheduler: Job 59 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027904 s
19/01/24 18:29:17 INFO TorrentBroadcast: Destroying Broadcast(117) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:17 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:17 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:17 INFO LBFGS: Val and Grad Norm: 0,0283739 (rel: 0,00399) 0,00531647
19/01/24 18:29:17 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 119 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 60 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 64 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 64 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 64.0 (TID 63)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 64.0 (TID 63). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 63) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 64 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:18 INFO DAGScheduler: Job 60 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029094 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(119) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0282870 (rel: 0,00306) 0,00553462
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 121 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 61 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 65 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 65 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 65.0 (TID 64)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 65.0 (TID 64). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 64) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 65 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:18 INFO DAGScheduler: Job 61 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027125 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(121) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0282548 (rel: 0,00114) 0,00397435
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.3 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 123 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 62 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 66 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 66 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 66.0 (TID 65)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 66.0 (TID 65). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 65) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 66 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:18 INFO DAGScheduler: Job 62 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028885 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(123) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0282183 (rel: 0,00129) 0,00289874
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 63.3 KB, free 358.2 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.2 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.4 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 125 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 63 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 67 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.1 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 67 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 67.0 (TID 66)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 67.0 (TID 66). 68236 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 66) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 67 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:29:18 INFO DAGScheduler: Job 63 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033467 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(125) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0281719 (rel: 0,00164) 0,00445034
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 127 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 64 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 68 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 68 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 68.0 (TID 67)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 68.0 (TID 67). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 67) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 68 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 18:29:18 INFO DAGScheduler: Job 64 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035961 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(127) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0281092 (rel: 0,00223) 0,00521472
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 129 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 65 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 69 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 69 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 69.0 (TID 68)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 69.0 (TID 68). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 68) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 69 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:29:18 INFO DAGScheduler: Job 65 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034602 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(129) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0280739 (rel: 0,00125) 0,00627099
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.3 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 131 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 66 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 70 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 70 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 70.0 (TID 69)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 70.0 (TID 69). 68236 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 69) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 70 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 18:29:18 INFO DAGScheduler: Job 66 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036239 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(131) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0280154 (rel: 0,00208) 0,00209270
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 133 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 67 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 71 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 71 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 71.0 (TID 70)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 71.0 (TID 70). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 70) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 71 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:18 INFO DAGScheduler: Job 67 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026166 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(133) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0279933 (rel: 0,000787) 0,00174697
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.9 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 135 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 68 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 72 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 72 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 72.0 (TID 71)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 72.0 (TID 71). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 71) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 72 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:18 INFO DAGScheduler: Job 68 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026331 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(135) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0279381 (rel: 0,00197) 0,00168608
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 137 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 69 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 73 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[105] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[105] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 73 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 73.0 (TID 72)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 73.0 (TID 72). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 72) in 20 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 73 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:18 INFO DAGScheduler: Job 69 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026526 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(137) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0278585 (rel: 0,00285) 0,00163783
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 139 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 70 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 74 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[106] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[106] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 74 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 74.0 (TID 73)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 74.0 (TID 73). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 73) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 74 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:18 INFO DAGScheduler: Job 70 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025897 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(139) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0277578 (rel: 0,00361) 0,00180832
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.3 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 141 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 71 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 75 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[107] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[107] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 75 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 75.0 (TID 74)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 75.0 (TID 74). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 74) in 29 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 75 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 18:29:18 INFO DAGScheduler: Job 71 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033347 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(141) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 361.1 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 143 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 72 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 76 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[108] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[108] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 76 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 76.0 (TID 75)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 76.0 (TID 75). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 75) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 76 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:29:18 INFO DAGScheduler: Job 72 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028424 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(143) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO StrongWolfeLineSearch: Line search t: 0.1 fval: 0.027738693432296787 rhs: 0.027757797712281675 cdd: -5.903516402336295E-6
19/01/24 18:29:18 INFO LBFGS: Step Size: 0,1000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0277387 (rel: 0,000688) 0,00422118
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 145 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 73 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 77 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[109] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[109] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 77 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 77.0 (TID 76)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 77.0 (TID 76). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 76) in 52 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 77 (treeAggregate at LogisticRegression.scala:1892) finished in 0,054 s
19/01/24 18:29:18 INFO DAGScheduler: Job 73 finished: treeAggregate at LogisticRegression.scala:1892, took 0,063926 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(145) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0276637 (rel: 0,00270) 0,00155316
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.3 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 147 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 74 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 78 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[110] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[110] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 78 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 78.0 (TID 77)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 78.0 (TID 77). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 77) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 78 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:29:18 INFO DAGScheduler: Job 74 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034200 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(147) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0276344 (rel: 0,00106) 0,00261385
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 149 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 75 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 79 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[111] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[111] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 79 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 79.0 (TID 78)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 79.0 (TID 78). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 78) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 79 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:29:18 INFO DAGScheduler: Job 75 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032921 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(149) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0276142 (rel: 0,000733) 0,00179582
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.9 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 151 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 76 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 80 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[112] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[112] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 80 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 80.0 (TID 79)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 80.0 (TID 79). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 79) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 80 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:29:18 INFO DAGScheduler: Job 76 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037093 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(151) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0275970 (rel: 0,000620) 0,00226395
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 153 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 77 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 81 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[113] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[113] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 81 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 81.0 (TID 80)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 81.0 (TID 80). 68193 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 80) in 31 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 81 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 18:29:18 INFO DAGScheduler: Job 77 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037908 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(153) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0275743 (rel: 0,000825) 0,00167558
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.5 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 155 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 78 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 82 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[114] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[114] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 82 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 82.0 (TID 81)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 82.0 (TID 81). 68279 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 81) in 34 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 82 (treeAggregate at LogisticRegression.scala:1892) finished in 0,035 s
19/01/24 18:29:18 INFO DAGScheduler: Job 78 finished: treeAggregate at LogisticRegression.scala:1892, took 0,040546 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(155) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.3 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 157 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 79 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 83 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[115] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[115] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
19/01/24 18:29:18 WARN TaskSetManager: Stage 83 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 83.0 (TID 82)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 83.0 (TID 82). 68236 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 82) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 83 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 18:29:18 INFO DAGScheduler: Job 79 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034441 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(157) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO StrongWolfeLineSearch: Line search t: 0.4769797418924374 fval: 0.0275444991324947 rhs: 0.02757426596461796 cdd: 3.9424837397726215E-8
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO LBFGS: Step Size: 0,4770
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0275445 (rel: 0,00108) 0,00616549
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 63.3 KB, free 358.2 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.2 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.4 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 159 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:18 INFO DAGScheduler: Got job 80 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:18 INFO DAGScheduler: Final stage: ResultStage 84 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:18 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[116] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 116.2 KB, free 358.0 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:18 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[116] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:18 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:18 WARN TaskSetManager: Stage 84 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:18 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:18 INFO Executor: Running task 0.0 in stage 84.0 (TID 83)
19/01/24 18:29:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:18 INFO Executor: Finished task 0.0 in stage 84.0 (TID 83). 68236 bytes result sent to driver
19/01/24 18:29:18 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 83) in 49 ms on localhost (executor driver) (1/1)
19/01/24 18:29:18 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
19/01/24 18:29:18 INFO DAGScheduler: ResultStage 84 (treeAggregate at LogisticRegression.scala:1892) finished in 0,050 s
19/01/24 18:29:18 INFO DAGScheduler: Job 80 finished: treeAggregate at LogisticRegression.scala:1892, took 0,072116 s
19/01/24 18:29:18 INFO TorrentBroadcast: Destroying Broadcast(159) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:18 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:29:18 INFO LBFGS: Val and Grad Norm: 0,0275073 (rel: 0,00135) 0,00214546
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.7 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 161 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 81 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 85 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[117] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[117] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 85 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 85.0 (TID 84)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 85.0 (TID 84). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 84) in 42 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 85 (treeAggregate at LogisticRegression.scala:1892) finished in 0,046 s
19/01/24 18:29:19 INFO DAGScheduler: Job 81 finished: treeAggregate at LogisticRegression.scala:1892, took 0,067559 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(161) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0274931 (rel: 0,000516) 0,00158449
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 163 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 82 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 86 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[118] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[118] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 86 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 86.0 (TID 85)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 86.0 (TID 85). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 85) in 33 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 86 (treeAggregate at LogisticRegression.scala:1892) finished in 0,033 s
19/01/24 18:29:19 INFO DAGScheduler: Job 82 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039134 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(163) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0274843 (rel: 0,000320) 0,00180161
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.3 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 165 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 83 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 87 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[119] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[119] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 87 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 87.0 (TID 86)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 87.0 (TID 86). 68236 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 86) in 29 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 87 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 18:29:19 INFO DAGScheduler: Job 83 finished: treeAggregate at LogisticRegression.scala:1892, took 0,065782 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(165) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0274576 (rel: 0,000971) 0,00158743
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.1 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.8 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 167 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 84 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 88 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[120] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[120] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 88 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 88.0 (TID 87)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 88.0 (TID 87). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 87) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 88 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:19 INFO DAGScheduler: Job 84 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031396 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(167) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.8 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0274144 (rel: 0,00158) 0,00393116
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.9 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 169 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 85 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 89 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[121] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[121] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 89 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 89.0 (TID 88)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 89.0 (TID 88). 68236 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 88) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 89 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 18:29:19 INFO DAGScheduler: Job 85 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039215 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(169) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0273875 (rel: 0,000982) 0,00432852
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.7 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 171 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 86 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 90 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[122] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[122] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 90 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 90.0 (TID 89)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 90.0 (TID 89). 68236 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 89) in 27 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 90 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 18:29:19 INFO DAGScheduler: Job 86 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032845 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(171) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.6 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0273598 (rel: 0,00101) 0,00188127
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 57.3 KB, free 358.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 360.6 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 173 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 87 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 91 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[123] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[123] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 91 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 91.0 (TID 90)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 91.0 (TID 90). 68236 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 90) in 33 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 91 (treeAggregate at LogisticRegression.scala:1892) finished in 0,034 s
19/01/24 18:29:19 INFO DAGScheduler: Job 87 finished: treeAggregate at LogisticRegression.scala:1892, took 0,042268 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(173) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.6 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0273468 (rel: 0,000476) 0,00116889
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.3 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.5 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 175 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 88 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 92 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[124] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[124] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 92 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 92.0 (TID 91)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 92.0 (TID 91). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 91) in 41 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 92 (treeAggregate at LogisticRegression.scala:1892) finished in 0,042 s
19/01/24 18:29:19 INFO DAGScheduler: Job 88 finished: treeAggregate at LogisticRegression.scala:1892, took 0,048298 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(175) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0273375 (rel: 0,000339) 0,00133102
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 63.3 KB, free 359.6 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 177 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 89 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 93 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[125] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[125] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 93 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 93.0 (TID 92)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 93.0 (TID 92). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 92) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 93 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:19 INFO DAGScheduler: Job 89 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029802 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(177) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 179 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 90 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 94 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[126] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[126] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 94 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 94.0 (TID 93)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 94.0 (TID 93). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 93) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 94 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:29:19 INFO DAGScheduler: Job 90 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027854 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(179) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO StrongWolfeLineSearch: Line search t: 0.44238853046279136 fval: 0.027322638685121102 rhs: 0.02733753822231949 cdd: 4.543171550924762E-8
19/01/24 18:29:19 INFO LBFGS: Step Size: 0,4424
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0273226 (rel: 0,000545) 0,00359478
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.3 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 181 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 91 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 95 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[127] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[127] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 95 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 95.0 (TID 94)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 95.0 (TID 94). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 94) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 95 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:29:19 INFO DAGScheduler: Job 91 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028373 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(181) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0273029 (rel: 0,000724) 0,00144224
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 183 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 92 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 96 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[128] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[128] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 96 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 96.0 (TID 95)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 96.0 (TID 95). 68236 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 95) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 96 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:29:19 INFO DAGScheduler: Job 92 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033638 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(183) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0272873 (rel: 0,000571) 0,00140178
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.9 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 185 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 93 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 97 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[129] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[129] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 97 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 97.0 (TID 96)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 97.0 (TID 96). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 96) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 97 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:19 INFO DAGScheduler: Job 93 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026926 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(185) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.7 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 187 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 94 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 98 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[130] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[130] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 98 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 98.0 (TID 97)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 98.0 (TID 97). 68150 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 97) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 98 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:19 INFO DAGScheduler: Job 94 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025179 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(187) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO StrongWolfeLineSearch: Line search t: 0.18124034043854675 fval: 0.02727528205684075 rhs: 0.027287265460974944 cdd: -5.034893050342904E-7
19/01/24 18:29:19 INFO LBFGS: Step Size: 0,1812
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0272753 (rel: 0,000439) 0,00379483
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 189 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 95 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 99 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[131] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[131] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 99 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 99.0 (TID 98)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 99.0 (TID 98). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 98) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 99 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:19 INFO DAGScheduler: Job 95 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027412 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(189) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0272599 (rel: 0,000564) 0,00212009
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.3 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 191 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 96 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 100 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[132] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[132] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 100 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 100.0 (TID 99)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 100.0 (TID 99). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 99) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 100 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:19 INFO DAGScheduler: Job 96 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026627 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(191) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0272480 (rel: 0,000436) 0,00117490
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 63.3 KB, free 358.2 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.2 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.4 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 193 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 97 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 101 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[133] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 116.2 KB, free 358.0 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[133] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:19 WARN TaskSetManager: Stage 101 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 101.0 (TID 100)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 101.0 (TID 100). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 100) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 101 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:19 INFO DAGScheduler: Job 97 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032193 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(193) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0272368 (rel: 0,000412) 0,00132283
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.7 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 195 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 98 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 102 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[134] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[134] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 102 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 102.0 (TID 101)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 102.0 (TID 101). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 101) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 102 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:19 INFO DAGScheduler: Job 98 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026123 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(195) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0272191 (rel: 0,000649) 0,00202239
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.5 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 361.0 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 197 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 99 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 103 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[135] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[135] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 103 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 103.0 (TID 102)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 103.0 (TID 102). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 102) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 103 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:19 INFO DAGScheduler: Job 99 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025764 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(197) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0272060 (rel: 0,000484) 0,00307922
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.3 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 199 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 100 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 104 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[136] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[136] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 104 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 104.0 (TID 103)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:19 INFO Executor: Finished task 0.0 in stage 104.0 (TID 103). 68193 bytes result sent to driver
19/01/24 18:29:19 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 103) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:19 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
19/01/24 18:29:19 INFO DAGScheduler: ResultStage 104 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:19 INFO DAGScheduler: Job 100 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025994 s
19/01/24 18:29:19 INFO TorrentBroadcast: Destroying Broadcast(199) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:19 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.9 MB)
19/01/24 18:29:19 INFO LBFGS: Val and Grad Norm: 0,0271824 (rel: 0,000867) 0,00153555
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 201 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:19 INFO DAGScheduler: Got job 101 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:19 INFO DAGScheduler: Final stage: ResultStage 105 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:19 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[137] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:19 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:19 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:19 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[137] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:19 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
19/01/24 18:29:19 WARN TaskSetManager: Stage 105 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:19 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:19 INFO Executor: Running task 0.0 in stage 105.0 (TID 104)
19/01/24 18:29:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 105.0 (TID 104). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 104) in 37 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 105 (treeAggregate at LogisticRegression.scala:1892) finished in 0,037 s
19/01/24 18:29:20 INFO DAGScheduler: Job 101 finished: treeAggregate at LogisticRegression.scala:1892, took 0,042502 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(201) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0271749 (rel: 0,000274) 0,00102271
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.9 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 203 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 102 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 106 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[138] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[138] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 106 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 106.0 (TID 105)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 106.0 (TID 105). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 105) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 106 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:20 INFO DAGScheduler: Job 102 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028593 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(203) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0271630 (rel: 0,000438) 0,000860860
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.7 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 205 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 103 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 107 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[139] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[139] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 107 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 107.0 (TID 106)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 107.0 (TID 106). 68236 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 106) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 107 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:29:20 INFO DAGScheduler: Job 103 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032637 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(205) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 57.5 KB, free 358.5 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 207 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 104 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 108 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[140] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[140] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 108 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 108.0 (TID 107)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 108.0 (TID 107). 68236 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 107) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 108 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:29:20 INFO DAGScheduler: Job 104 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039370 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(207) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO StrongWolfeLineSearch: Line search t: 0.19604525695405883 fval: 0.02715561387700296 rhs: 0.027163021359093393 cdd: -2.620166538343346E-8
19/01/24 18:29:20 INFO LBFGS: Step Size: 0,1960
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0271556 (rel: 0,000273) 0,00187077
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.3 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 209 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 105 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 109 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[141] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[141] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 109 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 109.0 (TID 108)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 109.0 (TID 108). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 108) in 41 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 109 (treeAggregate at LogisticRegression.scala:1892) finished in 0,041 s
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:20 INFO DAGScheduler: Job 105 finished: treeAggregate at LogisticRegression.scala:1892, took 0,048826 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(209) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0271413 (rel: 0,000526) 0,00152413
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.0 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 360.8 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 211 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 106 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 110 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[142] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[142] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 110 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 110.0 (TID 109)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 110.0 (TID 109). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 109) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 110 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:29:20 INFO DAGScheduler: Job 106 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031560 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(211) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0271041 (rel: 0,00137) 0,00202190
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.5 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 213 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 107 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 111 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[143] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[143] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 111 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 111.0 (TID 110)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 111.0 (TID 110). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 110) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 111 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:29:20 INFO DAGScheduler: Job 107 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038346 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(213) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.3 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 215 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 108 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 112 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[144] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 116.2 KB, free 359.2 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.1 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[144] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 112 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 112.0 (TID 111)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 112.0 (TID 111). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 111) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 112 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:20 INFO DAGScheduler: Job 108 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028041 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(215) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO StrongWolfeLineSearch: Line search t: 0.5007448344415253 fval: 0.027092939336304526 rhs: 0.027104070568816956 cdd: -4.9042881056530016E-9
19/01/24 18:29:20 INFO LBFGS: Step Size: 0,5007
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.9 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0270929 (rel: 0,000411) 0,00189099
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 63.3 KB, free 359.2 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 217 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 109 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 113 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[145] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 116.2 KB, free 359.0 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.9 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[145] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 113 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 113.0 (TID 112)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 113.0 (TID 112). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 112) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 113 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:20 INFO DAGScheduler: Job 109 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027428 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(217) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.8 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0270825 (rel: 0,000385) 0,00131139
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 63.3 KB, free 359.0 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.9 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 219 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 110 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 114 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[146] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 116.2 KB, free 358.8 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.7 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[146] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 114 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 114.0 (TID 113)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 114.0 (TID 113). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 113) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 114 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:20 INFO DAGScheduler: Job 110 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026678 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(219) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0270734 (rel: 0,000337) 0,00167538
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 63.3 KB, free 358.8 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.7 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 221 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 111 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 115 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[147] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 116.2 KB, free 358.6 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.5 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[147] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 115 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 115.0 (TID 114)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 115.0 (TID 114). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 114) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 115 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:29:20 INFO DAGScheduler: Job 111 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027245 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(221) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0270557 (rel: 0,000654) 0,00129150
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 63.3 KB, free 358.6 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 57.3 KB, free 358.5 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 127.0.0.1:53695 (size: 57.3 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 223 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 112 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 116 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[148] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 116.2 KB, free 358.4 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.3 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[148] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 116 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 116.0 (TID 115)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 116.0 (TID 115). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 115) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 116 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:20 INFO DAGScheduler: Job 112 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026881 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(223) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 127.0.0.1:53695 in memory (size: 57.3 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0270527 (rel: 0,000112) 0,00487597
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 63.3 KB, free 358.4 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.3 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 225 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 113 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 117 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[149] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 116.2 KB, free 358.2 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.2 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[149] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 117 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 117.0 (TID 116)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 117.0 (TID 116). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 116) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 117 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:29:20 INFO DAGScheduler: Job 113 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026155 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(225) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 360.5 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0270365 (rel: 0,000598) 0,00244017
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 63.3 KB, free 358.2 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 57.4 KB, free 358.2 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 360.4 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 227 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 114 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 118 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[150] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 116.2 KB, free 358.0 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 74.7 KB, free 358.0 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[150] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 118 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 118.0 (TID 117)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.4 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.5 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.6 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.7 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.8 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 118.0 (TID 117). 68236 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 117) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 118 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 18:29:20 INFO DAGScheduler: Job 114 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033612 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(227) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.1 MB)
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0270285 (rel: 0,000294) 0,00115072
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.7 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 127.0.0.1:53695 (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 229 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 115 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 119 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[151] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 116.2 KB, free 359.5 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.5 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[151] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 119 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 119.0 (TID 118)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 119.0 (TID 118). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 118) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 119 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:20 INFO DAGScheduler: Job 115 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026009 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(229) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0270226 (rel: 0,000218) 0,000931583
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 127.0.0.1:53695 in memory (size: 57.4 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.5 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 127.0.0.1:53695 (size: 57.5 KB, free: 361.0 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 231 from broadcast at LogisticRegression.scala:1879
19/01/24 18:29:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:29:20 INFO DAGScheduler: Got job 116 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:29:20 INFO DAGScheduler: Final stage: ResultStage 120 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:29:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:29:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:20 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[152] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 116.2 KB, free 359.4 MB)
19/01/24 18:29:20 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 74.7 KB, free 359.3 MB)
19/01/24 18:29:20 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 127.0.0.1:53695 (size: 74.7 KB, free: 360.9 MB)
19/01/24 18:29:20 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[152] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:20 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks
19/01/24 18:29:20 WARN TaskSetManager: Stage 120 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:20 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 119, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:29:20 INFO Executor: Running task 0.0 in stage 120.0 (TID 119)
19/01/24 18:29:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:29:20 INFO Executor: Finished task 0.0 in stage 120.0 (TID 119). 68193 bytes result sent to driver
19/01/24 18:29:20 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 119) in 19 ms on localhost (executor driver) (1/1)
19/01/24 18:29:20 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
19/01/24 18:29:20 INFO DAGScheduler: ResultStage 120 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:29:20 INFO DAGScheduler: Job 116 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025528 s
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(231) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:29:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:29:20 INFO LBFGS: Val and Grad Norm: 0,0270067 (rel: 0,000588) 0,000915275
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 127.0.0.1:53695 in memory (size: 57.5 KB, free: 360.9 MB)
19/01/24 18:29:20 INFO LBFGS: Converged because max iterations reached
19/01/24 18:29:20 INFO TorrentBroadcast: Destroying Broadcast(10) (from destroy at LogisticRegression.scala:796)
19/01/24 18:29:20 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53695 in memory (size: 7.7 KB, free: 360.9 MB)
19/01/24 18:29:20 INFO MapPartitionsRDD: Removing RDD 40 from persistence list
19/01/24 18:29:20 INFO BlockManager: Removing RDD 40
19/01/24 18:29:20 INFO CodeGenerator: Code generated in 26.957306 ms
19/01/24 18:29:20 INFO Instrumentation: LogisticRegression-logistic_regression_4c8628a5a2a-1424242246-1: training finished
19/01/24 18:29:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c839681fe5`
19/01/24 18:29:43 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c844de627a
19/01/24 18:29:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c844de627a` AS `zzz4`
WHERE (0 = 1)
19/01/24 18:29:43 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c844de627a`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:29:43 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:43 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:43 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c844de627a`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:29:43 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:43 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:43 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c844de627a`
GROUP BY `Sentiment`, `Prediction`
LIMIT 11
19/01/24 18:29:43 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:43 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:44 INFO CodeGenerator: Code generated in 17.416384 ms
19/01/24 18:29:44 INFO CodeGenerator: Code generated in 35.121589 ms
19/01/24 18:29:44 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:29:44 INFO DAGScheduler: Registering RDD 160 (collect at utils.scala:200)
19/01/24 18:29:44 INFO DAGScheduler: Got job 117 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:29:44 INFO DAGScheduler: Final stage: ResultStage 122 (collect at utils.scala:200)
19/01/24 18:29:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)
19/01/24 18:29:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 121)
19/01/24 18:29:44 INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[160] at collect at utils.scala:200), which has no missing parents
19/01/24 18:29:44 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 195.9 KB, free 361.8 MB)
19/01/24 18:29:44 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 140.0 KB, free 361.7 MB)
19/01/24 18:29:44 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 127.0.0.1:53695 (size: 140.0 KB, free: 363.4 MB)
19/01/24 18:29:44 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[160] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:44 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
19/01/24 18:29:44 WARN TaskSetManager: Stage 121 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:29:44 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:29:44 INFO Executor: Running task 0.0 in stage 121.0 (TID 120)
19/01/24 18:29:44 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:29:44 INFO CodeGenerator: Code generated in 3.907828 ms
19/01/24 18:29:44 INFO CodeGenerator: Code generated in 3.717834 ms
19/01/24 18:29:44 INFO CodeGenerator: Code generated in 4.386279 ms
19/01/24 18:29:44 INFO CodeGenerator: Code generated in 6.815361 ms
19/01/24 18:29:44 INFO CodeGenerator: Code generated in 3.827965 ms
19/01/24 18:29:44 INFO Executor: Finished task 0.0 in stage 121.0 (TID 120). 2263 bytes result sent to driver
19/01/24 18:29:44 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 120) in 350 ms on localhost (executor driver) (1/1)
19/01/24 18:29:44 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
19/01/24 18:29:44 INFO DAGScheduler: ShuffleMapStage 121 (collect at utils.scala:200) finished in 0,350 s
19/01/24 18:29:44 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:29:44 INFO DAGScheduler: running: Set()
19/01/24 18:29:44 INFO DAGScheduler: waiting: Set(ResultStage 122)
19/01/24 18:29:44 INFO DAGScheduler: failed: Set()
19/01/24 18:29:44 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[163] at collect at utils.scala:200), which has no missing parents
19/01/24 18:29:44 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 177.2 KB, free 361.5 MB)
19/01/24 18:29:44 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 363.4 MB)
19/01/24 18:29:44 INFO ContextCleaner: Cleaned accumulator 2957
19/01/24 18:29:44 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 135.8 KB, free 361.6 MB)
19/01/24 18:29:44 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 127.0.0.1:53695 (size: 135.8 KB, free: 363.3 MB)
19/01/24 18:29:44 INFO SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[163] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:29:44 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
19/01/24 18:29:44 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 363.4 MB)
19/01/24 18:29:44 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 121, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:29:44 INFO Executor: Running task 0.0 in stage 122.0 (TID 121)
19/01/24 18:29:44 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 127.0.0.1:53695 in memory (size: 74.7 KB, free: 363.4 MB)
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:29:44 INFO Executor: Finished task 0.0 in stage 122.0 (TID 121). 2541 bytes result sent to driver
19/01/24 18:29:44 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 121) in 9 ms on localhost (executor driver) (1/1)
19/01/24 18:29:44 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
19/01/24 18:29:44 INFO DAGScheduler: ResultStage 122 (collect at utils.scala:200) finished in 0,009 s
19/01/24 18:29:44 INFO DAGScheduler: Job 117 finished: collect at utils.scala:200, took 0,375295 s
19/01/24 18:29:44 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:29:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 149 bytes
19/01/24 18:29:44 INFO DAGScheduler: Got job 118 (collect at utils.scala:200) with 4 output partitions
19/01/24 18:29:44 INFO DAGScheduler: Final stage: ResultStage 124 (collect at utils.scala:200)
19/01/24 18:29:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 123)
19/01/24 18:29:44 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:44 INFO DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[163] at collect at utils.scala:200), which has no missing parents
19/01/24 18:29:44 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 177.2 KB, free 361.8 MB)
19/01/24 18:29:44 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 135.8 KB, free 361.6 MB)
19/01/24 18:29:44 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 127.0.0.1:53695 (size: 135.8 KB, free: 363.3 MB)
19/01/24 18:29:44 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 124 (MapPartitionsRDD[163] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
19/01/24 18:29:44 INFO TaskSchedulerImpl: Adding task set 124.0 with 4 tasks
19/01/24 18:29:44 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 122, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:29:44 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 123, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:29:44 INFO TaskSetManager: Starting task 2.0 in stage 124.0 (TID 124, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:29:44 INFO TaskSetManager: Starting task 3.0 in stage 124.0 (TID 125, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:29:44 INFO Executor: Running task 0.0 in stage 124.0 (TID 122)
19/01/24 18:29:44 INFO Executor: Running task 1.0 in stage 124.0 (TID 123)
19/01/24 18:29:44 INFO Executor: Running task 2.0 in stage 124.0 (TID 124)
19/01/24 18:29:44 INFO Executor: Running task 3.0 in stage 124.0 (TID 125)
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:29:44 INFO Executor: Finished task 1.0 in stage 124.0 (TID 123). 2515 bytes result sent to driver
19/01/24 18:29:44 INFO Executor: Finished task 3.0 in stage 124.0 (TID 125). 2515 bytes result sent to driver
19/01/24 18:29:44 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 123) in 12 ms on localhost (executor driver) (1/4)
19/01/24 18:29:44 INFO Executor: Finished task 0.0 in stage 124.0 (TID 122). 2515 bytes result sent to driver
19/01/24 18:29:44 INFO Executor: Finished task 2.0 in stage 124.0 (TID 124). 2515 bytes result sent to driver
19/01/24 18:29:44 INFO TaskSetManager: Finished task 3.0 in stage 124.0 (TID 125) in 12 ms on localhost (executor driver) (2/4)
19/01/24 18:29:44 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 122) in 13 ms on localhost (executor driver) (3/4)
19/01/24 18:29:44 INFO TaskSetManager: Finished task 2.0 in stage 124.0 (TID 124) in 12 ms on localhost (executor driver) (4/4)
19/01/24 18:29:44 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
19/01/24 18:29:44 INFO DAGScheduler: ResultStage 124 (collect at utils.scala:200) finished in 0,013 s
19/01/24 18:29:44 INFO DAGScheduler: Job 118 finished: collect at utils.scala:200, took 0,018598 s
19/01/24 18:29:44 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:29:44 INFO DAGScheduler: Got job 119 (collect at utils.scala:200) with 3 output partitions
19/01/24 18:29:44 INFO DAGScheduler: Final stage: ResultStage 126 (collect at utils.scala:200)
19/01/24 18:29:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
19/01/24 18:29:44 INFO DAGScheduler: Missing parents: List()
19/01/24 18:29:44 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[163] at collect at utils.scala:200), which has no missing parents
19/01/24 18:29:44 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 177.2 KB, free 361.5 MB)
19/01/24 18:29:44 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 135.8 KB, free 361.3 MB)
19/01/24 18:29:44 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 127.0.0.1:53695 (size: 135.8 KB, free: 363.2 MB)
19/01/24 18:29:44 INFO SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1006
19/01/24 18:29:44 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 126 (MapPartitionsRDD[163] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(5, 6, 7))
19/01/24 18:29:44 INFO TaskSchedulerImpl: Adding task set 126.0 with 3 tasks
19/01/24 18:29:44 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 126, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:29:44 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 127, localhost, executor driver, partition 5, ANY, 4726 bytes)
19/01/24 18:29:44 INFO TaskSetManager: Starting task 2.0 in stage 126.0 (TID 128, localhost, executor driver, partition 7, ANY, 4726 bytes)
19/01/24 18:29:44 INFO Executor: Running task 0.0 in stage 126.0 (TID 127)
19/01/24 18:29:44 INFO Executor: Running task 2.0 in stage 126.0 (TID 128)
19/01/24 18:29:44 INFO Executor: Running task 1.0 in stage 126.0 (TID 126)
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:29:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:29:44 INFO Executor: Finished task 1.0 in stage 126.0 (TID 126). 2515 bytes result sent to driver
19/01/24 18:29:44 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 126) in 9 ms on localhost (executor driver) (1/3)
19/01/24 18:29:44 INFO Executor: Finished task 0.0 in stage 126.0 (TID 127). 2591 bytes result sent to driver
19/01/24 18:29:44 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 127) in 9 ms on localhost (executor driver) (2/3)
19/01/24 18:29:44 INFO Executor: Finished task 2.0 in stage 126.0 (TID 128). 2535 bytes result sent to driver
19/01/24 18:29:44 INFO TaskSetManager: Finished task 2.0 in stage 126.0 (TID 128) in 10 ms on localhost (executor driver) (3/3)
19/01/24 18:29:44 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
19/01/24 18:29:44 INFO DAGScheduler: ResultStage 126 (collect at utils.scala:200) finished in 0,011 s
19/01/24 18:29:44 INFO DAGScheduler: Job 119 finished: collect at utils.scala:200, took 0,015968 s
19/01/24 18:29:44 INFO CodeGenerator: Code generated in 5.183452 ms
19/01/24 18:29:44 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c844de627a`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:29:44 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:44 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:29:45 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:45 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:45 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:45 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:29:45 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:29:45 INFO CodeGenerator: Code generated in 8.415178 ms
19/01/24 18:29:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:29:45 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:45 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:45 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:45 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:29:45 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:29:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:29:45 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:45 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:45 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:29:45 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:29:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:29:45 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:33:49 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 18:33:49 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 18:33:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 18:33:49 INFO MemoryStore: MemoryStore cleared
19/01/24 18:33:49 INFO BlockManager: BlockManager stopped
19/01/24 18:33:49 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 18:33:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 18:33:49 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-8affd81b-7397-4556-a2e6-8b31601dad31\userFiles-d011e361-25d7-4b7e-adb4-1f2f9c7fd298
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-8affd81b-7397-4556-a2e6-8b31601dad31\userFiles-d011e361-25d7-4b7e-adb4-1f2f9c7fd298
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:33:49 INFO SparkContext: Successfully stopped SparkContext
19/01/24 18:33:49 INFO ShutdownHookManager: Shutdown hook called
19/01/24 18:33:49 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-8affd81b-7397-4556-a2e6-8b31601dad31
19/01/24 18:33:49 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-8affd81b-7397-4556-a2e6-8b31601dad31
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-8affd81b-7397-4556-a2e6-8b31601dad31
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:33:49 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-8affd81b-7397-4556-a2e6-8b31601dad31\userFiles-d011e361-25d7-4b7e-adb4-1f2f9c7fd298
19/01/24 18:33:49 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-8affd81b-7397-4556-a2e6-8b31601dad31\userFiles-d011e361-25d7-4b7e-adb4-1f2f9c7fd298
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-8affd81b-7397-4556-a2e6-8b31601dad31\userFiles-d011e361-25d7-4b7e-adb4-1f2f9c7fd298
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 18:34:03 INFO SparkContext: Running Spark version 2.2.0
19/01/24 18:34:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 18:34:03 INFO SparkContext: Submitted application: sparklyr
19/01/24 18:34:03 INFO SecurityManager: Changing view acls to: yanis
19/01/24 18:34:03 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 18:34:03 INFO SecurityManager: Changing view acls groups to: 
19/01/24 18:34:03 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 18:34:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 18:34:03 INFO Utils: Successfully started service 'sparkDriver' on port 53807.
19/01/24 18:34:03 INFO SparkEnv: Registering MapOutputTracker
19/01/24 18:34:03 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 18:34:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 18:34:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 18:34:03 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-a565b49e-a51d-41ee-8340-81f9bb13d90d
19/01/24 18:34:03 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 18:34:03 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 18:34:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 18:34:03 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 18:34:03 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:53807/jars/sparklyr-2.2-2.11.jar with timestamp 1548351243971
19/01/24 18:34:04 INFO Executor: Starting executor ID driver on host localhost
19/01/24 18:34:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53848.
19/01/24 18:34:04 INFO NettyBlockTransferService: Server created on 127.0.0.1:53848
19/01/24 18:34:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 18:34:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53848, None)
19/01/24 18:34:04 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53848 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53848, None)
19/01/24 18:34:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53848, None)
19/01/24 18:34:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53848, None)
19/01/24 18:34:04 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 18:34:04 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 18:34:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 18:34:04 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 18:34:04 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 18:34:05 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 18:34:05 INFO ObjectStore: ObjectStore, initialize called
19/01/24 18:34:05 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 18:34:05 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 18:34:06 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 18:34:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:34:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:34:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:34:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:34:07 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 18:34:07 INFO ObjectStore: Initialized ObjectStore
19/01/24 18:34:07 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 18:34:08 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 18:34:08 INFO HiveMetaStore: Added admin role in metastore
19/01/24 18:34:08 INFO HiveMetaStore: Added public role in metastore
19/01/24 18:34:08 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 18:34:08 INFO HiveMetaStore: 0: get_all_databases
19/01/24 18:34:08 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 18:34:08 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 18:34:08 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 18:34:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 18:34:08 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/4aaec741-58d5-472b-ad14-93bebe973ef8_resources
19/01/24 18:34:08 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/4aaec741-58d5-472b-ad14-93bebe973ef8
19/01/24 18:34:08 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/4aaec741-58d5-472b-ad14-93bebe973ef8
19/01/24 18:34:08 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/4aaec741-58d5-472b-ad14-93bebe973ef8/_tmp_space.db
19/01/24 18:34:08 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:34:08 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:08 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:08 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 18:34:08 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 18:34:08 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 18:34:08 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/8089c11f-565e-4869-ba72-b2ff27141735_resources
19/01/24 18:34:08 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/8089c11f-565e-4869-ba72-b2ff27141735
19/01/24 18:34:08 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/8089c11f-565e-4869-ba72-b2ff27141735
19/01/24 18:34:08 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/8089c11f-565e-4869-ba72-b2ff27141735/_tmp_space.db
19/01/24 18:34:08 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 18:34:08 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 18:34:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:34:10 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:10 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:10 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:10 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:34:10 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:34:10 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 18:34:10 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 18:34:10 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 18:34:10 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:10 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:10 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 18:34:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 18:34:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 18:34:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53848 (size: 3.4 KB, free: 366.3 MB)
19/01/24 18:34:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 18:34:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 18:34:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 18:34:11 INFO Executor: Fetching spark://127.0.0.1:53807/jars/sparklyr-2.2-2.11.jar with timestamp 1548351243971
19/01/24 18:34:11 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53807 after 13 ms (0 ms spent in bootstraps)
19/01/24 18:34:11 INFO Utils: Fetching spark://127.0.0.1:53807/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-5e400486-05ed-4d2c-ae8f-797e6148d030\userFiles-c1b5d933-f8a4-429a-a21b-d9c791d0b3e8\fetchFileTemp1627314481576915575.tmp
19/01/24 18:34:11 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-5e400486-05ed-4d2c-ae8f-797e6148d030/userFiles-c1b5d933-f8a4-429a-a21b-d9c791d0b3e8/sparklyr-2.2-2.11.jar to class loader
19/01/24 18:34:11 INFO CodeGenerator: Code generated in 197.923702 ms
19/01/24 18:34:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/01/24 18:34:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 546 ms on localhost (executor driver) (1/1)
19/01/24 18:34:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 18:34:11 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,564 s
19/01/24 18:34:11 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,726615 s
19/01/24 18:34:12 INFO SparkSqlParser: Parsing command: reviews_spark
19/01/24 18:34:12 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews_spark`
19/01/24 18:34:12 INFO SparkSqlParser: Parsing command: `reviews_spark`
19/01/24 18:34:12 INFO CodeGenerator: Code generated in 14.959951 ms
19/01/24 18:34:12 INFO CodeGenerator: Code generated in 9.395782 ms
19/01/24 18:34:12 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 18:34:12 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 18:34:12 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 18:34:12 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 18:34:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 18:34:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 18:34:12 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 18:34:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 18:34:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 18:34:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53848 (size: 7.7 KB, free: 366.3 MB)
19/01/24 18:34:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 18:34:12 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:34:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 18:34:12 INFO CodeGenerator: Code generated in 8.618665 ms
19/01/24 18:34:12 INFO CodeGenerator: Code generated in 22.304087 ms
19/01/24 18:34:12 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.4 MB)
19/01/24 18:34:12 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:53848 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 18:34:12 INFO CodeGenerator: Code generated in 4.483282 ms
19/01/24 18:34:12 INFO CodeGenerator: Code generated in 15.914664 ms
19/01/24 18:34:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 18:34:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 375 ms on localhost (executor driver) (1/1)
19/01/24 18:34:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 18:34:12 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,377 s
19/01/24 18:34:12 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:34:12 INFO DAGScheduler: running: Set()
19/01/24 18:34:12 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 18:34:12 INFO DAGScheduler: failed: Set()
19/01/24 18:34:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 18:34:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:34:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:34:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53848 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:34:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 18:34:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:34:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 18:34:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:34:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/01/24 18:34:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1538 bytes result sent to driver
19/01/24 18:34:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:34:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 18:34:12 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,029 s
19/01/24 18:34:12 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,447579 s
19/01/24 18:34:12 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews_spark`
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 18:34:12 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53848 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 18:34:12 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 18:34:12 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53848 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:34:12 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 18:34:12 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53848 in memory (size: 3.4 KB, free: 364.5 MB)
19/01/24 18:34:12 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:12 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:13 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:34:13 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 18:34:13 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:34:13 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 18:34:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 18:34:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 18:34:13 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 18:34:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 18:34:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.5 MB)
19/01/24 18:34:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53848 (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:34:13 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:13 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 18:34:13 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:13 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:34:13 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 18:34:13 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:34:13 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
19/01/24 18:34:13 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 35 ms on localhost (executor driver) (1/1)
19/01/24 18:34:13 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 18:34:13 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,036 s
19/01/24 18:34:13 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:34:13 INFO DAGScheduler: running: Set()
19/01/24 18:34:13 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 18:34:13 INFO DAGScheduler: failed: Set()
19/01/24 18:34:13 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 18:34:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 18:34:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 18:34:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53848 (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:34:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:13 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 18:34:13 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:34:13 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 18:34:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:34:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:34:13 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
19/01/24 18:34:13 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 4 ms on localhost (executor driver) (1/1)
19/01/24 18:34:13 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 18:34:13 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,004 s
19/01/24 18:34:13 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,057338 s
19/01/24 18:34:13 INFO CodeGenerator: Code generated in 4.983976 ms
19/01/24 18:34:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews_spark` AS `zzz5`
WHERE (0 = 1)
19/01/24 18:34:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews_spark`
19/01/24 18:34:15 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c826194b1e
19/01/24 18:34:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c826194b1e` AS `zzz6`
WHERE (0 = 1)
19/01/24 18:34:15 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c86e047f0
19/01/24 18:34:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c86e047f0` AS `zzz7`
WHERE (0 = 1)
19/01/24 18:34:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c826194b1e`
19/01/24 18:34:16 INFO CodeGenerator: Code generated in 25.07742 ms
19/01/24 18:34:16 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:34:16 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 18:34:16 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:34:16 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 18:34:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 18:34:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 18:34:16 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:34:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 18:34:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 18:34:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53848 (size: 13.0 KB, free: 364.5 MB)
19/01/24 18:34:16 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:16 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 18:34:16 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:34:16 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 18:34:16 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:34:16 INFO CodeGenerator: Code generated in 13.558516 ms
19/01/24 18:34:16 INFO CodeGenerator: Code generated in 14.100419 ms
19/01/24 18:34:16 INFO CodeGenerator: Code generated in 9.507737 ms
19/01/24 18:34:16 INFO CodeGenerator: Code generated in 12.167656 ms
19/01/24 18:34:16 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53848 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 18:34:16 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 18:34:16 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53848 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 18:34:17 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1951 bytes result sent to driver
19/01/24 18:34:17 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 786 ms on localhost (executor driver) (1/1)
19/01/24 18:34:17 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 18:34:17 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 0,787 s
19/01/24 18:34:17 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:34:17 INFO DAGScheduler: running: Set()
19/01/24 18:34:17 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 18:34:17 INFO DAGScheduler: failed: Set()
19/01/24 18:34:17 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 18:34:17 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 18:34:17 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 18:34:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53848 (size: 1887.0 B, free: 364.5 MB)
19/01/24 18:34:17 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:17 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 18:34:17 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 18:34:17 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 18:34:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:34:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:34:17 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 18:34:17 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:53848 (size: 686.3 KB, free: 363.8 MB)
19/01/24 18:34:17 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1787 bytes result sent to driver
19/01/24 18:34:17 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 102 ms on localhost (executor driver) (1/1)
19/01/24 18:34:17 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 18:34:17 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,104 s
19/01/24 18:34:17 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 0,920123 s
19/01/24 18:34:17 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 18:34:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 18:34:17 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 18:34:17 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 18:34:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 18:34:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:17 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 18:34:17 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.8 MB)
19/01/24 18:34:17 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.8 MB)
19/01/24 18:34:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53848 (size: 2.2 KB, free: 363.8 MB)
19/01/24 18:34:17 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:17 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 18:34:17 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 18:34:17 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 18:34:17 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 18:34:17 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 18:34:17 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 46 ms on localhost (executor driver) (1/1)
19/01/24 18:34:17 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 18:34:17 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,046 s
19/01/24 18:34:17 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,062974 s
19/01/24 18:34:17 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 18:34:17 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.6 MB)
19/01/24 18:34:17 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53848 (size: 89.8 KB, free: 363.7 MB)
19/01/24 18:34:17 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 18:34:17 INFO CodeGenerator: Code generated in 28.929088 ms
19/01/24 18:34:17 INFO CodeGenerator: Code generated in 19.512885 ms
19/01/24 18:34:17 INFO Instrumentation: LogisticRegression-logistic_regression_4c8481f65f5-846246232-1: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
19/01/24 18:34:17 INFO Instrumentation: LogisticRegression-logistic_regression_4c8481f65f5-846246232-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
19/01/24 18:34:17 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:517
19/01/24 18:34:17 INFO DAGScheduler: Got job 5 (treeAggregate at LogisticRegression.scala:517) with 1 output partitions
19/01/24 18:34:17 INFO DAGScheduler: Final stage: ResultStage 9 (treeAggregate at LogisticRegression.scala:517)
19/01/24 18:34:17 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:17 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:17 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at treeAggregate at LogisticRegression.scala:517), which has no missing parents
19/01/24 18:34:17 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 116.1 KB, free 362.4 MB)
19/01/24 18:34:17 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 74.7 KB, free 362.4 MB)
19/01/24 18:34:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53848 (size: 74.7 KB, free: 363.6 MB)
19/01/24 18:34:17 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at treeAggregate at LogisticRegression.scala:517) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:17 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 18:34:17 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:17 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:17 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 18:34:17 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53848 in memory (size: 2.2 KB, free: 363.6 MB)
19/01/24 18:34:17 INFO ContextCleaner: Cleaned accumulator 178
19/01/24 18:34:17 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 18:34:17 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53848 in memory (size: 13.0 KB, free: 363.6 MB)
19/01/24 18:34:17 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 18:34:17 INFO ContextCleaner: Cleaned accumulator 174
19/01/24 18:34:17 INFO BlockManager: Removing RDD 30
19/01/24 18:34:17 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:34:17 INFO ContextCleaner: Cleaned RDD 30
19/01/24 18:34:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53848 in memory (size: 1887.0 B, free: 364.3 MB)
19/01/24 18:34:17 INFO ContextCleaner: Cleaned accumulator 176
19/01/24 18:34:17 INFO ContextCleaner: Cleaned accumulator 177
19/01/24 18:34:17 INFO ContextCleaner: Cleaned accumulator 175
19/01/24 18:34:17 INFO CodeGenerator: Code generated in 8.119064 ms
19/01/24 18:34:18 INFO MemoryStore: Block rdd_40_0 stored as values in memory (estimated size 2.5 MB, free 360.6 MB)
19/01/24 18:34:18 INFO BlockManagerInfo: Added rdd_40_0 in memory on 127.0.0.1:53848 (size: 2.5 MB, free: 361.8 MB)
19/01/24 18:34:18 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 524154 bytes result sent to driver
19/01/24 18:34:18 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 797 ms on localhost (executor driver) (1/1)
19/01/24 18:34:18 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 18:34:18 INFO DAGScheduler: ResultStage 9 (treeAggregate at LogisticRegression.scala:517) finished in 0,798 s
19/01/24 18:34:18 INFO DAGScheduler: Job 5 finished: treeAggregate at LogisticRegression.scala:517, took 0,806288 s
19/01/24 18:34:18 INFO Instrumentation: LogisticRegression-logistic_regression_4c8481f65f5-846246232-1: {"numClasses":2}
19/01/24 18:34:18 INFO Instrumentation: LogisticRegression-logistic_regression_4c8481f65f5-846246232-1: {"numFeatures":8098}
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 63.3 KB, free 360.5 MB)
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.7 KB, free 360.5 MB)
19/01/24 18:34:18 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53848 (size: 7.7 KB, free: 361.8 MB)
19/01/24 18:34:18 INFO SparkContext: Created broadcast 10 from broadcast at LogisticRegression.scala:600
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 439.0 B, free 360.4 MB)
19/01/24 18:34:18 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53848 (size: 439.0 B, free: 361.8 MB)
19/01/24 18:34:18 INFO SparkContext: Created broadcast 11 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:18 INFO DAGScheduler: Got job 6 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:18 INFO DAGScheduler: Final stage: ResultStage 10 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:18 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:18 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:18 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 18:34:18 WARN TaskSetManager: Stage 10 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:18 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:18 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 18:34:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:18 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 68236 bytes result sent to driver
19/01/24 18:34:18 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 37 ms on localhost (executor driver) (1/1)
19/01/24 18:34:18 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 18:34:18 INFO DAGScheduler: ResultStage 10 (treeAggregate at LogisticRegression.scala:1892) finished in 0,037 s
19/01/24 18:34:18 INFO DAGScheduler: Job 6 finished: treeAggregate at LogisticRegression.scala:1892, took 0,046182 s
19/01/24 18:34:18 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/01/24 18:34:18 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/01/24 18:34:18 INFO TorrentBroadcast: Destroying Broadcast(11) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:18 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53848 in memory (size: 439.0 B, free: 361.7 MB)
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.5 KB, free 360.2 MB)
19/01/24 18:34:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53848 (size: 23.5 KB, free: 361.7 MB)
19/01/24 18:34:18 INFO SparkContext: Created broadcast 13 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:18 INFO DAGScheduler: Got job 7 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:18 INFO DAGScheduler: Final stage: ResultStage 11 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:18 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[43] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:18 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[43] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:18 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 18:34:18 WARN TaskSetManager: Stage 11 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:18 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:18 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 18:34:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:18 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 68279 bytes result sent to driver
19/01/24 18:34:18 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 34 ms on localhost (executor driver) (1/1)
19/01/24 18:34:18 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 18:34:18 INFO DAGScheduler: ResultStage 11 (treeAggregate at LogisticRegression.scala:1892) finished in 0,034 s
19/01/24 18:34:18 INFO DAGScheduler: Job 7 finished: treeAggregate at LogisticRegression.scala:1892, took 0,041279 s
19/01/24 18:34:18 INFO TorrentBroadcast: Destroying Broadcast(13) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:18 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53848 in memory (size: 23.5 KB, free: 361.6 MB)
19/01/24 18:34:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:18 INFO LBFGS: Val and Grad Norm: 0,330456 (rel: 0,523) 0,367278
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 57.6 KB, free 360.0 MB)
19/01/24 18:34:18 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53848 (size: 57.6 KB, free: 361.6 MB)
19/01/24 18:34:18 INFO SparkContext: Created broadcast 15 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:18 INFO DAGScheduler: Got job 8 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:18 INFO DAGScheduler: Final stage: ResultStage 12 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:18 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:18 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:18 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:18 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 18:34:18 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:18 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:18 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 18:34:18 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:18 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 68193 bytes result sent to driver
19/01/24 18:34:18 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:34:18 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 18:34:18 INFO DAGScheduler: ResultStage 12 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:18 INFO DAGScheduler: Job 8 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034028 s
19/01/24 18:34:18 INFO TorrentBroadcast: Destroying Broadcast(15) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:18 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53848 in memory (size: 57.6 KB, free: 361.5 MB)
19/01/24 18:34:18 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:18 INFO LBFGS: Val and Grad Norm: 0,213198 (rel: 0,355) 0,167363
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:18 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 18:34:18 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:18 INFO SparkContext: Created broadcast 17 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:18 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:18 INFO DAGScheduler: Got job 9 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:18 INFO DAGScheduler: Final stage: ResultStage 13 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:18 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:18 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:18 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[45] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[45] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 13 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 27 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 13 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 18:34:19 INFO DAGScheduler: Job 9 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035457 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(17) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,147331 (rel: 0,309) 0,0949852
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 19 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 10 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 14 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 14 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 14.0 (TID 13)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 14.0 (TID 13). 68236 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 13) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 14 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:19 INFO DAGScheduler: Job 10 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032429 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(19) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,100491 (rel: 0,318) 0,0613800
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 57.7 KB, free 359.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53848 (size: 57.7 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 21 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 11 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 15 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[47] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[47] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 15 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 15.0 (TID 14)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 15.0 (TID 14). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 14) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 15 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:19 INFO DAGScheduler: Job 11 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032046 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(21) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53848 in memory (size: 57.7 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0724526 (rel: 0,279) 0,0316812
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 23 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 16 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.5 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53848 in memory (size: 74.7 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:19 WARN TaskSetManager: Stage 16 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 16.0 (TID 15)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 16.0 (TID 15). 68236 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 15) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 16 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:34:19 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:1892, took 0,042033 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(23) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.8 MB)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0587020 (rel: 0,190) 0,0233276
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.7 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 25 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 17 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[49] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[49] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 17 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 17.0 (TID 16)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 17.0 (TID 16). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 16) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 17 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:19 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029925 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(25) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.7 MB)
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0508755 (rel: 0,133) 0,0191974
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 27 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 18 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 18 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 18.0 (TID 17)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 18.0 (TID 17). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 17) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 18 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:19 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030237 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(27) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0492985 (rel: 0,0310) 0,0273011
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.0 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 29 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 19 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[51] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[51] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 19 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 19.0 (TID 18)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 19.0 (TID 18). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 18) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 19 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:19 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029346 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(29) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0448300 (rel: 0,0906) 0,0186364
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 31 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 20 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 20 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 20.0 (TID 19)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 20.0 (TID 19). 68236 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 19) in 27 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 20 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 18:34:19 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034793 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(31) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0396473 (rel: 0,116) 0,0195072
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 33 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 21 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[53] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[53] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 21 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 21.0 (TID 20)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 21.0 (TID 20). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 20) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 21 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:19 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031470 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(33) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 35 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 22 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 22.0 (TID 21)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 22.0 (TID 21). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 21) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:19 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028938 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(35) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO StrongWolfeLineSearch: Line search t: 0.32886824614418664 fval: 0.03927381963744339 rhs: 0.03964717451086121 cdd: 6.991968417275898E-4
19/01/24 18:34:19 INFO LBFGS: Step Size: 0,3289
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0392738 (rel: 0,00942) 0,0181790
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 37 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[55] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[55] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 23 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 23.0 (TID 22)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 23.0 (TID 22). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 22) in 29 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 18:34:19 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036820 s
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(37) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0379879 (rel: 0,0327) 0,0145010
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 57.6 KB, free 359.8 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:53848 (size: 57.6 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 39 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 24 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 24.0 (TID 23)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 24.0 (TID 23). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 23) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:19 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030492 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(39) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:53848 in memory (size: 57.6 KB, free: 361.7 MB)
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0369358 (rel: 0,0277) 0,0191350
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 41 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[57] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[57] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 25 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 25.0 (TID 24)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 25.0 (TID 24). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 24) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:19 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029021 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(41) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0363885 (rel: 0,0148) 0,0167591
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.0 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 43 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 26 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 26.0 (TID 25)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 26.0 (TID 25). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 25) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:19 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028001 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(43) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 63.3 KB, free 359.8 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 45 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[59] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[59] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 27 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 27.0 (TID 26)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 27.0 (TID 26). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 26) in 27 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 18:34:19 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033480 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(45) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO StrongWolfeLineSearch: Line search t: 0.4108013193598613 fval: 0.03594493422285328 rhs: 0.03638839827048342 cdd: 3.814229000619686E-4
19/01/24 18:34:19 INFO LBFGS: Step Size: 0,4108
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0359449 (rel: 0,0122) 0,0135038
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 47 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 28 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 28.0 (TID 27)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 28.0 (TID 27). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 27) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:19 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030991 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(47) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0357242 (rel: 0,00614) 0,00639451
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 49 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 29 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 29.0 (TID 28)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 29.0 (TID 28). 68236 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 28) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:19 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032148 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(49) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0353285 (rel: 0,0111) 0,00918555
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 51 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 30 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 30.0 (TID 29)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 30.0 (TID 29). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 29) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:19 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027583 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(51) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0349337 (rel: 0,0112) 0,00751039
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 53 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 31 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 31.0 (TID 30)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 31.0 (TID 30). 68236 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 30) in 32 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:34:19 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038823 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(53) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 55 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 32 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 32.0 (TID 31)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 32.0 (TID 31). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 31) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:19 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028356 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(55) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO StrongWolfeLineSearch: Line search t: 0.17279326617073676 fval: 0.03482345995373003 rhs: 0.03493363733470484 cdd: 9.033313740993744E-4
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:19 INFO LBFGS: Step Size: 0,1728
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0348235 (rel: 0,00315) 0,0355699
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 57 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 33 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 33.0 (TID 32)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 33.0 (TID 32). 68193 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 32) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:19 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027985 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(57) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0341632 (rel: 0,0190) 0,00651399
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.0 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 59 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 30 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/01/24 18:34:19 WARN TaskSetManager: Stage 34 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:19 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:19 INFO Executor: Running task 0.0 in stage 34.0 (TID 33)
19/01/24 18:34:19 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:19 INFO Executor: Finished task 0.0 in stage 34.0 (TID 33). 68236 bytes result sent to driver
19/01/24 18:34:19 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 33) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:19 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/01/24 18:34:19 INFO DAGScheduler: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:19 INFO DAGScheduler: Job 30 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039408 s
19/01/24 18:34:19 INFO TorrentBroadcast: Destroying Broadcast(59) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:19 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:19 INFO LBFGS: Val and Grad Norm: 0,0339435 (rel: 0,00643) 0,00558368
19/01/24 18:34:19 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 61 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:19 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:19 INFO DAGScheduler: Got job 31 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:19 INFO DAGScheduler: Final stage: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:19 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:19 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:19 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:19 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:19 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:19 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:19 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 35 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 35.0 (TID 34)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 35.0 (TID 34). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 34) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:34:20 INFO DAGScheduler: Job 31 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031208 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(61) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0334690 (rel: 0,0140) 0,00643648
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 63 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 32 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 36 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 36.0 (TID 35)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 36.0 (TID 35). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 35) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:20 INFO DAGScheduler: Job 32 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029541 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(63) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0326367 (rel: 0,0249) 0,0142538
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 65 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 33 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 37 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 37.0 (TID 36)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 37.0 (TID 36). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 36) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:20 INFO DAGScheduler: Job 33 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030088 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(65) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0322304 (rel: 0,0124) 0,00481859
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 67 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 34 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 38 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 38.0 (TID 37)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 38.0 (TID 37). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 37) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:20 INFO DAGScheduler: Job 34 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029680 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(67) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0320398 (rel: 0,00592) 0,00458256
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.1 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 69 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 35 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 39 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 39.0 (TID 38)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 39.0 (TID 38). 68236 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 38) in 33 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892) finished in 0,033 s
19/01/24 18:34:20 INFO DAGScheduler: Job 35 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038509 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(69) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0317947 (rel: 0,00765) 0,0150047
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.8 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.7 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 71 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 36 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 40 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 40.0 (TID 39)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 40.0 (TID 39). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 39) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:20 INFO DAGScheduler: Job 36 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027280 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(71) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.7 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0315248 (rel: 0,00849) 0,00508445
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 73 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 37 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 41 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 41.0 (TID 40)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 41.0 (TID 40). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 40) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 41 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:20 INFO DAGScheduler: Job 37 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026560 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(73) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0314268 (rel: 0,00311) 0,00583252
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 75 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 38 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 42 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 42.0 (TID 41)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 42.0 (TID 41). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 41) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 42 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:20 INFO DAGScheduler: Job 38 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027284 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(75) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0312075 (rel: 0,00698) 0,00464233
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 77 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 39 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 43 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[75] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[75] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 43 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 43.0 (TID 42)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 43.0 (TID 42). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 42) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 43 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:20 INFO DAGScheduler: Job 39 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028782 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(77) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0309571 (rel: 0,00802) 0,00454268
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 79 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 40 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 44 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 44 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 44.0 (TID 43)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 44.0 (TID 43). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 43) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 44 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 18:34:20 INFO DAGScheduler: Job 40 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034651 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(79) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0307409 (rel: 0,00698) 0,00503477
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 81 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 41 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 45 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[77] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[77] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 45 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 45.0 (TID 44)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 45.0 (TID 44). 68150 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 44) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 45 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:20 INFO DAGScheduler: Job 41 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028487 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(81) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0304751 (rel: 0,00864) 0,00428555
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 83 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 42 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 46 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[78] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[78] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 46 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 46.0 (TID 45)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 46.0 (TID 45). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 45) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 46 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:20 INFO DAGScheduler: Job 42 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027407 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(83) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0302014 (rel: 0,00898) 0,00396539
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.1 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 85 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 43 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 47 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[79] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[79] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:20 WARN TaskSetManager: Stage 47 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 47.0 (TID 46)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 47.0 (TID 46). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 46) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 47 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:20 INFO DAGScheduler: Job 43 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034033 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(85) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.8 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0298543 (rel: 0,0115) 0,00537635
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.7 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 87 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 44 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 48 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[80] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[80] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 48 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 48.0 (TID 47)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 48.0 (TID 47). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 47) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 48 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:20 INFO DAGScheduler: Job 44 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028122 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(87) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.7 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0296887 (rel: 0,00554) 0,0116162
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 89 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 45 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 49 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[81] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[81] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 49 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 49.0 (TID 48)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 49.0 (TID 48). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 48) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 49 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:20 INFO DAGScheduler: Job 45 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039852 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(89) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0295122 (rel: 0,00595) 0,00539889
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 91 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 46 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 50 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[82] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[82] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 50 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 50.0 (TID 49)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 50.0 (TID 49). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 49) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 50 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:20 INFO DAGScheduler: Job 46 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027166 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(91) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0294075 (rel: 0,00355) 0,00319102
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 93 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 47 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 51 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[83] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[83] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 51 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 51.0 (TID 50)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 51.0 (TID 50). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 50) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 51 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:20 INFO DAGScheduler: Job 47 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027170 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(93) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0293339 (rel: 0,00250) 0,00352100
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 95 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 48 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 52 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[84] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[84] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 52 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 52.0 (TID 51)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 52.0 (TID 51). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 51) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 52 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:20 INFO DAGScheduler: Job 48 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026178 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(95) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0292944 (rel: 0,00135) 0,0111846
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 97 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 49 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 53 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[85] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[85] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 53 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 53.0 (TID 52)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 53.0 (TID 52). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 52) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 53 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:20 INFO DAGScheduler: Job 49 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026334 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(97) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0292388 (rel: 0,00190) 0,00613614
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 99 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 50 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 54 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 54 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 54.0 (TID 53)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 54.0 (TID 53). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 53) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 54 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:20 INFO DAGScheduler: Job 50 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026667 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(99) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0291668 (rel: 0,00246) 0,00573039
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 101 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.8 MB)
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 51 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 55 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 116.3 KB, free 360.4 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 55 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 55.0 (TID 54)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 55.0 (TID 54). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 54) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 55 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:20 INFO DAGScheduler: Job 51 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026650 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(101) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0291146 (rel: 0,00179) 0,00597272
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 103 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 52 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 56 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 56 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 56.0 (TID 55)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 56.0 (TID 55). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 55) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 56 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:20 INFO DAGScheduler: Job 52 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026722 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(103) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0289667 (rel: 0,00508) 0,00414288
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.2 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 105 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 53 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 57 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 57 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 57.0 (TID 56)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 57.0 (TID 56). 68236 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 56) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 57 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:20 INFO DAGScheduler: Job 53 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026478 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(105) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0288259 (rel: 0,00486) 0,00436637
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 107 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 54 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 58 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 58 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 58.0 (TID 57)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 58.0 (TID 57). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 57) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 58 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:20 INFO DAGScheduler: Job 54 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025999 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(107) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0287244 (rel: 0,00352) 0,00223707
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 109 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 55 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 59 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 59 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 59.0 (TID 58)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:20 INFO Executor: Finished task 0.0 in stage 59.0 (TID 58). 68193 bytes result sent to driver
19/01/24 18:34:20 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 58) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:20 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/01/24 18:34:20 INFO DAGScheduler: ResultStage 59 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:20 INFO DAGScheduler: Job 55 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026972 s
19/01/24 18:34:20 INFO TorrentBroadcast: Destroying Broadcast(109) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:20 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:20 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:20 INFO LBFGS: Val and Grad Norm: 0,0286589 (rel: 0,00228) 0,00213336
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.6 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 111 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:20 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:20 INFO DAGScheduler: Got job 56 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:20 INFO DAGScheduler: Final stage: ResultStage 60 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:20 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:20 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:20 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:20 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:20 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:20 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:20 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
19/01/24 18:34:20 WARN TaskSetManager: Stage 60 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:20 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:20 INFO Executor: Running task 0.0 in stage 60.0 (TID 59)
19/01/24 18:34:20 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 60.0 (TID 59). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 59) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 60 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:21 INFO DAGScheduler: Job 56 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028028 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(111) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0285803 (rel: 0,00274) 0,00415048
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 113 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 57 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 61 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 61 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 61.0 (TID 60)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 61.0 (TID 60). 68236 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 60) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 61 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:21 INFO DAGScheduler: Job 57 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026611 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(113) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 115 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 58 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 62 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 62 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 62.0 (TID 61)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 62.0 (TID 61). 68279 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 61) in 34 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 62 (treeAggregate at LogisticRegression.scala:1892) finished in 0,035 s
19/01/24 18:34:21 INFO DAGScheduler: Job 58 finished: treeAggregate at LogisticRegression.scala:1892, took 0,040033 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(115) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO StrongWolfeLineSearch: Line search t: 0.4267145302663191 fval: 0.02848748920414812 rhs: 0.028580243313891446 cdd: 5.6037400286210854E-8
19/01/24 18:34:21 INFO LBFGS: Step Size: 0,4267
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.8 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0284875 (rel: 0,00325) 0,00586295
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 117 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 59 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 63 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 63 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 63.0 (TID 62)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 63.0 (TID 62). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 62) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 63 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:21 INFO DAGScheduler: Job 59 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027229 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(117) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0283739 (rel: 0,00399) 0,00531647
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 119 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 60 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 64 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 64 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 64.0 (TID 63)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 64.0 (TID 63). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 63) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 64 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:21 INFO DAGScheduler: Job 60 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029068 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(119) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0282870 (rel: 0,00306) 0,00553462
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 121 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 61 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 65 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 65 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 65.0 (TID 64)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 65.0 (TID 64). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 64) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 65 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:21 INFO DAGScheduler: Job 61 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027513 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(121) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0282548 (rel: 0,00114) 0,00397435
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 123 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 62 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 66 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 66 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 66.0 (TID 65)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 66.0 (TID 65). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 65) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 66 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:21 INFO DAGScheduler: Job 62 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026926 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(123) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0282183 (rel: 0,00129) 0,00289874
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 125 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 63 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 67 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 67 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 67.0 (TID 66)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 67.0 (TID 66). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 66) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 67 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:21 INFO DAGScheduler: Job 63 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027207 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(125) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0281719 (rel: 0,00164) 0,00445034
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 127 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 64 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 68 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 68 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 68.0 (TID 67)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 68.0 (TID 67). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 67) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 68 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:21 INFO DAGScheduler: Job 64 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026714 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(127) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0281092 (rel: 0,00223) 0,00521472
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 129 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 65 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 69 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 69 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 69.0 (TID 68)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 69.0 (TID 68). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 68) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 69 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:34:21 INFO DAGScheduler: Job 65 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030789 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(129) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0280739 (rel: 0,00125) 0,00627099
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.1 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 131 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 66 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 70 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 70 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 70.0 (TID 69)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 70.0 (TID 69). 68236 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 69) in 33 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 70 (treeAggregate at LogisticRegression.scala:1892) finished in 0,035 s
19/01/24 18:34:21 INFO DAGScheduler: Job 66 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039673 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(131) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.8 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0280154 (rel: 0,00208) 0,00209270
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 133 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 67 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 71 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 71 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 71.0 (TID 70)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 71.0 (TID 70). 68236 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 70) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 71 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:21 INFO DAGScheduler: Job 67 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028211 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(133) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0279933 (rel: 0,000787) 0,00174697
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 135 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 68 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 72 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 72 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 72.0 (TID 71)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 72.0 (TID 71). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 71) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 72 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:21 INFO DAGScheduler: Job 68 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028882 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(135) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0279381 (rel: 0,00197) 0,00168608
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 137 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 69 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 73 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[105] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[105] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 73 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 73.0 (TID 72)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 73.0 (TID 72). 68236 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 72) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 73 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:21 INFO DAGScheduler: Job 69 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027732 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(137) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0278585 (rel: 0,00285) 0,00163783
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 139 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 70 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 74 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[106] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[106] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 74 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 74.0 (TID 73)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 74.0 (TID 73). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 73) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 74 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:21 INFO DAGScheduler: Job 70 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027371 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(139) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0277578 (rel: 0,00361) 0,00180832
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 141 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 71 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 75 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[107] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[107] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 75 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 75.0 (TID 74)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 75.0 (TID 74). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 74) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 75 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:34:21 INFO DAGScheduler: Job 71 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037979 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(141) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 143 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 72 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 76 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[108] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[108] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 76 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 76.0 (TID 75)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 76.0 (TID 75). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 75) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 76 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:21 INFO DAGScheduler: Job 72 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030035 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(143) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO StrongWolfeLineSearch: Line search t: 0.1 fval: 0.027738693432296787 rhs: 0.027757797712281675 cdd: -5.903516402336295E-6
19/01/24 18:34:21 INFO LBFGS: Step Size: 0,1000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0277387 (rel: 0,000688) 0,00422118
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 145 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 73 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 77 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[109] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[109] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 77 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 77.0 (TID 76)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 77.0 (TID 76). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 76) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 77 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 18:34:21 INFO DAGScheduler: Job 73 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037306 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(145) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0276637 (rel: 0,00270) 0,00155316
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.1 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 147 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 74 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 78 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[110] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[110] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 78 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 78.0 (TID 77)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 78.0 (TID 77). 68236 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 77) in 33 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 78 (treeAggregate at LogisticRegression.scala:1892) finished in 0,033 s
19/01/24 18:34:21 INFO DAGScheduler: Job 74 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038338 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(147) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.8 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0276344 (rel: 0,00106) 0,00261385
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 149 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 75 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 79 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[111] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[111] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 79 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 79.0 (TID 78)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 79.0 (TID 78). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 78) in 30 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 79 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 18:34:21 INFO DAGScheduler: Job 75 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037059 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(149) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0276142 (rel: 0,000733) 0,00179582
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 151 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 76 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 80 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[112] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[112] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 80 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 80.0 (TID 79)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 80.0 (TID 79). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 79) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 80 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:21 INFO DAGScheduler: Job 76 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029793 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(151) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0275970 (rel: 0,000620) 0,00226395
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 153 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 77 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 81 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[113] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[113] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 81 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 81.0 (TID 80)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 81.0 (TID 80). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 80) in 27 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 81 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 18:34:21 INFO DAGScheduler: Job 77 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033047 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(153) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0275743 (rel: 0,000825) 0,00167558
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 155 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 78 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 82 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[114] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[114] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 82 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 82.0 (TID 81)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 82.0 (TID 81). 68236 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 81) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 82 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:21 INFO DAGScheduler: Job 78 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028625 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(155) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 157 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 79 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 83 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[115] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[115] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 83 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 83.0 (TID 82)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 83.0 (TID 82). 68236 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 82) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 83 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:34:21 INFO DAGScheduler: Job 79 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031324 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(157) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO StrongWolfeLineSearch: Line search t: 0.4769797418924374 fval: 0.0275444991324947 rhs: 0.02757426596461796 cdd: 3.9424837397726215E-8
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:34:21 INFO LBFGS: Step Size: 0,4770
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0275445 (rel: 0,00108) 0,00616549
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 159 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 80 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 84 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[116] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[116] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:21 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
19/01/24 18:34:21 WARN TaskSetManager: Stage 84 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:21 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:21 INFO Executor: Running task 0.0 in stage 84.0 (TID 83)
19/01/24 18:34:21 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:21 INFO Executor: Finished task 0.0 in stage 84.0 (TID 83). 68193 bytes result sent to driver
19/01/24 18:34:21 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 83) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:21 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
19/01/24 18:34:21 INFO DAGScheduler: ResultStage 84 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:21 INFO DAGScheduler: Job 80 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028627 s
19/01/24 18:34:21 INFO TorrentBroadcast: Destroying Broadcast(159) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:21 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:21 INFO LBFGS: Val and Grad Norm: 0,0275073 (rel: 0,00135) 0,00214546
19/01/24 18:34:21 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:21 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 18:34:21 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:21 INFO SparkContext: Created broadcast 161 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:21 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:21 INFO DAGScheduler: Got job 81 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:21 INFO DAGScheduler: Final stage: ResultStage 85 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:21 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:21 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:21 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[117] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[117] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 85 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 85.0 (TID 84)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 85.0 (TID 84). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 84) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 85 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:22 INFO DAGScheduler: Job 81 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030809 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(161) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0274931 (rel: 0,000516) 0,00158449
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.1 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.2 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 163 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 82 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 86 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[118] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[118] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 86 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 86.0 (TID 85)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 86.0 (TID 85). 68279 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 85) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 86 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 18:34:22 INFO DAGScheduler: Job 82 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032365 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(163) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0274843 (rel: 0,000320) 0,00180161
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.8 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.7 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 165 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 83 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 87 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[119] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[119] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 87 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 87.0 (TID 86)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 87.0 (TID 86). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 86) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 87 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:22 INFO DAGScheduler: Job 83 finished: treeAggregate at LogisticRegression.scala:1892, took 0,048391 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(165) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.7 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0274576 (rel: 0,000971) 0,00158743
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 167 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 84 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 88 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[120] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[120] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 88 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 88.0 (TID 87)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 88.0 (TID 87). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 87) in 20 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 88 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:22 INFO DAGScheduler: Job 84 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025952 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(167) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0274144 (rel: 0,00158) 0,00393116
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 169 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 85 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 89 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[121] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[121] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 89 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 89.0 (TID 88)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 89.0 (TID 88). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 88) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 89 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:22 INFO DAGScheduler: Job 85 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026612 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(169) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0273875 (rel: 0,000982) 0,00432852
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 171 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 86 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 90 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[122] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[122] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 90 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 90.0 (TID 89)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 90.0 (TID 89). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 89) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 90 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:22 INFO DAGScheduler: Job 86 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027964 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(171) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0273598 (rel: 0,00101) 0,00188127
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 173 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 87 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 91 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[123] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[123] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 91 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 91.0 (TID 90)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 91.0 (TID 90). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 90) in 24 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 91 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 18:34:22 INFO DAGScheduler: Job 87 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032164 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(173) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0273468 (rel: 0,000476) 0,00116889
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 175 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 88 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 92 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[124] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[124] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 92 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 92.0 (TID 91)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 92.0 (TID 91). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 91) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 92 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:22 INFO DAGScheduler: Job 88 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028373 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(175) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0273375 (rel: 0,000339) 0,00133102
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 177 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 89 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 93 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[125] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[125] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 93 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 93.0 (TID 92)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 93.0 (TID 92). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 92) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 93 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:22 INFO DAGScheduler: Job 89 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026282 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(177) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.1 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.2 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 179 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 90 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 94 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[126] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[126] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:22 WARN TaskSetManager: Stage 94 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 94.0 (TID 93)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 94.0 (TID 93). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 93) in 28 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 94 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 18:34:22 INFO DAGScheduler: Job 90 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034898 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(179) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO StrongWolfeLineSearch: Line search t: 0.44238853046279136 fval: 0.027322638685121102 rhs: 0.02733753822231949 cdd: 4.543171550924762E-8
19/01/24 18:34:22 INFO LBFGS: Step Size: 0,4424
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.8 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0273226 (rel: 0,000545) 0,00359478
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 181 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 91 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 95 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[127] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[127] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 95 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 95.0 (TID 94)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 95.0 (TID 94). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 94) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 95 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:22 INFO DAGScheduler: Job 91 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028819 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(181) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0273029 (rel: 0,000724) 0,00144224
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 183 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 92 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 96 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[128] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[128] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 96 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 96.0 (TID 95)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 96.0 (TID 95). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 95) in 34 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 96 (treeAggregate at LogisticRegression.scala:1892) finished in 0,034 s
19/01/24 18:34:22 INFO DAGScheduler: Job 92 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039206 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(183) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0272873 (rel: 0,000571) 0,00140178
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.0 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 185 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 93 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 97 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[129] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[129] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 97 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 97.0 (TID 96)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 97.0 (TID 96). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 96) in 29 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 97 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 18:34:22 INFO DAGScheduler: Job 93 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034924 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(185) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 187 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 94 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 98 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[130] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[130] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 98 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 98.0 (TID 97)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 98.0 (TID 97). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 97) in 27 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 98 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 18:34:22 INFO DAGScheduler: Job 94 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033815 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(187) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO StrongWolfeLineSearch: Line search t: 0.18124034043854675 fval: 0.02727528205684075 rhs: 0.027287265460974944 cdd: -5.034893050342904E-7
19/01/24 18:34:22 INFO LBFGS: Step Size: 0,1812
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0272753 (rel: 0,000439) 0,00379483
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 189 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 95 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 99 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[131] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[131] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 99 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 99.0 (TID 98)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 99.0 (TID 98). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 98) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 99 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:22 INFO DAGScheduler: Job 95 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026883 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(189) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0272599 (rel: 0,000564) 0,00212009
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 191 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 96 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 100 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[132] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[132] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 100 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 100.0 (TID 99)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 100.0 (TID 99). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 99) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 100 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:22 INFO DAGScheduler: Job 96 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027227 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(191) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0272480 (rel: 0,000436) 0,00117490
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 193 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 97 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 101 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[133] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[133] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 101 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 101.0 (TID 100)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 101.0 (TID 100). 68236 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 100) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 101 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:22 INFO DAGScheduler: Job 97 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027098 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(193) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0272368 (rel: 0,000412) 0,00132283
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.2 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 195 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 98 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 102 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[134] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.1 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[134] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:22 WARN TaskSetManager: Stage 102 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 102.0 (TID 101)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 102.0 (TID 101). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 101) in 25 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 102 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 18:34:22 INFO DAGScheduler: Job 98 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034473 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(195) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0272191 (rel: 0,000649) 0,00202239
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.7 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 197 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 99 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 103 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[135] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[135] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 103 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 103.0 (TID 102)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 103.0 (TID 102). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 102) in 20 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 103 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:22 INFO DAGScheduler: Job 99 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026550 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(197) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.7 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0272060 (rel: 0,000484) 0,00307922
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 199 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 100 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 104 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[136] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[136] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 104 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 104.0 (TID 103)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 104.0 (TID 103). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 103) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 104 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:22 INFO DAGScheduler: Job 100 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027008 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(199) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0271824 (rel: 0,000867) 0,00153555
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 201 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 101 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 105 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[137] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[137] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 105 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 105.0 (TID 104)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 105.0 (TID 104). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 104) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 105 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:22 INFO DAGScheduler: Job 101 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026466 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(201) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0271749 (rel: 0,000274) 0,00102271
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 203 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 102 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 106 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[138] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[138] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 106 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 106.0 (TID 105)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 106.0 (TID 105). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 105) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 106 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:22 INFO DAGScheduler: Job 102 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027616 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(203) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0271630 (rel: 0,000438) 0,000860860
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 205 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 103 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 107 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[139] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[139] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 107 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 107.0 (TID 106)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 107.0 (TID 106). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 106) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 107 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 18:34:22 INFO DAGScheduler: Job 103 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028029 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(205) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 207 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 104 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 108 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[140] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[140] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 108 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 108.0 (TID 107)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 108.0 (TID 107). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 107) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 108 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:22 INFO DAGScheduler: Job 104 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028178 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(207) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO StrongWolfeLineSearch: Line search t: 0.19604525695405883 fval: 0.02715561387700296 rhs: 0.027163021359093393 cdd: -2.620166538343346E-8
19/01/24 18:34:22 INFO LBFGS: Step Size: 0,1960
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0271556 (rel: 0,000273) 0,00187077
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 209 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 105 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 109 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[141] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[141] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
19/01/24 18:34:22 WARN TaskSetManager: Stage 109 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:22 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:22 INFO Executor: Running task 0.0 in stage 109.0 (TID 108)
19/01/24 18:34:22 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:22 INFO Executor: Finished task 0.0 in stage 109.0 (TID 108). 68193 bytes result sent to driver
19/01/24 18:34:22 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 108) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:22 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
19/01/24 18:34:22 INFO DAGScheduler: ResultStage 109 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:22 INFO DAGScheduler: Job 105 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025840 s
19/01/24 18:34:22 INFO TorrentBroadcast: Destroying Broadcast(209) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:22 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO LBFGS: Val and Grad Norm: 0,0271413 (rel: 0,000526) 0,00152413
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.1 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 211 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.8 MB)
19/01/24 18:34:22 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:22 INFO DAGScheduler: Got job 106 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:22 INFO DAGScheduler: Final stage: ResultStage 110 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:22 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:22 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:22 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[142] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 116.3 KB, free 360.4 MB)
19/01/24 18:34:22 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.4 MB)
19/01/24 18:34:22 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:22 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[142] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:22 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 110 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 110.0 (TID 109)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 110.0 (TID 109). 68150 bytes result sent to driver
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 109) in 23 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 110 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 18:34:23 INFO DAGScheduler: Job 106 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028237 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(211) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.8 MB)
19/01/24 18:34:23 INFO LBFGS: Val and Grad Norm: 0,0271041 (rel: 0,00137) 0,00202190
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 213 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:23 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:23 INFO DAGScheduler: Got job 107 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:23 INFO DAGScheduler: Final stage: ResultStage 111 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:23 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:23 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:23 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[143] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[143] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:23 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 111 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 111.0 (TID 110)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 111.0 (TID 110). 68193 bytes result sent to driver
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 110) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 111 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:23 INFO DAGScheduler: Job 107 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025564 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(213) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 215 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:23 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:23 INFO DAGScheduler: Got job 108 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:23 INFO DAGScheduler: Final stage: ResultStage 112 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:23 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:23 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:23 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[144] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[144] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:23 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 112 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 112.0 (TID 111)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 112.0 (TID 111). 68193 bytes result sent to driver
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 111) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 112 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:23 INFO DAGScheduler: Job 108 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026350 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(215) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO StrongWolfeLineSearch: Line search t: 0.5007448344415253 fval: 0.027092939336304526 rhs: 0.027104070568816956 cdd: -4.9042881056530016E-9
19/01/24 18:34:23 INFO LBFGS: Step Size: 0,5007
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO LBFGS: Val and Grad Norm: 0,0270929 (rel: 0,000411) 0,00189099
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 217 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:23 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:23 INFO DAGScheduler: Got job 109 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:23 INFO DAGScheduler: Final stage: ResultStage 113 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:23 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:23 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:23 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[145] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[145] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:23 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 113 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 113.0 (TID 112)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 113.0 (TID 112). 68193 bytes result sent to driver
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 112) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 113 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:23 INFO DAGScheduler: Job 109 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026163 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(217) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:23 INFO LBFGS: Val and Grad Norm: 0,0270825 (rel: 0,000385) 0,00131139
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 219 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:23 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:23 INFO DAGScheduler: Got job 110 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:23 INFO DAGScheduler: Final stage: ResultStage 114 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:23 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:23 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:23 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[146] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[146] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:23 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 114 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 114.0 (TID 113)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 114.0 (TID 113). 68193 bytes result sent to driver
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 113) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 114 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:23 INFO DAGScheduler: Job 110 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025581 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(219) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 18:34:23 INFO LBFGS: Val and Grad Norm: 0,0270734 (rel: 0,000337) 0,00167538
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 221 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:23 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:23 INFO DAGScheduler: Got job 111 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:23 INFO DAGScheduler: Final stage: ResultStage 115 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:23 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:23 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:23 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[147] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[147] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:23 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 115 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 115.0 (TID 114)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 115.0 (TID 114). 68236 bytes result sent to driver
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 114) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 115 (treeAggregate at LogisticRegression.scala:1892) finished in 0,021 s
19/01/24 18:34:23 INFO DAGScheduler: Job 111 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026462 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(221) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 18:34:23 INFO LBFGS: Val and Grad Norm: 0,0270557 (rel: 0,000654) 0,00129150
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.4 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 127.0.0.1:53848 (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 223 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:23 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:23 INFO DAGScheduler: Got job 112 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:23 INFO DAGScheduler: Final stage: ResultStage 116 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:23 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:23 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:23 INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[148] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[148] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:23 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 116 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 116.0 (TID 115)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 116.0 (TID 115). 68193 bytes result sent to driver
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 115) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 116 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:23 INFO DAGScheduler: Job 112 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026183 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(223) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 127.0.0.1:53848 in memory (size: 57.3 KB, free: 361.3 MB)
19/01/24 18:34:23 INFO LBFGS: Val and Grad Norm: 0,0270527 (rel: 0,000112) 0,00487597
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.3 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 225 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:23 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:23 INFO DAGScheduler: Got job 113 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:23 INFO DAGScheduler: Final stage: ResultStage 117 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:23 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:23 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:23 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[149] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.2 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[149] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:23 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 117 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 117.0 (TID 116)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 117.0 (TID 116). 68193 bytes result sent to driver
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 116) in 26 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 117 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 18:34:23 INFO DAGScheduler: Job 113 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030793 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(225) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 18:34:23 INFO LBFGS: Val and Grad Norm: 0,0270365 (rel: 0,000598) 0,00244017
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 227 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:23 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:23 INFO DAGScheduler: Got job 114 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:23 INFO DAGScheduler: Final stage: ResultStage 118 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:23 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:23 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:23 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[150] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[150] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:23 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 118 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 118.0 (TID 117)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 118.0 (TID 117). 68193 bytes result sent to driver
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 117) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 118 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:23 INFO DAGScheduler: Job 114 finished: treeAggregate at LogisticRegression.scala:1892, took 0,025870 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(227) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 18:34:23 INFO LBFGS: Val and Grad Norm: 0,0270285 (rel: 0,000294) 0,00115072
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 127.0.0.1:53848 (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 229 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:23 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:23 INFO DAGScheduler: Got job 115 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:23 INFO DAGScheduler: Final stage: ResultStage 119 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:23 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:23 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:23 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[151] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[151] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:23 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 119 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 119.0 (TID 118)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 119.0 (TID 118). 68193 bytes result sent to driver
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 118) in 21 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 119 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:23 INFO DAGScheduler: Job 115 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026462 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(229) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 127.0.0.1:53848 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO LBFGS: Val and Grad Norm: 0,0270226 (rel: 0,000218) 0,000931583
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.0 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 127.0.0.1:53848 (size: 57.5 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 231 from broadcast at LogisticRegression.scala:1879
19/01/24 18:34:23 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 18:34:23 INFO DAGScheduler: Got job 116 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 18:34:23 INFO DAGScheduler: Final stage: ResultStage 120 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 18:34:23 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:34:23 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:23 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[152] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 18:34:23 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 18:34:23 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 127.0.0.1:53848 (size: 74.8 KB, free: 361.5 MB)
19/01/24 18:34:23 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[152] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:23 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks
19/01/24 18:34:23 WARN TaskSetManager: Stage 120 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:23 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 119, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 18:34:23 INFO Executor: Running task 0.0 in stage 120.0 (TID 119)
19/01/24 18:34:23 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 18:34:23 INFO Executor: Finished task 0.0 in stage 120.0 (TID 119). 68193 bytes result sent to driver
19/01/24 18:34:23 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 119) in 22 ms on localhost (executor driver) (1/1)
19/01/24 18:34:23 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
19/01/24 18:34:23 INFO DAGScheduler: ResultStage 120 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 18:34:23 INFO DAGScheduler: Job 116 finished: treeAggregate at LogisticRegression.scala:1892, took 0,026217 s
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(231) (from destroy at LogisticRegression.scala:1933)
19/01/24 18:34:23 INFO LBFGS: Step Size: 1,000
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 127.0.0.1:53848 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 18:34:23 INFO LBFGS: Val and Grad Norm: 0,0270067 (rel: 0,000588) 0,000915275
19/01/24 18:34:23 INFO LBFGS: Converged because max iterations reached
19/01/24 18:34:23 INFO TorrentBroadcast: Destroying Broadcast(10) (from destroy at LogisticRegression.scala:796)
19/01/24 18:34:23 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53848 in memory (size: 7.7 KB, free: 361.6 MB)
19/01/24 18:34:23 INFO MapPartitionsRDD: Removing RDD 40 from persistence list
19/01/24 18:34:23 INFO BlockManager: Removing RDD 40
19/01/24 18:34:23 INFO CodeGenerator: Code generated in 19.943199 ms
19/01/24 18:34:23 INFO Instrumentation: LogisticRegression-logistic_regression_4c8481f65f5-846246232-1: training finished
19/01/24 18:34:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c86e047f0`
19/01/24 18:34:47 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c81ed72d33
19/01/24 18:34:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c81ed72d33` AS `zzz8`
WHERE (0 = 1)
19/01/24 18:34:47 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c81ed72d33`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:34:47 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:47 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:47 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c81ed72d33`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:34:47 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:47 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:47 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c81ed72d33`
GROUP BY `Sentiment`, `Prediction`
LIMIT 11
19/01/24 18:34:47 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:47 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:47 INFO CodeGenerator: Code generated in 16.529501 ms
19/01/24 18:34:47 INFO CodeGenerator: Code generated in 40.805007 ms
19/01/24 18:34:47 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:34:47 INFO DAGScheduler: Registering RDD 160 (collect at utils.scala:200)
19/01/24 18:34:47 INFO DAGScheduler: Got job 117 (collect at utils.scala:200) with 1 output partitions
19/01/24 18:34:47 INFO DAGScheduler: Final stage: ResultStage 122 (collect at utils.scala:200)
19/01/24 18:34:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)
19/01/24 18:34:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 121)
19/01/24 18:34:47 INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[160] at collect at utils.scala:200), which has no missing parents
19/01/24 18:34:47 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 196.0 KB, free 362.3 MB)
19/01/24 18:34:47 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 140.5 KB, free 362.2 MB)
19/01/24 18:34:47 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 127.0.0.1:53848 (size: 140.5 KB, free: 364.0 MB)
19/01/24 18:34:47 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[160] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:47 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
19/01/24 18:34:47 WARN TaskSetManager: Stage 121 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:34:47 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:34:47 INFO Executor: Running task 0.0 in stage 121.0 (TID 120)
19/01/24 18:34:47 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 18:34:47 INFO CodeGenerator: Code generated in 4.666711 ms
19/01/24 18:34:47 INFO CodeGenerator: Code generated in 3.546438 ms
19/01/24 18:34:47 INFO CodeGenerator: Code generated in 4.003373 ms
19/01/24 18:34:47 INFO CodeGenerator: Code generated in 7.932717 ms
19/01/24 18:34:47 INFO CodeGenerator: Code generated in 4.961002 ms
19/01/24 18:34:48 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 364.0 MB)
19/01/24 18:34:48 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 364.1 MB)
19/01/24 18:34:48 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 364.2 MB)
19/01/24 18:34:48 INFO ContextCleaner: Cleaned accumulator 2957
19/01/24 18:34:48 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 127.0.0.1:53848 in memory (size: 74.8 KB, free: 364.3 MB)
19/01/24 18:34:48 INFO Executor: Finished task 0.0 in stage 121.0 (TID 120). 2263 bytes result sent to driver
19/01/24 18:34:48 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 120) in 354 ms on localhost (executor driver) (1/1)
19/01/24 18:34:48 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
19/01/24 18:34:48 INFO DAGScheduler: ShuffleMapStage 121 (collect at utils.scala:200) finished in 0,356 s
19/01/24 18:34:48 INFO DAGScheduler: looking for newly runnable stages
19/01/24 18:34:48 INFO DAGScheduler: running: Set()
19/01/24 18:34:48 INFO DAGScheduler: waiting: Set(ResultStage 122)
19/01/24 18:34:48 INFO DAGScheduler: failed: Set()
19/01/24 18:34:48 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[163] at collect at utils.scala:200), which has no missing parents
19/01/24 18:34:48 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 177.3 KB, free 362.8 MB)
19/01/24 18:34:48 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 136.1 KB, free 362.6 MB)
19/01/24 18:34:48 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 127.0.0.1:53848 (size: 136.1 KB, free: 364.1 MB)
19/01/24 18:34:48 INFO SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[163] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 18:34:48 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
19/01/24 18:34:48 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 121, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 18:34:48 INFO Executor: Running task 0.0 in stage 122.0 (TID 121)
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:34:48 INFO Executor: Finished task 0.0 in stage 122.0 (TID 121). 2584 bytes result sent to driver
19/01/24 18:34:48 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 121) in 9 ms on localhost (executor driver) (1/1)
19/01/24 18:34:48 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
19/01/24 18:34:48 INFO DAGScheduler: ResultStage 122 (collect at utils.scala:200) finished in 0,009 s
19/01/24 18:34:48 INFO DAGScheduler: Job 117 finished: collect at utils.scala:200, took 0,375153 s
19/01/24 18:34:48 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:34:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 149 bytes
19/01/24 18:34:48 INFO DAGScheduler: Got job 118 (collect at utils.scala:200) with 4 output partitions
19/01/24 18:34:48 INFO DAGScheduler: Final stage: ResultStage 124 (collect at utils.scala:200)
19/01/24 18:34:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 123)
19/01/24 18:34:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:48 INFO DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[163] at collect at utils.scala:200), which has no missing parents
19/01/24 18:34:48 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 177.3 KB, free 362.5 MB)
19/01/24 18:34:48 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 136.1 KB, free 362.3 MB)
19/01/24 18:34:48 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 127.0.0.1:53848 (size: 136.1 KB, free: 364.0 MB)
19/01/24 18:34:48 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 124 (MapPartitionsRDD[163] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
19/01/24 18:34:48 INFO TaskSchedulerImpl: Adding task set 124.0 with 4 tasks
19/01/24 18:34:48 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 122, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:34:48 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 123, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:34:48 INFO TaskSetManager: Starting task 2.0 in stage 124.0 (TID 124, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:34:48 INFO TaskSetManager: Starting task 3.0 in stage 124.0 (TID 125, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:34:48 INFO Executor: Running task 0.0 in stage 124.0 (TID 122)
19/01/24 18:34:48 INFO Executor: Running task 1.0 in stage 124.0 (TID 123)
19/01/24 18:34:48 INFO Executor: Running task 2.0 in stage 124.0 (TID 124)
19/01/24 18:34:48 INFO Executor: Running task 3.0 in stage 124.0 (TID 125)
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:34:48 INFO Executor: Finished task 1.0 in stage 124.0 (TID 123). 2515 bytes result sent to driver
19/01/24 18:34:48 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 123) in 12 ms on localhost (executor driver) (1/4)
19/01/24 18:34:48 INFO Executor: Finished task 3.0 in stage 124.0 (TID 125). 2515 bytes result sent to driver
19/01/24 18:34:48 INFO Executor: Finished task 0.0 in stage 124.0 (TID 122). 2515 bytes result sent to driver
19/01/24 18:34:48 INFO Executor: Finished task 2.0 in stage 124.0 (TID 124). 2515 bytes result sent to driver
19/01/24 18:34:48 INFO TaskSetManager: Finished task 3.0 in stage 124.0 (TID 125) in 12 ms on localhost (executor driver) (2/4)
19/01/24 18:34:48 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 122) in 13 ms on localhost (executor driver) (3/4)
19/01/24 18:34:48 INFO TaskSetManager: Finished task 2.0 in stage 124.0 (TID 124) in 13 ms on localhost (executor driver) (4/4)
19/01/24 18:34:48 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
19/01/24 18:34:48 INFO DAGScheduler: ResultStage 124 (collect at utils.scala:200) finished in 0,013 s
19/01/24 18:34:48 INFO DAGScheduler: Job 118 finished: collect at utils.scala:200, took 0,016946 s
19/01/24 18:34:48 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 18:34:48 INFO DAGScheduler: Got job 119 (collect at utils.scala:200) with 3 output partitions
19/01/24 18:34:48 INFO DAGScheduler: Final stage: ResultStage 126 (collect at utils.scala:200)
19/01/24 18:34:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
19/01/24 18:34:48 INFO DAGScheduler: Missing parents: List()
19/01/24 18:34:48 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[163] at collect at utils.scala:200), which has no missing parents
19/01/24 18:34:48 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 177.3 KB, free 362.2 MB)
19/01/24 18:34:48 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 136.1 KB, free 362.0 MB)
19/01/24 18:34:48 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 127.0.0.1:53848 (size: 136.1 KB, free: 363.9 MB)
19/01/24 18:34:48 INFO SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1006
19/01/24 18:34:48 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 126 (MapPartitionsRDD[163] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(5, 6, 7))
19/01/24 18:34:48 INFO TaskSchedulerImpl: Adding task set 126.0 with 3 tasks
19/01/24 18:34:48 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 126, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
19/01/24 18:34:48 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 127, localhost, executor driver, partition 5, ANY, 4726 bytes)
19/01/24 18:34:48 INFO TaskSetManager: Starting task 2.0 in stage 126.0 (TID 128, localhost, executor driver, partition 7, ANY, 4726 bytes)
19/01/24 18:34:48 INFO Executor: Running task 1.0 in stage 126.0 (TID 126)
19/01/24 18:34:48 INFO Executor: Running task 0.0 in stage 126.0 (TID 127)
19/01/24 18:34:48 INFO Executor: Running task 2.0 in stage 126.0 (TID 128)
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 18:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 18:34:48 INFO Executor: Finished task 0.0 in stage 126.0 (TID 127). 2548 bytes result sent to driver
19/01/24 18:34:48 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 127) in 6 ms on localhost (executor driver) (1/3)
19/01/24 18:34:48 INFO Executor: Finished task 2.0 in stage 126.0 (TID 128). 2535 bytes result sent to driver
19/01/24 18:34:48 INFO Executor: Finished task 1.0 in stage 126.0 (TID 126). 2515 bytes result sent to driver
19/01/24 18:34:48 INFO TaskSetManager: Finished task 2.0 in stage 126.0 (TID 128) in 7 ms on localhost (executor driver) (2/3)
19/01/24 18:34:48 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 126) in 7 ms on localhost (executor driver) (3/3)
19/01/24 18:34:48 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
19/01/24 18:34:48 INFO DAGScheduler: ResultStage 126 (collect at utils.scala:200) finished in 0,008 s
19/01/24 18:34:48 INFO DAGScheduler: Job 119 finished: collect at utils.scala:200, took 0,012920 s
19/01/24 18:34:48 INFO CodeGenerator: Code generated in 4.50662 ms
19/01/24 18:34:48 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c81ed72d33`
GROUP BY `Sentiment`, `Prediction`
19/01/24 18:34:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:34:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:34:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:34:48 INFO CodeGenerator: Code generated in 5.220284 ms
19/01/24 18:34:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:34:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:34:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:34:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:34:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:34:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:34:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:34:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:58:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 18:58:55 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:58:55 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:58:55 INFO HiveMetaStore: 0: get_database: default
19/01/24 18:58:55 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 18:58:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 18:58:55 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 18:58:55 INFO CodeGenerator: Code generated in 3.915851 ms
19/01/24 18:58:55 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 18:58:55 INFO DAGScheduler: Got job 120 (collect at utils.scala:44) with 4 output partitions
19/01/24 18:58:55 INFO DAGScheduler: Final stage: ResultStage 127 (collect at utils.scala:44)
19/01/24 18:58:55 INFO DAGScheduler: Parents of final stage: List()
19/01/24 18:58:55 INFO DAGScheduler: Missing parents: List()
19/01/24 18:58:55 INFO DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[168] at map at utils.scala:41), which has no missing parents
19/01/24 18:58:55 INFO MemoryStore: Block broadcast_237 stored as values in memory (estimated size 6.6 KB, free 362.0 MB)
19/01/24 18:58:55 INFO MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 3.6 KB, free 362.0 MB)
19/01/24 18:58:55 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 127.0.0.1:53848 (size: 3.6 KB, free: 363.9 MB)
19/01/24 18:58:55 INFO SparkContext: Created broadcast 237 from broadcast at DAGScheduler.scala:1006
19/01/24 18:58:55 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 127 (MapPartitionsRDD[168] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/01/24 18:58:55 INFO TaskSchedulerImpl: Adding task set 127.0 with 4 tasks
19/01/24 18:58:55 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 5019 bytes)
19/01/24 18:58:55 INFO TaskSetManager: Starting task 1.0 in stage 127.0 (TID 130, localhost, executor driver, partition 1, PROCESS_LOCAL, 5027 bytes)
19/01/24 18:58:55 INFO TaskSetManager: Starting task 2.0 in stage 127.0 (TID 131, localhost, executor driver, partition 2, PROCESS_LOCAL, 5027 bytes)
19/01/24 18:58:55 INFO TaskSetManager: Starting task 3.0 in stage 127.0 (TID 132, localhost, executor driver, partition 3, PROCESS_LOCAL, 5027 bytes)
19/01/24 18:58:55 INFO Executor: Running task 0.0 in stage 127.0 (TID 129)
19/01/24 18:58:55 INFO Executor: Running task 2.0 in stage 127.0 (TID 131)
19/01/24 18:58:55 INFO Executor: Running task 3.0 in stage 127.0 (TID 132)
19/01/24 18:58:55 INFO Executor: Running task 1.0 in stage 127.0 (TID 130)
19/01/24 18:58:55 INFO Executor: Finished task 2.0 in stage 127.0 (TID 131). 911 bytes result sent to driver
19/01/24 18:58:55 INFO Executor: Finished task 1.0 in stage 127.0 (TID 130). 911 bytes result sent to driver
19/01/24 18:58:55 INFO Executor: Finished task 0.0 in stage 127.0 (TID 129). 900 bytes result sent to driver
19/01/24 18:58:55 INFO Executor: Finished task 3.0 in stage 127.0 (TID 132). 910 bytes result sent to driver
19/01/24 18:58:55 INFO TaskSetManager: Finished task 2.0 in stage 127.0 (TID 131) in 4 ms on localhost (executor driver) (1/4)
19/01/24 18:58:55 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 129) in 4 ms on localhost (executor driver) (2/4)
19/01/24 18:58:55 INFO TaskSetManager: Finished task 1.0 in stage 127.0 (TID 130) in 5 ms on localhost (executor driver) (3/4)
19/01/24 18:58:55 INFO TaskSetManager: Finished task 3.0 in stage 127.0 (TID 132) in 5 ms on localhost (executor driver) (4/4)
19/01/24 18:58:55 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
19/01/24 18:58:55 INFO DAGScheduler: ResultStage 127 (collect at utils.scala:44) finished in 0,006 s
19/01/24 18:58:55 INFO DAGScheduler: Job 120 finished: collect at utils.scala:44, took 0,008731 s
19/01/24 18:58:55 INFO MapPartitionsRDD: Removing RDD 9 from persistence list
19/01/24 18:58:55 INFO BlockManager: Removing RDD 9
19/01/24 18:58:56 INFO SparkSqlParser: Parsing command: reviews_spark
19/01/24 18:58:56 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews_spark`
19/01/24 18:58:56 INFO SparkSqlParser: Parsing command: `reviews_spark`
19/01/24 18:58:56 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 18:58:56 INFO DAGScheduler: Registering RDD 176 (sql at <unknown>:0)
19/01/24 18:58:56 INFO DAGScheduler: Got job 121 (sql at <unknown>:0) with 1 output partitions
19/01/24 18:58:56 INFO DAGScheduler: Final stage: ResultStage 129 (sql at <unknown>:0)
19/01/24 18:58:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 128)
19/01/24 18:58:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 128)
19/01/24 18:58:56 INFO DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[176] at sql at <unknown>:0), which has no missing parents
19/01/24 18:58:56 INFO MemoryStore: Block broadcast_238 stored as values in memory (estimated size 15.5 KB, free 363.8 MB)
19/01/24 18:58:56 INFO MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 7.7 KB, free 363.8 MB)
19/01/24 18:58:56 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 127.0.0.1:53848 (size: 7.7 KB, free: 365.7 MB)
19/01/24 18:58:56 INFO SparkContext: Created broadcast 238 from broadcast at DAGScheduler.scala:1006
19/01/24 18:58:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[176] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 18:58:56 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks
19/01/24 18:58:56 WARN TaskSetManager: Stage 128 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:58:56 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:58:56 INFO Executor: Running task 0.0 in stage 128.0 (TID 133)
19/01/24 18:58:56 INFO MemoryStore: Block rdd_173_0 stored as values in memory (estimated size 1865.6 KB, free 362.0 MB)
19/01/24 18:58:56 INFO BlockManagerInfo: Added rdd_173_0 in memory on 127.0.0.1:53848 (size: 1865.6 KB, free: 363.8 MB)
19/01/24 18:58:56 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file C:\Users\yanis\AppData\Local\Temp\blockmgr-a565b49e-a51d-41ee-8340-81f9bb13d90d\2a\temp_shuffle_b0b6685e-d821-456f-a25f-9183c5028318
java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-a565b49e-a51d-41ee-8340-81f9bb13d90d\2a\temp_shuffle_b0b6685e-d821-456f-a25f-9183c5028318 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$revertPartialWritesAndClose$2.apply$mcV$sp(DiskBlockObjectWriter.scala:215)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1346)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:212)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:237)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:102)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
19/01/24 18:58:56 ERROR BypassMergeSortShuffleWriter: Error while deleting file C:\Users\yanis\AppData\Local\Temp\blockmgr-a565b49e-a51d-41ee-8340-81f9bb13d90d\2a\temp_shuffle_b0b6685e-d821-456f-a25f-9183c5028318
19/01/24 18:58:56 ERROR Executor: Exception in task 0.0 in stage 128.0 (TID 133)
java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-a565b49e-a51d-41ee-8340-81f9bb13d90d\2a\temp_shuffle_b0b6685e-d821-456f-a25f-9183c5028318 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
19/01/24 18:58:56 WARN TaskSetManager: Lost task 0.0 in stage 128.0 (TID 133, localhost, executor driver): java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-a565b49e-a51d-41ee-8340-81f9bb13d90d\2a\temp_shuffle_b0b6685e-d821-456f-a25f-9183c5028318 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

19/01/24 18:58:56 ERROR TaskSetManager: Task 0 in stage 128.0 failed 1 times; aborting job
19/01/24 18:58:56 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
19/01/24 18:58:56 INFO TaskSchedulerImpl: Cancelling stage 128
19/01/24 18:58:56 INFO DAGScheduler: ShuffleMapStage 128 (sql at <unknown>:0) failed in 0,100 s due to Job aborted due to stage failure: Task 0 in stage 128.0 failed 1 times, most recent failure: Lost task 0.0 in stage 128.0 (TID 133, localhost, executor driver): java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-a565b49e-a51d-41ee-8340-81f9bb13d90d\2a\temp_shuffle_b0b6685e-d821-456f-a25f-9183c5028318 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
19/01/24 18:58:56 INFO DAGScheduler: Job 121 failed: sql at <unknown>:0, took 0,107548 s
19/01/24 18:58:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews_spark`
19/01/24 18:58:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c86eb16b13
19/01/24 18:58:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c86eb16b13` AS `zzz9`
WHERE (0 = 1)
19/01/24 18:58:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c8403e219b
19/01/24 18:58:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c8403e219b` AS `zzz10`
WHERE (0 = 1)
19/01/24 18:58:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c86eb16b13`
19/01/24 18:58:59 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 18:58:59 INFO DAGScheduler: Registering RDD 185 (flatMap at CountVectorizer.scala:163)
19/01/24 18:58:59 INFO DAGScheduler: Got job 122 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 18:58:59 INFO DAGScheduler: Final stage: ResultStage 131 (count at CountVectorizer.scala:176)
19/01/24 18:58:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 130)
19/01/24 18:58:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 130)
19/01/24 18:58:59 INFO DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[185] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 18:58:59 INFO MemoryStore: Block broadcast_239 stored as values in memory (estimated size 28.5 KB, free 362.0 MB)
19/01/24 18:58:59 INFO MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 13.0 KB, free 362.0 MB)
19/01/24 18:58:59 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 127.0.0.1:53848 (size: 13.0 KB, free: 363.8 MB)
19/01/24 18:58:59 INFO SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:1006
19/01/24 18:58:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[185] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 18:58:59 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks
19/01/24 18:58:59 WARN TaskSetManager: Stage 130 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 18:58:59 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 18:58:59 INFO Executor: Running task 0.0 in stage 130.0 (TID 134)
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3103
19/01/24 18:58:59 INFO BlockManagerInfo: Removed broadcast_235_piece0 on 127.0.0.1:53848 in memory (size: 136.1 KB, free: 364.0 MB)
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3101
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3108
19/01/24 18:58:59 INFO BlockManagerInfo: Removed broadcast_238_piece0 on 127.0.0.1:53848 in memory (size: 7.7 KB, free: 364.0 MB)
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3070
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2961
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2964
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3105
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2959
19/01/24 18:58:59 INFO ContextCleaner: Cleaned shuffle 4
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3097
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2969
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2965
19/01/24 18:58:59 INFO BlockManagerInfo: Removed broadcast_234_piece0 on 127.0.0.1:53848 in memory (size: 136.1 KB, free: 364.1 MB)
19/01/24 18:58:59 INFO ContextCleaner: Cleaned shuffle 3
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2972
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3100
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2973
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3102
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2960
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3107
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2971
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2970
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3109
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2962
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2958
19/01/24 18:58:59 INFO BlockManagerInfo: Removed broadcast_237_piece0 on 127.0.0.1:53848 in memory (size: 3.6 KB, free: 364.1 MB)
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2963
19/01/24 18:58:59 INFO BlockManagerInfo: Removed broadcast_236_piece0 on 127.0.0.1:53848 in memory (size: 136.1 KB, free: 364.2 MB)
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3098
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2968
19/01/24 18:58:59 INFO BlockManagerInfo: Removed broadcast_233_piece0 on 127.0.0.1:53848 in memory (size: 140.5 KB, free: 364.4 MB)
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3104
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2967
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3106
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 3099
19/01/24 18:58:59 INFO ContextCleaner: Cleaned accumulator 2966
19/01/24 18:58:59 INFO BlockManager: Found block rdd_173_0 locally
19/01/24 18:58:59 INFO CodeGenerator: Code generated in 10.165969 ms
19/01/24 18:59:00 ERROR Executor: Exception in task 0.0 in stage 130.0 (TID 134)
java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-a565b49e-a51d-41ee-8340-81f9bb13d90d\19\shuffle_5_0_0.data.221f4ba5-36ea-49c1-896a-351d8ef1886e (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$1.writeNext(WritablePartitionedPairCollection.scala:56)
	at org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:699)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
19/01/24 18:59:00 WARN TaskSetManager: Lost task 0.0 in stage 130.0 (TID 134, localhost, executor driver): java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-a565b49e-a51d-41ee-8340-81f9bb13d90d\19\shuffle_5_0_0.data.221f4ba5-36ea-49c1-896a-351d8ef1886e (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$1.writeNext(WritablePartitionedPairCollection.scala:56)
	at org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:699)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

19/01/24 18:59:00 ERROR TaskSetManager: Task 0 in stage 130.0 failed 1 times; aborting job
19/01/24 18:59:00 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
19/01/24 18:59:00 INFO TaskSchedulerImpl: Cancelling stage 130
19/01/24 18:59:00 INFO DAGScheduler: ShuffleMapStage 130 (flatMap at CountVectorizer.scala:163) failed in 0,310 s due to Job aborted due to stage failure: Task 0 in stage 130.0 failed 1 times, most recent failure: Lost task 0.0 in stage 130.0 (TID 134, localhost, executor driver): java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-a565b49e-a51d-41ee-8340-81f9bb13d90d\19\shuffle_5_0_0.data.221f4ba5-36ea-49c1-896a-351d8ef1886e (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$1.writeNext(WritablePartitionedPairCollection.scala:56)
	at org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:699)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
19/01/24 18:59:00 INFO DAGScheduler: Job 122 failed: count at CountVectorizer.scala:176, took 0,317452 s
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 114
19/01/24 19:04:04 INFO ContextCleaner: Cleaned shuffle 1
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 3138
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 3137
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 3139
19/01/24 19:04:04 INFO ContextCleaner: Cleaned shuffle 5
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 3134
19/01/24 19:04:04 INFO BlockManagerInfo: Removed broadcast_239_piece0 on 127.0.0.1:53848 in memory (size: 13.0 KB, free: 364.4 MB)
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 3135
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 3136
19/01/24 19:04:04 INFO BlockManager: Removing RDD 188
19/01/24 19:04:04 INFO ContextCleaner: Cleaned RDD 188
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 254
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 122
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 123
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 257
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 256
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 115
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 119
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 252
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 261
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 262
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 255
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 251
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 260
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 121
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 118
19/01/24 19:04:04 INFO BlockManager: Removing RDD 40
19/01/24 19:04:04 INFO ContextCleaner: Cleaned RDD 40
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 253
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 258
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 124
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 116
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 259
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 113
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 117
19/01/24 19:04:04 INFO ContextCleaner: Cleaned accumulator 120
19/01/24 19:04:51 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 19:04:51 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 19:04:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 19:04:51 INFO MemoryStore: MemoryStore cleared
19/01/24 19:04:51 INFO BlockManager: BlockManager stopped
19/01/24 19:04:51 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 19:04:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 19:04:51 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-5e400486-05ed-4d2c-ae8f-797e6148d030\userFiles-c1b5d933-f8a4-429a-a21b-d9c791d0b3e8
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-5e400486-05ed-4d2c-ae8f-797e6148d030\userFiles-c1b5d933-f8a4-429a-a21b-d9c791d0b3e8
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 19:04:51 INFO SparkContext: Successfully stopped SparkContext
19/01/24 19:04:51 INFO ShutdownHookManager: Shutdown hook called
19/01/24 19:04:51 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-5e400486-05ed-4d2c-ae8f-797e6148d030
19/01/24 19:04:51 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-5e400486-05ed-4d2c-ae8f-797e6148d030
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-5e400486-05ed-4d2c-ae8f-797e6148d030
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 19:04:51 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-5e400486-05ed-4d2c-ae8f-797e6148d030\userFiles-c1b5d933-f8a4-429a-a21b-d9c791d0b3e8
19/01/24 19:04:51 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-5e400486-05ed-4d2c-ae8f-797e6148d030\userFiles-c1b5d933-f8a4-429a-a21b-d9c791d0b3e8
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-5e400486-05ed-4d2c-ae8f-797e6148d030\userFiles-c1b5d933-f8a4-429a-a21b-d9c791d0b3e8
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 19:05:08 INFO SparkContext: Running Spark version 2.2.0
19/01/24 19:05:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 19:05:08 INFO SparkContext: Submitted application: sparklyr
19/01/24 19:05:08 INFO SecurityManager: Changing view acls to: yanis
19/01/24 19:05:08 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 19:05:08 INFO SecurityManager: Changing view acls groups to: 
19/01/24 19:05:08 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 19:05:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 19:05:08 INFO Utils: Successfully started service 'sparkDriver' on port 54156.
19/01/24 19:05:08 INFO SparkEnv: Registering MapOutputTracker
19/01/24 19:05:08 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 19:05:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 19:05:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 19:05:08 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-2c8bf22f-de95-4eb4-bca0-7f86b143d347
19/01/24 19:05:08 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 19:05:08 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 19:05:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 19:05:08 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 19:05:08 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:54156/jars/sparklyr-2.2-2.11.jar with timestamp 1548353108987
19/01/24 19:05:09 INFO Executor: Starting executor ID driver on host localhost
19/01/24 19:05:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54197.
19/01/24 19:05:09 INFO NettyBlockTransferService: Server created on 127.0.0.1:54197
19/01/24 19:05:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 19:05:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54197, None)
19/01/24 19:05:09 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54197 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 54197, None)
19/01/24 19:05:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54197, None)
19/01/24 19:05:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54197, None)
19/01/24 19:05:09 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 19:05:09 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 19:05:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 19:05:09 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 19:05:09 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 19:05:10 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 19:05:10 INFO ObjectStore: ObjectStore, initialize called
19/01/24 19:05:10 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 19:05:10 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 19:05:11 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 19:05:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 19:05:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 19:05:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 19:05:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 19:05:12 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 19:05:12 INFO ObjectStore: Initialized ObjectStore
19/01/24 19:05:12 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 19:05:13 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 19:05:13 INFO HiveMetaStore: Added admin role in metastore
19/01/24 19:05:13 INFO HiveMetaStore: Added public role in metastore
19/01/24 19:05:13 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 19:05:13 INFO HiveMetaStore: 0: get_all_databases
19/01/24 19:05:13 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 19:05:13 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 19:05:13 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 19:05:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 19:05:13 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/b64a903a-607d-4c94-bacb-a95280d715f9_resources
19/01/24 19:05:13 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/b64a903a-607d-4c94-bacb-a95280d715f9
19/01/24 19:05:13 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/b64a903a-607d-4c94-bacb-a95280d715f9
19/01/24 19:05:13 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/b64a903a-607d-4c94-bacb-a95280d715f9/_tmp_space.db
19/01/24 19:05:13 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 19:05:13 INFO HiveMetaStore: 0: get_database: default
19/01/24 19:05:13 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 19:05:13 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 19:05:13 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 19:05:13 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 19:05:13 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/e8fbdfad-031b-4cf7-964a-52ba0f967a07_resources
19/01/24 19:05:13 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/e8fbdfad-031b-4cf7-964a-52ba0f967a07
19/01/24 19:05:13 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/e8fbdfad-031b-4cf7-964a-52ba0f967a07
19/01/24 19:05:13 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/e8fbdfad-031b-4cf7-964a-52ba0f967a07/_tmp_space.db
19/01/24 19:05:13 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 19:05:13 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 19:05:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 19:05:15 INFO HiveMetaStore: 0: get_database: default
19/01/24 19:05:15 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 19:05:15 INFO HiveMetaStore: 0: get_database: default
19/01/24 19:05:15 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 19:05:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 19:05:15 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 19:05:15 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 19:05:15 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 19:05:15 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 19:05:15 INFO DAGScheduler: Parents of final stage: List()
19/01/24 19:05:15 INFO DAGScheduler: Missing parents: List()
19/01/24 19:05:15 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 19:05:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 19:05:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 19:05:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:54197 (size: 3.4 KB, free: 366.3 MB)
19/01/24 19:05:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 19:05:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 19:05:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 19:05:15 INFO Executor: Fetching spark://127.0.0.1:54156/jars/sparklyr-2.2-2.11.jar with timestamp 1548353108987
19/01/24 19:05:16 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54156 after 14 ms (0 ms spent in bootstraps)
19/01/24 19:05:16 INFO Utils: Fetching spark://127.0.0.1:54156/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-dea9d28e-1864-424c-bcd0-0db3a95558e3\userFiles-fa29ecbf-5ef7-4c97-914d-66a7f2756501\fetchFileTemp452192133814030478.tmp
19/01/24 19:05:16 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-dea9d28e-1864-424c-bcd0-0db3a95558e3/userFiles-fa29ecbf-5ef7-4c97-914d-66a7f2756501/sparklyr-2.2-2.11.jar to class loader
19/01/24 19:05:16 INFO CodeGenerator: Code generated in 279.10085 ms
19/01/24 19:05:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/01/24 19:05:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 676 ms on localhost (executor driver) (1/1)
19/01/24 19:05:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 19:05:16 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,699 s
19/01/24 19:05:16 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,857904 s
19/01/24 19:05:17 INFO SparkSqlParser: Parsing command: reviews
19/01/24 19:05:17 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 19:05:17 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 19:05:17 INFO CodeGenerator: Code generated in 14.120476 ms
19/01/24 19:05:17 INFO CodeGenerator: Code generated in 8.138027 ms
19/01/24 19:05:17 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 19:05:17 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 19:05:17 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 19:05:17 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 19:05:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 19:05:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 19:05:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 19:05:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 19:05:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 19:05:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:54197 (size: 7.7 KB, free: 366.3 MB)
19/01/24 19:05:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 19:05:17 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 19:05:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 19:05:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 19:05:17 INFO CodeGenerator: Code generated in 8.581833 ms
19/01/24 19:05:17 INFO CodeGenerator: Code generated in 28.655585 ms
19/01/24 19:05:17 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.4 MB)
19/01/24 19:05:17 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:54197 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 19:05:17 INFO CodeGenerator: Code generated in 4.574449 ms
19/01/24 19:05:17 INFO CodeGenerator: Code generated in 17.866026 ms
19/01/24 19:05:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 19:05:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 397 ms on localhost (executor driver) (1/1)
19/01/24 19:05:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 19:05:17 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,399 s
19/01/24 19:05:17 INFO DAGScheduler: looking for newly runnable stages
19/01/24 19:05:17 INFO DAGScheduler: running: Set()
19/01/24 19:05:17 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 19:05:17 INFO DAGScheduler: failed: Set()
19/01/24 19:05:17 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 19:05:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 19:05:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 19:05:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:54197 (size: 3.7 KB, free: 364.5 MB)
19/01/24 19:05:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 19:05:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 19:05:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 19:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 19:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/01/24 19:05:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1538 bytes result sent to driver
19/01/24 19:05:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (executor driver) (1/1)
19/01/24 19:05:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 19:05:17 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,031 s
19/01/24 19:05:17 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,473684 s
19/01/24 19:05:17 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 19:05:18 INFO HiveMetaStore: 0: get_database: default
19/01/24 19:05:18 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 19:05:18 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:54197 in memory (size: 3.4 KB, free: 364.5 MB)
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 19:05:18 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 19:05:18 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:54197 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 19:05:18 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:54197 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 19:05:18 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 19:05:18 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 19:05:18 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 19:05:18 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 19:05:18 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 19:05:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 19:05:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 19:05:18 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 19:05:18 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 19:05:18 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.5 MB)
19/01/24 19:05:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:54197 (size: 7.7 KB, free: 364.5 MB)
19/01/24 19:05:18 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:18 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 19:05:18 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 19:05:18 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 19:05:18 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 19:05:18 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 19:05:18 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1647 bytes result sent to driver
19/01/24 19:05:18 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 35 ms on localhost (executor driver) (1/1)
19/01/24 19:05:18 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 19:05:18 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,036 s
19/01/24 19:05:18 INFO DAGScheduler: looking for newly runnable stages
19/01/24 19:05:18 INFO DAGScheduler: running: Set()
19/01/24 19:05:18 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 19:05:18 INFO DAGScheduler: failed: Set()
19/01/24 19:05:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 19:05:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 19:05:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 19:05:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:54197 (size: 3.7 KB, free: 364.5 MB)
19/01/24 19:05:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:18 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 19:05:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 19:05:18 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 19:05:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 19:05:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 19:05:18 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/01/24 19:05:18 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 4 ms on localhost (executor driver) (1/1)
19/01/24 19:05:18 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 19:05:18 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,005 s
19/01/24 19:05:18 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,056797 s
19/01/24 19:05:18 INFO CodeGenerator: Code generated in 5.242529 ms
19/01/24 19:05:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz11`
WHERE (0 = 1)
19/01/24 19:05:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 19:05:25 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c8a8a7a37
19/01/24 19:05:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c8a8a7a37` AS `zzz12`
WHERE (0 = 1)
19/01/24 19:05:25 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c8600c55fe
19/01/24 19:05:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c8600c55fe` AS `zzz13`
WHERE (0 = 1)
19/01/24 19:05:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c8a8a7a37`
19/01/24 19:05:25 INFO CodeGenerator: Code generated in 29.872496 ms
19/01/24 19:05:26 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 19:05:26 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 19:05:26 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 19:05:26 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 19:05:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 19:05:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 19:05:26 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 19:05:26 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 19:05:26 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 19:05:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:54197 (size: 13.0 KB, free: 364.5 MB)
19/01/24 19:05:26 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:26 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 19:05:26 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 19:05:26 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 19:05:26 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 19:05:26 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 19:05:26 INFO CodeGenerator: Code generated in 16.379621 ms
19/01/24 19:05:26 INFO CodeGenerator: Code generated in 12.743109 ms
19/01/24 19:05:26 INFO CodeGenerator: Code generated in 8.345526 ms
19/01/24 19:05:26 INFO CodeGenerator: Code generated in 33.929111 ms
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 124
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 122
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 115
19/01/24 19:05:26 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:54197 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 117
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 113
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 121
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 118
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 116
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 120
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 119
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 114
19/01/24 19:05:26 INFO ContextCleaner: Cleaned shuffle 1
19/01/24 19:05:26 INFO ContextCleaner: Cleaned accumulator 123
19/01/24 19:05:26 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:54197 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 19:05:27 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1994 bytes result sent to driver
19/01/24 19:05:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1010 ms on localhost (executor driver) (1/1)
19/01/24 19:05:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 19:05:27 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 1,011 s
19/01/24 19:05:27 INFO DAGScheduler: looking for newly runnable stages
19/01/24 19:05:27 INFO DAGScheduler: running: Set()
19/01/24 19:05:27 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 19:05:27 INFO DAGScheduler: failed: Set()
19/01/24 19:05:27 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 19:05:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 19:05:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 19:05:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:54197 (size: 1887.0 B, free: 364.5 MB)
19/01/24 19:05:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:27 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 19:05:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 19:05:27 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 19:05:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 19:05:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 19:05:27 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 19:05:27 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:54197 (size: 686.3 KB, free: 363.8 MB)
19/01/24 19:05:27 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1830 bytes result sent to driver
19/01/24 19:05:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 152 ms on localhost (executor driver) (1/1)
19/01/24 19:05:27 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 19:05:27 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,153 s
19/01/24 19:05:27 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 1,210852 s
19/01/24 19:05:27 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 19:05:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 19:05:27 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 19:05:27 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 19:05:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 19:05:27 INFO DAGScheduler: Missing parents: List()
19/01/24 19:05:27 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 19:05:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.8 MB)
19/01/24 19:05:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.8 MB)
19/01/24 19:05:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:54197 (size: 2.2 KB, free: 363.8 MB)
19/01/24 19:05:27 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:27 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 19:05:27 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 19:05:27 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 19:05:27 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 19:05:27 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 19:05:27 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 59 ms on localhost (executor driver) (1/1)
19/01/24 19:05:27 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 19:05:27 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,060 s
19/01/24 19:05:27 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,077062 s
19/01/24 19:05:27 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 19:05:27 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.6 MB)
19/01/24 19:05:27 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:54197 (size: 89.8 KB, free: 363.7 MB)
19/01/24 19:05:27 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 19:05:27 INFO CodeGenerator: Code generated in 59.841995 ms
19/01/24 19:05:27 INFO Instrumentation: NaiveBayes-naive_bayes_4c870eb92e-669399754-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 19:05:27 INFO Instrumentation: NaiveBayes-naive_bayes_4c870eb92e-669399754-1: {"smoothing":1.0,"featuresCol":"vectorizer_output","modelType":"multinomial","labelCol":"Sentiment","predictionCol":"prediction","rawPredictionCol":"rawPrediction","probabilityCol":"probability"}
19/01/24 19:05:27 INFO CodeGenerator: Code generated in 38.168426 ms
19/01/24 19:05:27 INFO SparkContext: Starting job: head at NaiveBayes.scala:154
19/01/24 19:05:27 INFO DAGScheduler: Got job 5 (head at NaiveBayes.scala:154) with 1 output partitions
19/01/24 19:05:27 INFO DAGScheduler: Final stage: ResultStage 9 (head at NaiveBayes.scala:154)
19/01/24 19:05:27 INFO DAGScheduler: Parents of final stage: List()
19/01/24 19:05:27 INFO DAGScheduler: Missing parents: List()
19/01/24 19:05:27 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154), which has no missing parents
19/01/24 19:05:27 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 113.1 KB, free 362.4 MB)
19/01/24 19:05:27 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 72.9 KB, free 362.4 MB)
19/01/24 19:05:27 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:54197 (size: 72.9 KB, free: 363.6 MB)
19/01/24 19:05:27 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:27 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 19:05:27 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 19:05:27 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 19:05:27 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 19:05:27 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 19:05:27 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 1743 bytes result sent to driver
19/01/24 19:05:27 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 104 ms on localhost (executor driver) (1/1)
19/01/24 19:05:27 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 19:05:27 INFO DAGScheduler: ResultStage 9 (head at NaiveBayes.scala:154) finished in 0,106 s
19/01/24 19:05:27 INFO DAGScheduler: Job 5 finished: head at NaiveBayes.scala:154, took 0,126390 s
19/01/24 19:05:28 INFO CodeGenerator: Code generated in 7.326267 ms
19/01/24 19:05:28 INFO Instrumentation: NaiveBayes-naive_bayes_4c870eb92e-669399754-1: {"numFeatures":8098}
19/01/24 19:05:28 INFO CodeGenerator: Code generated in 52.235296 ms
19/01/24 19:05:28 INFO ContextCleaner: Cleaned accumulator 257
19/01/24 19:05:28 INFO ContextCleaner: Cleaned accumulator 259
19/01/24 19:05:28 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:54197 in memory (size: 1887.0 B, free: 363.6 MB)
19/01/24 19:05:28 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:54197 in memory (size: 72.9 KB, free: 363.7 MB)
19/01/24 19:05:28 INFO ContextCleaner: Cleaned accumulator 258
19/01/24 19:05:28 INFO ContextCleaner: Cleaned accumulator 260
19/01/24 19:05:28 INFO SparkContext: Starting job: collect at NaiveBayes.scala:174
19/01/24 19:05:28 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:54197 in memory (size: 2.2 KB, free: 363.7 MB)
19/01/24 19:05:28 INFO DAGScheduler: Registering RDD 43 (map at NaiveBayes.scala:162)
19/01/24 19:05:28 INFO DAGScheduler: Got job 6 (collect at NaiveBayes.scala:174) with 1 output partitions
19/01/24 19:05:28 INFO DAGScheduler: Final stage: ResultStage 11 (collect at NaiveBayes.scala:174)
19/01/24 19:05:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/01/24 19:05:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/01/24 19:05:28 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162), which has no missing parents
19/01/24 19:05:28 INFO ContextCleaner: Cleaned accumulator 262
19/01/24 19:05:28 INFO ContextCleaner: Cleaned accumulator 261
19/01/24 19:05:28 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 243.7 KB, free 362.3 MB)
19/01/24 19:05:28 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 76.0 KB, free 362.3 MB)
19/01/24 19:05:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:54197 (size: 76.0 KB, free: 363.6 MB)
19/01/24 19:05:28 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:28 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 19:05:28 WARN TaskSetManager: Stage 10 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 19:05:28 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 19:05:28 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 19:05:28 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 19:05:28 INFO CodeGenerator: Code generated in 8.6792 ms
19/01/24 19:05:28 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1908 bytes result sent to driver
19/01/24 19:05:28 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 507 ms on localhost (executor driver) (1/1)
19/01/24 19:05:28 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 19:05:28 INFO DAGScheduler: ShuffleMapStage 10 (map at NaiveBayes.scala:162) finished in 0,508 s
19/01/24 19:05:28 INFO DAGScheduler: looking for newly runnable stages
19/01/24 19:05:28 INFO DAGScheduler: running: Set()
19/01/24 19:05:28 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/01/24 19:05:28 INFO DAGScheduler: failed: Set()
19/01/24 19:05:28 INFO DAGScheduler: Submitting ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163), which has no missing parents
19/01/24 19:05:28 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 244.4 KB, free 362.0 MB)
19/01/24 19:05:28 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 76.4 KB, free 361.9 MB)
19/01/24 19:05:28 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:54197 (size: 76.4 KB, free: 363.6 MB)
19/01/24 19:05:28 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/01/24 19:05:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 19:05:28 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 19:05:28 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 19:05:28 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 19:05:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 19:05:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 19:05:28 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 132363 bytes result sent to driver
19/01/24 19:05:28 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 17 ms on localhost (executor driver) (1/1)
19/01/24 19:05:28 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 19:05:28 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:54197 in memory (size: 76.0 KB, free: 363.6 MB)
19/01/24 19:05:28 INFO DAGScheduler: ResultStage 11 (collect at NaiveBayes.scala:174) finished in 0,018 s
19/01/24 19:05:28 INFO DAGScheduler: Job 6 finished: collect at NaiveBayes.scala:174, took 0,556055 s
19/01/24 19:05:28 INFO Instrumentation: NaiveBayes-naive_bayes_4c870eb92e-669399754-1: {"numClasses":2}
19/01/24 19:05:28 INFO Instrumentation: NaiveBayes-naive_bayes_4c870eb92e-669399754-1: training finished
19/01/24 19:06:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c8600c55fe`
19/01/24 19:06:07 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4c85f1b1792
19/01/24 19:06:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c85f1b1792` AS `zzz14`
WHERE (0 = 1)
19/01/24 19:06:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4c8a8a7a37`
19/01/24 19:06:07 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 19:06:07 INFO DAGScheduler: Registering RDD 50 (flatMap at CountVectorizer.scala:163)
19/01/24 19:06:07 INFO DAGScheduler: Got job 7 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 19:06:07 INFO DAGScheduler: Final stage: ResultStage 13 (count at CountVectorizer.scala:176)
19/01/24 19:06:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/01/24 19:06:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/01/24 19:06:07 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[50] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 19:06:07 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 28.5 KB, free 362.2 MB)
19/01/24 19:06:07 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KB, free 362.2 MB)
19/01/24 19:06:07 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:54197 (size: 13.0 KB, free: 363.6 MB)
19/01/24 19:06:07 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 19:06:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[50] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 19:06:07 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 19:06:07 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 19:06:07 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 19:06:07 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 19:06:07 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 19:06:07 INFO CodeGenerator: Code generated in 16.566698 ms
19/01/24 19:06:07 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 1865 bytes result sent to driver
19/01/24 19:06:07 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 404 ms on localhost (executor driver) (1/1)
19/01/24 19:06:07 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 19:06:07 INFO DAGScheduler: ShuffleMapStage 12 (flatMap at CountVectorizer.scala:163) finished in 0,404 s
19/01/24 19:06:07 INFO DAGScheduler: looking for newly runnable stages
19/01/24 19:06:07 INFO DAGScheduler: running: Set()
19/01/24 19:06:07 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/01/24 19:06:07 INFO DAGScheduler: failed: Set()
19/01/24 19:06:07 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[53] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 19:06:07 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.2 KB, free 362.2 MB)
19/01/24 19:06:07 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 1887.0 B, free 362.2 MB)
19/01/24 19:06:07 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:54197 (size: 1887.0 B, free: 363.6 MB)
19/01/24 19:06:07 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/01/24 19:06:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[53] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 19:06:07 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 19:06:07 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 19:06:07 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 19:06:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 19:06:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 289
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 254
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 287
19/01/24 19:06:07 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:54197 in memory (size: 13.0 KB, free: 363.6 MB)
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 256
19/01/24 19:06:07 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:54197 in memory (size: 76.4 KB, free: 363.7 MB)
19/01/24 19:06:07 INFO ContextCleaner: Cleaned shuffle 3
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 253
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 288
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 252
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 290
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 255
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 291
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 292
19/01/24 19:06:07 INFO ContextCleaner: Cleaned accumulator 251
19/01/24 19:06:08 INFO MemoryStore: Block rdd_53_0 stored as values in memory (estimated size 686.3 KB, free 361.9 MB)
19/01/24 19:06:08 INFO BlockManagerInfo: Added rdd_53_0 in memory on 127.0.0.1:54197 (size: 686.3 KB, free: 363.0 MB)
19/01/24 19:06:08 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 1830 bytes result sent to driver
19/01/24 19:06:08 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 112 ms on localhost (executor driver) (1/1)
19/01/24 19:06:08 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 19:06:08 INFO DAGScheduler: ResultStage 13 (count at CountVectorizer.scala:176) finished in 0,113 s
19/01/24 19:06:08 INFO DAGScheduler: Job 7 finished: count at CountVectorizer.scala:176, took 0,533627 s
19/01/24 19:06:08 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 19:06:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 143 bytes
19/01/24 19:06:08 INFO DAGScheduler: Got job 8 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 19:06:08 INFO DAGScheduler: Final stage: ResultStage 15 (top at CountVectorizer.scala:179)
19/01/24 19:06:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/01/24 19:06:08 INFO DAGScheduler: Missing parents: List()
19/01/24 19:06:08 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 4.2 KB, free 361.9 MB)
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.2 KB, free 361.9 MB)
19/01/24 19:06:08 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:54197 (size: 2.2 KB, free: 363.0 MB)
19/01/24 19:06:08 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 19:06:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 19:06:08 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/01/24 19:06:08 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 19:06:08 INFO Executor: Running task 0.0 in stage 15.0 (TID 13)
19/01/24 19:06:08 INFO BlockManager: Found block rdd_53_0 locally
19/01/24 19:06:08 INFO Executor: Finished task 0.0 in stage 15.0 (TID 13). 174434 bytes result sent to driver
19/01/24 19:06:08 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 13) in 18 ms on localhost (executor driver) (1/1)
19/01/24 19:06:08 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 19:06:08 INFO DAGScheduler: ResultStage 15 (top at CountVectorizer.scala:179) finished in 0,018 s
19/01/24 19:06:08 INFO DAGScheduler: Job 8 finished: top at CountVectorizer.scala:179, took 0,023520 s
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 1137.7 KB, free 360.8 MB)
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 89.8 KB, free 360.7 MB)
19/01/24 19:06:08 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:54197 (size: 89.8 KB, free: 362.9 MB)
19/01/24 19:06:08 INFO SparkContext: Created broadcast 15 from broadcast at CountVectorizer.scala:244
19/01/24 19:06:08 INFO CodeGenerator: Code generated in 12.117696 ms
19/01/24 19:06:08 INFO CodeGenerator: Code generated in 17.639199 ms
19/01/24 19:06:08 INFO SparkContext: Starting job: take at Classifier.scala:111
19/01/24 19:06:08 INFO DAGScheduler: Registering RDD 57 (take at Classifier.scala:111)
19/01/24 19:06:08 INFO DAGScheduler: Got job 9 (take at Classifier.scala:111) with 1 output partitions
19/01/24 19:06:08 INFO DAGScheduler: Final stage: ResultStage 17 (take at Classifier.scala:111)
19/01/24 19:06:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
19/01/24 19:06:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
19/01/24 19:06:08 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[57] at take at Classifier.scala:111), which has no missing parents
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 25.0 KB, free 360.7 MB)
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 11.3 KB, free 360.7 MB)
19/01/24 19:06:08 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:54197 (size: 11.3 KB, free: 362.9 MB)
19/01/24 19:06:08 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/01/24 19:06:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[57] at take at Classifier.scala:111) (first 15 tasks are for partitions Vector(0))
19/01/24 19:06:08 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/01/24 19:06:08 WARN TaskSetManager: Stage 16 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 19:06:08 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 19:06:08 INFO Executor: Running task 0.0 in stage 16.0 (TID 14)
19/01/24 19:06:08 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 19:06:08 INFO Executor: Finished task 0.0 in stage 16.0 (TID 14). 2256 bytes result sent to driver
19/01/24 19:06:08 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 14) in 82 ms on localhost (executor driver) (1/1)
19/01/24 19:06:08 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/01/24 19:06:08 INFO DAGScheduler: ShuffleMapStage 16 (take at Classifier.scala:111) finished in 0,082 s
19/01/24 19:06:08 INFO DAGScheduler: looking for newly runnable stages
19/01/24 19:06:08 INFO DAGScheduler: running: Set()
19/01/24 19:06:08 INFO DAGScheduler: waiting: Set(ResultStage 17)
19/01/24 19:06:08 INFO DAGScheduler: failed: Set()
19/01/24 19:06:08 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[60] at take at Classifier.scala:111), which has no missing parents
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.2 KB, free 360.6 MB)
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.9 KB, free 360.6 MB)
19/01/24 19:06:08 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:54197 (size: 3.9 KB, free: 362.9 MB)
19/01/24 19:06:08 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/01/24 19:06:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[60] at take at Classifier.scala:111) (first 15 tasks are for partitions Vector(0))
19/01/24 19:06:08 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/01/24 19:06:08 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 19:06:08 INFO Executor: Running task 0.0 in stage 17.0 (TID 15)
19/01/24 19:06:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 19:06:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 19:06:08 INFO Executor: Finished task 0.0 in stage 17.0 (TID 15). 1465 bytes result sent to driver
19/01/24 19:06:08 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 15) in 6 ms on localhost (executor driver) (1/1)
19/01/24 19:06:08 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 19:06:08 INFO DAGScheduler: ResultStage 17 (take at Classifier.scala:111) finished in 0,006 s
19/01/24 19:06:08 INFO DAGScheduler: Job 9 finished: take at Classifier.scala:111, took 0,103030 s
19/01/24 19:06:08 INFO CodeGenerator: Code generated in 6.028397 ms
19/01/24 19:06:08 INFO RandomForestClassifier: org.apache.spark.ml.classification.RandomForestClassifier inferred 2 classes for labelCol=random_forest_classifier_4c85f52130b__labelCol since numClasses was not specified in the column metadata.
19/01/24 19:06:08 INFO CodeGenerator: Code generated in 21.620326 ms
19/01/24 19:06:08 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_4c85f52130b-829774443-2: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 19:06:08 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_4c85f52130b-829774443-2: {"subsamplingRate":1.0,"impurity":"gini","featuresCol":"vectorizer_output","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"Sentiment","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"rawPredictionCol":"rawPrediction","probabilityCol":"probability","numTrees":20}
19/01/24 19:06:08 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:112
19/01/24 19:06:08 INFO DAGScheduler: Got job 10 (take at DecisionTreeMetadata.scala:112) with 1 output partitions
19/01/24 19:06:08 INFO DAGScheduler: Final stage: ResultStage 18 (take at DecisionTreeMetadata.scala:112)
19/01/24 19:06:08 INFO DAGScheduler: Parents of final stage: List()
19/01/24 19:06:08 INFO DAGScheduler: Missing parents: List()
19/01/24 19:06:08 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[67] at map at DecisionTreeMetadata.scala:112), which has no missing parents
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 115.2 KB, free 360.5 MB)
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 74.3 KB, free 360.5 MB)
19/01/24 19:06:08 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:54197 (size: 74.3 KB, free: 362.9 MB)
19/01/24 19:06:08 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/01/24 19:06:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[67] at map at DecisionTreeMetadata.scala:112) (first 15 tasks are for partitions Vector(0))
19/01/24 19:06:08 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/01/24 19:06:08 WARN TaskSetManager: Stage 18 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 19:06:08 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 19:06:08 INFO Executor: Running task 0.0 in stage 18.0 (TID 16)
19/01/24 19:06:08 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 19:06:08 INFO CodeGenerator: Code generated in 11.856956 ms
19/01/24 19:06:08 INFO Executor: Finished task 0.0 in stage 18.0 (TID 16). 1625 bytes result sent to driver
19/01/24 19:06:08 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 16) in 86 ms on localhost (executor driver) (1/1)
19/01/24 19:06:08 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/01/24 19:06:08 INFO DAGScheduler: ResultStage 18 (take at DecisionTreeMetadata.scala:112) finished in 0,087 s
19/01/24 19:06:08 INFO DAGScheduler: Job 10 finished: take at DecisionTreeMetadata.scala:112, took 0,099709 s
19/01/24 19:06:08 INFO SparkContext: Starting job: count at DecisionTreeMetadata.scala:118
19/01/24 19:06:08 INFO DAGScheduler: Got job 11 (count at DecisionTreeMetadata.scala:118) with 1 output partitions
19/01/24 19:06:08 INFO DAGScheduler: Final stage: ResultStage 19 (count at DecisionTreeMetadata.scala:118)
19/01/24 19:06:08 INFO DAGScheduler: Parents of final stage: List()
19/01/24 19:06:08 INFO DAGScheduler: Missing parents: List()
19/01/24 19:06:08 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[66] at retag at RandomForest.scala:103), which has no missing parents
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 114.8 KB, free 360.3 MB)
19/01/24 19:06:08 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 74.1 KB, free 360.3 MB)
19/01/24 19:06:08 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:54197 (size: 74.1 KB, free: 362.8 MB)
19/01/24 19:06:08 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/01/24 19:06:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[66] at retag at RandomForest.scala:103) (first 15 tasks are for partitions Vector(0))
19/01/24 19:06:08 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/01/24 19:06:08 WARN TaskSetManager: Stage 19 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 19:06:08 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 19:06:08 INFO Executor: Running task 0.0 in stage 19.0 (TID 17)
19/01/24 19:06:08 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 19:06:08 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:54197 in memory (size: 3.9 KB, free: 362.8 MB)
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 426
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 430
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 344
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 431
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 434
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 429
19/01/24 19:06:08 INFO BlockManager: Removing RDD 53
19/01/24 19:06:08 INFO ContextCleaner: Cleaned RDD 53
19/01/24 19:06:08 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:54197 in memory (size: 2.2 KB, free: 363.5 MB)
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 343
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 425
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 424
19/01/24 19:06:08 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:54197 in memory (size: 74.3 KB, free: 363.5 MB)
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 435
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 428
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 433
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 422
19/01/24 19:06:08 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:54197 in memory (size: 1887.0 B, free: 363.5 MB)
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 419
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 427
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 420
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 421
19/01/24 19:06:08 INFO ContextCleaner: Cleaned shuffle 5
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 341
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 423
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 346
19/01/24 19:06:08 INFO ContextCleaner: Cleaned shuffle 4
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 342
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 345
19/01/24 19:06:08 INFO ContextCleaner: Cleaned accumulator 432
19/01/24 19:06:08 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:54197 in memory (size: 11.3 KB, free: 363.5 MB)
19/01/24 19:06:09 INFO Executor: Finished task 0.0 in stage 19.0 (TID 17). 1719 bytes result sent to driver
19/01/24 19:06:09 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 17) in 510 ms on localhost (executor driver) (1/1)
19/01/24 19:06:09 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/01/24 19:06:09 INFO DAGScheduler: ResultStage 19 (count at DecisionTreeMetadata.scala:118) finished in 0,511 s
19/01/24 19:06:09 INFO DAGScheduler: Job 11 finished: count at DecisionTreeMetadata.scala:118, took 0,525569 s
19/01/24 19:06:09 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_4c85f52130b-829774443-2: {"numFeatures":8098}
19/01/24 19:06:09 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_4c85f52130b-829774443-2: {"numClasses":2}
19/01/24 19:06:09 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:928
19/01/24 19:06:09 INFO DAGScheduler: Registering RDD 69 (flatMap at RandomForest.scala:921)
19/01/24 19:06:09 INFO DAGScheduler: Got job 12 (collectAsMap at RandomForest.scala:928) with 1 output partitions
19/01/24 19:06:09 INFO DAGScheduler: Final stage: ResultStage 21 (collectAsMap at RandomForest.scala:928)
19/01/24 19:06:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/01/24 19:06:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/01/24 19:06:09 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[69] at flatMap at RandomForest.scala:921), which has no missing parents
19/01/24 19:06:09 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 199.7 KB, free 361.0 MB)
19/01/24 19:06:09 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 108.1 KB, free 360.9 MB)
19/01/24 19:06:09 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:54197 (size: 108.1 KB, free: 363.4 MB)
19/01/24 19:06:09 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/01/24 19:06:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[69] at flatMap at RandomForest.scala:921) (first 15 tasks are for partitions Vector(0))
19/01/24 19:06:09 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/01/24 19:06:09 WARN TaskSetManager: Stage 20 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 19:06:09 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914234 bytes)
19/01/24 19:06:09 INFO Executor: Running task 0.0 in stage 20.0 (TID 18)
19/01/24 19:06:09 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 19:06:10 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:54197 in memory (size: 74.1 KB, free: 363.5 MB)
19/01/24 19:06:26 INFO Executor: Finished task 0.0 in stage 20.0 (TID 18). 1865 bytes result sent to driver
19/01/24 19:06:26 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 18) in 17243 ms on localhost (executor driver) (1/1)
19/01/24 19:06:26 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/01/24 19:06:26 INFO DAGScheduler: ShuffleMapStage 20 (flatMap at RandomForest.scala:921) finished in 17,245 s
19/01/24 19:06:26 INFO DAGScheduler: looking for newly runnable stages
19/01/24 19:06:26 INFO DAGScheduler: running: Set()
19/01/24 19:06:26 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/01/24 19:06:26 INFO DAGScheduler: failed: Set()
19/01/24 19:06:26 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[71] at map at RandomForest.scala:923), which has no missing parents
19/01/24 19:06:26 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 233.7 KB, free 360.8 MB)
19/01/24 19:06:26 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 109.7 KB, free 360.7 MB)
19/01/24 19:06:26 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:54197 (size: 109.7 KB, free: 363.4 MB)
19/01/24 19:06:26 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/01/24 19:06:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[71] at map at RandomForest.scala:923) (first 15 tasks are for partitions Vector(0))
19/01/24 19:06:26 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/01/24 19:06:26 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 19, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 19:06:26 INFO Executor: Running task 0.0 in stage 21.0 (TID 19)
19/01/24 19:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 19:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 19:06:26 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:54197 in memory (size: 13.0 KB, free: 363.4 MB)
19/01/24 19:06:26 INFO ContextCleaner: Cleaned accumulator 177
19/01/24 19:06:26 INFO ContextCleaner: Cleaned accumulator 178
19/01/24 19:06:26 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:54197 in memory (size: 108.1 KB, free: 363.5 MB)
19/01/24 19:06:26 INFO BlockManager: Removing RDD 30
19/01/24 19:06:26 INFO ContextCleaner: Cleaned RDD 30
19/01/24 19:06:26 INFO ContextCleaner: Cleaned accumulator 176
19/01/24 19:06:26 INFO ContextCleaner: Cleaned accumulator 174
19/01/24 19:06:26 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 19:06:26 INFO ContextCleaner: Cleaned accumulator 175
19/01/24 19:06:26 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 19:06:29 ERROR Executor: Exception in task 0.0 in stage 21.0 (TID 19)
java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
19/01/24 19:06:29 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 19,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
19/01/24 19:06:29 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 19:06:29 WARN TaskSetManager: Lost task 0.0 in stage 21.0 (TID 19, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)

19/01/24 19:06:29 ERROR TaskSetManager: Task 0 in stage 21.0 failed 1 times; aborting job
19/01/24 19:06:29 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/01/24 19:06:29 INFO TaskSchedulerImpl: Cancelling stage 21
19/01/24 19:06:29 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 19:06:29 INFO DAGScheduler: ResultStage 21 (collectAsMap at RandomForest.scala:928) failed in 2,697 s due to Job aborted due to stage failure: Task 0 in stage 21.0 failed 1 times, most recent failure: Lost task 0.0 in stage 21.0 (TID 19, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)

Driver stacktrace:
19/01/24 19:06:29 INFO DAGScheduler: Job 12 failed: collectAsMap at RandomForest.scala:928, took 19,968958 s
19/01/24 19:06:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 19:06:29 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c85f1b1792`
GROUP BY `Sentiment`, `Prediction`
19/01/24 19:06:29 INFO HiveMetaStore: 0: get_database: default
19/01/24 19:06:29 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 19:06:29 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c85f1b1792`
GROUP BY `Sentiment`, `Prediction`
19/01/24 19:06:29 INFO HiveMetaStore: 0: get_database: default
19/01/24 19:06:29 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 19:06:29 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_4c85f1b1792`
GROUP BY `Sentiment`, `Prediction`
LIMIT 11
19/01/24 19:06:29 INFO HiveMetaStore: 0: get_database: default
19/01/24 19:06:29 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 19:06:29 INFO MemoryStore: MemoryStore cleared
19/01/24 19:06:29 INFO BlockManager: BlockManager stopped
19/01/24 19:06:29 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 19:06:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 19:06:29 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-dea9d28e-1864-424c-bcd0-0db3a95558e3\userFiles-fa29ecbf-5ef7-4c97-914d-66a7f2756501
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-dea9d28e-1864-424c-bcd0-0db3a95558e3\userFiles-fa29ecbf-5ef7-4c97-914d-66a7f2756501
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 19:06:29 INFO SparkContext: Successfully stopped SparkContext
19/01/24 19:06:29 INFO ShutdownHookManager: Shutdown hook called
19/01/24 19:06:29 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-dea9d28e-1864-424c-bcd0-0db3a95558e3\userFiles-fa29ecbf-5ef7-4c97-914d-66a7f2756501
19/01/24 19:06:29 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-dea9d28e-1864-424c-bcd0-0db3a95558e3\userFiles-fa29ecbf-5ef7-4c97-914d-66a7f2756501
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-dea9d28e-1864-424c-bcd0-0db3a95558e3\userFiles-fa29ecbf-5ef7-4c97-914d-66a7f2756501
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 19:06:29 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-dea9d28e-1864-424c-bcd0-0db3a95558e3
19/01/24 19:06:29 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-dea9d28e-1864-424c-bcd0-0db3a95558e3
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-dea9d28e-1864-424c-bcd0-0db3a95558e3
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 20:10:42 INFO SparkContext: Running Spark version 2.2.0
19/01/24 20:10:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 20:10:43 INFO SparkContext: Submitted application: sparklyr
19/01/24 20:10:43 INFO SecurityManager: Changing view acls to: yanis
19/01/24 20:10:43 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 20:10:43 INFO SecurityManager: Changing view acls groups to: 
19/01/24 20:10:43 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 20:10:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 20:10:43 INFO Utils: Successfully started service 'sparkDriver' on port 55039.
19/01/24 20:10:43 INFO SparkEnv: Registering MapOutputTracker
19/01/24 20:10:43 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 20:10:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 20:10:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 20:10:43 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-f61ca963-684b-433b-9a0d-29e7f8182e5b
19/01/24 20:10:43 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 20:10:43 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 20:10:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 20:10:43 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 20:10:43 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:55039/jars/sparklyr-2.2-2.11.jar with timestamp 1548357043663
19/01/24 20:10:43 INFO Executor: Starting executor ID driver on host localhost
19/01/24 20:10:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55080.
19/01/24 20:10:43 INFO NettyBlockTransferService: Server created on 127.0.0.1:55080
19/01/24 20:10:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 20:10:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 55080, None)
19/01/24 20:10:43 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:55080 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 55080, None)
19/01/24 20:10:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 55080, None)
19/01/24 20:10:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 55080, None)
19/01/24 20:10:43 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 20:10:44 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 20:10:44 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 20:10:44 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 20:10:44 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 20:10:45 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 20:10:45 INFO ObjectStore: ObjectStore, initialize called
19/01/24 20:10:45 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 20:10:45 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 20:10:46 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 20:10:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 20:10:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 20:10:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 20:10:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 20:10:48 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 20:10:48 INFO ObjectStore: Initialized ObjectStore
19/01/24 20:10:48 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 20:10:48 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 20:10:48 INFO HiveMetaStore: Added admin role in metastore
19/01/24 20:10:48 INFO HiveMetaStore: Added public role in metastore
19/01/24 20:10:48 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 20:10:48 INFO HiveMetaStore: 0: get_all_databases
19/01/24 20:10:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 20:10:48 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 20:10:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 20:10:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 20:10:48 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/f363a053-088f-4f7d-abfd-e51b9852cb67_resources
19/01/24 20:10:48 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/f363a053-088f-4f7d-abfd-e51b9852cb67
19/01/24 20:10:48 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/f363a053-088f-4f7d-abfd-e51b9852cb67
19/01/24 20:10:48 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/f363a053-088f-4f7d-abfd-e51b9852cb67/_tmp_space.db
19/01/24 20:10:48 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 20:10:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 20:10:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 20:10:48 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 20:10:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 20:10:48 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 20:10:49 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/ec116f4f-a1c1-43c6-8c91-4996f67905ad_resources
19/01/24 20:10:49 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/ec116f4f-a1c1-43c6-8c91-4996f67905ad
19/01/24 20:10:49 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/ec116f4f-a1c1-43c6-8c91-4996f67905ad
19/01/24 20:10:49 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/ec116f4f-a1c1-43c6-8c91-4996f67905ad/_tmp_space.db
19/01/24 20:10:49 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 20:10:49 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 20:10:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 20:10:51 INFO HiveMetaStore: 0: get_database: default
19/01/24 20:10:51 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 20:10:51 INFO HiveMetaStore: 0: get_database: default
19/01/24 20:10:51 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 20:10:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 20:10:51 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 20:10:51 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 20:10:51 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 20:10:51 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 20:10:51 INFO DAGScheduler: Parents of final stage: List()
19/01/24 20:10:51 INFO DAGScheduler: Missing parents: List()
19/01/24 20:10:51 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 20:10:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 20:10:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 20:10:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:55080 (size: 3.4 KB, free: 366.3 MB)
19/01/24 20:10:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 20:10:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 20:10:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 20:10:51 INFO Executor: Fetching spark://127.0.0.1:55039/jars/sparklyr-2.2-2.11.jar with timestamp 1548357043663
19/01/24 20:10:51 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:55039 after 17 ms (0 ms spent in bootstraps)
19/01/24 20:10:51 INFO Utils: Fetching spark://127.0.0.1:55039/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-403189c1-3904-43d8-a243-b24e64ac35da\userFiles-f273b279-0c22-4ee0-b524-06e8203ccc01\fetchFileTemp6310456665959367714.tmp
19/01/24 20:10:52 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-403189c1-3904-43d8-a243-b24e64ac35da/userFiles-f273b279-0c22-4ee0-b524-06e8203ccc01/sparklyr-2.2-2.11.jar to class loader
19/01/24 20:10:52 INFO CodeGenerator: Code generated in 169.565325 ms
19/01/24 20:10:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/01/24 20:10:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 512 ms on localhost (executor driver) (1/1)
19/01/24 20:10:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 20:10:52 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,529 s
19/01/24 20:10:52 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,785368 s
19/01/24 20:10:52 INFO SparkSqlParser: Parsing command: reviews_spark
19/01/24 20:10:52 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews_spark`
19/01/24 20:10:52 INFO SparkSqlParser: Parsing command: `reviews_spark`
19/01/24 20:10:53 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:55080 in memory (size: 3.4 KB, free: 366.3 MB)
19/01/24 20:10:53 INFO CodeGenerator: Code generated in 15.365832 ms
19/01/24 20:10:53 INFO CodeGenerator: Code generated in 9.633913 ms
19/01/24 20:10:53 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 20:10:53 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 20:10:53 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 20:10:53 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 20:10:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 20:10:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 20:10:53 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 20:10:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 20:10:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 20:10:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:55080 (size: 7.7 KB, free: 366.3 MB)
19/01/24 20:10:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 20:10:53 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 20:10:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 20:10:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 20:10:53 INFO CodeGenerator: Code generated in 10.96132 ms
19/01/24 20:10:53 INFO CodeGenerator: Code generated in 19.347324 ms
19/01/24 20:10:53 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.5 MB)
19/01/24 20:10:53 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:55080 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 20:10:53 INFO CodeGenerator: Code generated in 4.950062 ms
19/01/24 20:10:53 INFO CodeGenerator: Code generated in 17.068487 ms
19/01/24 20:10:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 20:10:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 396 ms on localhost (executor driver) (1/1)
19/01/24 20:10:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 20:10:53 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,397 s
19/01/24 20:10:53 INFO DAGScheduler: looking for newly runnable stages
19/01/24 20:10:53 INFO DAGScheduler: running: Set()
19/01/24 20:10:53 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 20:10:53 INFO DAGScheduler: failed: Set()
19/01/24 20:10:53 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 20:10:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 20:10:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 20:10:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:55080 (size: 3.7 KB, free: 364.5 MB)
19/01/24 20:10:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:53 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 20:10:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 20:10:53 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 20:10:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 20:10:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/01/24 20:10:53 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1538 bytes result sent to driver
19/01/24 20:10:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 124 ms on localhost (executor driver) (1/1)
19/01/24 20:10:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 20:10:53 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,125 s
19/01/24 20:10:53 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 20:10:53 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 20:10:53 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,561622 s
19/01/24 20:10:53 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:55080 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 20:10:53 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews_spark`
19/01/24 20:10:53 INFO HiveMetaStore: 0: get_database: default
19/01/24 20:10:53 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 20:10:53 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 20:10:53 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 20:10:53 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 20:10:53 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 20:10:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 20:10:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 20:10:53 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 20:10:53 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 20:10:53 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.4 MB)
19/01/24 20:10:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:55080 (size: 7.7 KB, free: 364.5 MB)
19/01/24 20:10:53 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:53 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 20:10:53 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 20:10:53 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 20:10:53 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 20:10:53 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 20:10:53 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
19/01/24 20:10:53 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 50 ms on localhost (executor driver) (1/1)
19/01/24 20:10:53 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 20:10:53 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,051 s
19/01/24 20:10:53 INFO DAGScheduler: looking for newly runnable stages
19/01/24 20:10:53 INFO DAGScheduler: running: Set()
19/01/24 20:10:53 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 20:10:53 INFO DAGScheduler: failed: Set()
19/01/24 20:10:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 20:10:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 20:10:54 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 20:10:54 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:55080 (size: 3.7 KB, free: 364.5 MB)
19/01/24 20:10:54 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:54 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 20:10:54 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 20:10:54 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 20:10:54 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 20:10:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 20:10:54 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1452 bytes result sent to driver
19/01/24 20:10:54 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
19/01/24 20:10:54 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 20:10:54 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,006 s
19/01/24 20:10:54 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,075740 s
19/01/24 20:10:54 INFO CodeGenerator: Code generated in 6.200887 ms
19/01/24 20:10:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews_spark` AS `zzz1`
WHERE (0 = 1)
19/01/24 20:10:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews_spark`
19/01/24 20:10:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_5f28325f374a
19/01/24 20:10:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_5f28325f374a` AS `zzz2`
WHERE (0 = 1)
19/01/24 20:10:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_5f2826412db0
19/01/24 20:10:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_5f2826412db0` AS `zzz3`
WHERE (0 = 1)
19/01/24 20:10:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_5f28325f374a`
19/01/24 20:10:57 INFO CodeGenerator: Code generated in 44.999103 ms
19/01/24 20:10:57 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 20:10:57 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 20:10:57 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 20:10:57 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 20:10:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 20:10:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 20:10:57 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 20:10:57 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 20:10:57 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 20:10:57 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:55080 (size: 13.0 KB, free: 364.5 MB)
19/01/24 20:10:57 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:57 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 20:10:57 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 20:10:57 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 20:10:57 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 20:10:57 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 20:10:57 INFO CodeGenerator: Code generated in 21.01497 ms
19/01/24 20:10:57 INFO CodeGenerator: Code generated in 18.444031 ms
19/01/24 20:10:57 INFO CodeGenerator: Code generated in 15.202458 ms
19/01/24 20:10:57 INFO CodeGenerator: Code generated in 17.681136 ms
19/01/24 20:10:58 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 20:10:58 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:55080 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 20:10:58 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:55080 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 20:10:58 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1951 bytes result sent to driver
19/01/24 20:10:58 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 996 ms on localhost (executor driver) (1/1)
19/01/24 20:10:58 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 20:10:58 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 0,997 s
19/01/24 20:10:58 INFO DAGScheduler: looking for newly runnable stages
19/01/24 20:10:58 INFO DAGScheduler: running: Set()
19/01/24 20:10:58 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 20:10:58 INFO DAGScheduler: failed: Set()
19/01/24 20:10:58 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 20:10:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 20:10:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 20:10:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:55080 (size: 1887.0 B, free: 364.5 MB)
19/01/24 20:10:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:58 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 20:10:58 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 20:10:58 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 20:10:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 20:10:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 20:10:58 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 20:10:58 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:55080 (size: 686.3 KB, free: 363.8 MB)
19/01/24 20:10:58 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1787 bytes result sent to driver
19/01/24 20:10:58 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 198 ms on localhost (executor driver) (1/1)
19/01/24 20:10:58 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 20:10:58 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,198 s
19/01/24 20:10:58 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 1,231828 s
19/01/24 20:10:58 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 20:10:58 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 20:10:58 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 20:10:58 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 20:10:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 20:10:58 INFO DAGScheduler: Missing parents: List()
19/01/24 20:10:58 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 20:10:58 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.7 MB)
19/01/24 20:10:58 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.7 MB)
19/01/24 20:10:58 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:55080 (size: 2.2 KB, free: 363.8 MB)
19/01/24 20:10:58 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:58 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 20:10:58 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 20:10:58 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 20:10:58 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 20:10:58 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 20:10:58 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 87 ms on localhost (executor driver) (1/1)
19/01/24 20:10:58 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 20:10:58 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,087 s
19/01/24 20:10:58 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,112101 s
19/01/24 20:10:58 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 20:10:58 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.5 MB)
19/01/24 20:10:58 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:55080 (size: 89.8 KB, free: 363.7 MB)
19/01/24 20:10:58 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 20:10:59 INFO CodeGenerator: Code generated in 19.247039 ms
19/01/24 20:10:59 INFO CodeGenerator: Code generated in 21.626161 ms
19/01/24 20:10:59 INFO SparkContext: Starting job: take at Classifier.scala:111
19/01/24 20:10:59 INFO DAGScheduler: Registering RDD 34 (take at Classifier.scala:111)
19/01/24 20:10:59 INFO DAGScheduler: Got job 5 (take at Classifier.scala:111) with 1 output partitions
19/01/24 20:10:59 INFO DAGScheduler: Final stage: ResultStage 10 (take at Classifier.scala:111)
19/01/24 20:10:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
19/01/24 20:10:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
19/01/24 20:10:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[34] at take at Classifier.scala:111), which has no missing parents
19/01/24 20:10:59 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 25.0 KB, free 362.5 MB)
19/01/24 20:10:59 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.3 KB, free 362.5 MB)
19/01/24 20:10:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:55080 (size: 11.3 KB, free: 363.7 MB)
19/01/24 20:10:59 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[34] at take at Classifier.scala:111) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:59 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 20:10:59 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 20:10:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 20:10:59 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 20:10:59 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 20:10:59 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 2256 bytes result sent to driver
19/01/24 20:10:59 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 103 ms on localhost (executor driver) (1/1)
19/01/24 20:10:59 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 20:10:59 INFO DAGScheduler: ShuffleMapStage 9 (take at Classifier.scala:111) finished in 0,104 s
19/01/24 20:10:59 INFO DAGScheduler: looking for newly runnable stages
19/01/24 20:10:59 INFO DAGScheduler: running: Set()
19/01/24 20:10:59 INFO DAGScheduler: waiting: Set(ResultStage 10)
19/01/24 20:10:59 INFO DAGScheduler: failed: Set()
19/01/24 20:10:59 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[37] at take at Classifier.scala:111), which has no missing parents
19/01/24 20:10:59 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.2 KB, free 362.5 MB)
19/01/24 20:10:59 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 362.5 MB)
19/01/24 20:10:59 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:55080 (size: 3.9 KB, free: 363.7 MB)
19/01/24 20:10:59 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[37] at take at Classifier.scala:111) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:59 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 20:10:59 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 20:10:59 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 20:10:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 20:10:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 20:10:59 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1465 bytes result sent to driver
19/01/24 20:10:59 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 6 ms on localhost (executor driver) (1/1)
19/01/24 20:10:59 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 20:10:59 INFO DAGScheduler: ResultStage 10 (take at Classifier.scala:111) finished in 0,006 s
19/01/24 20:10:59 INFO DAGScheduler: Job 5 finished: take at Classifier.scala:111, took 0,130390 s
19/01/24 20:10:59 INFO CodeGenerator: Code generated in 5.392044 ms
19/01/24 20:10:59 INFO RandomForestClassifier: org.apache.spark.ml.classification.RandomForestClassifier inferred 2 classes for labelCol=random_forest_classifier_5f283c632e5e__labelCol since numClasses was not specified in the column metadata.
19/01/24 20:10:59 INFO CodeGenerator: Code generated in 18.658823 ms
19/01/24 20:10:59 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_5f283c632e5e-204551382-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 20:10:59 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_5f283c632e5e-204551382-1: {"subsamplingRate":1.0,"impurity":"gini","featuresCol":"vectorizer_output","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"Sentiment","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"rawPredictionCol":"rawPrediction","probabilityCol":"probability","numTrees":20}
19/01/24 20:10:59 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:112
19/01/24 20:10:59 INFO DAGScheduler: Got job 6 (take at DecisionTreeMetadata.scala:112) with 1 output partitions
19/01/24 20:10:59 INFO DAGScheduler: Final stage: ResultStage 11 (take at DecisionTreeMetadata.scala:112)
19/01/24 20:10:59 INFO DAGScheduler: Parents of final stage: List()
19/01/24 20:10:59 INFO DAGScheduler: Missing parents: List()
19/01/24 20:10:59 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[44] at map at DecisionTreeMetadata.scala:112), which has no missing parents
19/01/24 20:10:59 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 115.2 KB, free 362.4 MB)
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 265
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 262
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 176
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 261
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 178
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 174
19/01/24 20:10:59 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 74.4 KB, free 362.3 MB)
19/01/24 20:10:59 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:55080 in memory (size: 1887.0 B, free: 363.7 MB)
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 251
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 175
19/01/24 20:10:59 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:55080 (size: 74.4 KB, free: 363.6 MB)
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 267
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 252
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 254
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 255
19/01/24 20:10:59 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 263
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 257
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 266
19/01/24 20:10:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[44] at map at DecisionTreeMetadata.scala:112) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:59 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 20:10:59 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:55080 in memory (size: 13.0 KB, free: 363.6 MB)
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 20:10:59 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:55080 in memory (size: 2.2 KB, free: 363.6 MB)
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 264
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 260
19/01/24 20:10:59 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:55080 in memory (size: 11.3 KB, free: 363.6 MB)
19/01/24 20:10:59 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:55080 in memory (size: 3.9 KB, free: 363.6 MB)
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 259
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 258
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 177
19/01/24 20:10:59 WARN TaskSetManager: Stage 11 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 20:10:59 INFO BlockManager: Removing RDD 30
19/01/24 20:10:59 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 20:10:59 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 20:10:59 INFO ContextCleaner: Cleaned RDD 30
19/01/24 20:10:59 INFO ContextCleaner: Cleaned shuffle 3
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 256
19/01/24 20:10:59 INFO ContextCleaner: Cleaned accumulator 253
19/01/24 20:10:59 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 20:10:59 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 20:10:59 INFO CodeGenerator: Code generated in 7.084853 ms
19/01/24 20:10:59 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 1625 bytes result sent to driver
19/01/24 20:10:59 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 98 ms on localhost (executor driver) (1/1)
19/01/24 20:10:59 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 20:10:59 INFO DAGScheduler: ResultStage 11 (take at DecisionTreeMetadata.scala:112) finished in 0,099 s
19/01/24 20:10:59 INFO DAGScheduler: Job 6 finished: take at DecisionTreeMetadata.scala:112, took 0,118668 s
19/01/24 20:10:59 INFO SparkContext: Starting job: count at DecisionTreeMetadata.scala:118
19/01/24 20:10:59 INFO DAGScheduler: Got job 7 (count at DecisionTreeMetadata.scala:118) with 1 output partitions
19/01/24 20:10:59 INFO DAGScheduler: Final stage: ResultStage 12 (count at DecisionTreeMetadata.scala:118)
19/01/24 20:10:59 INFO DAGScheduler: Parents of final stage: List()
19/01/24 20:10:59 INFO DAGScheduler: Missing parents: List()
19/01/24 20:10:59 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[43] at retag at RandomForest.scala:103), which has no missing parents
19/01/24 20:10:59 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 114.8 KB, free 363.0 MB)
19/01/24 20:10:59 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 74.1 KB, free 362.9 MB)
19/01/24 20:10:59 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:55080 (size: 74.1 KB, free: 364.2 MB)
19/01/24 20:10:59 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 20:10:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[43] at retag at RandomForest.scala:103) (first 15 tasks are for partitions Vector(0))
19/01/24 20:10:59 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 20:10:59 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 20:10:59 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 20:10:59 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 20:10:59 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 20:10:59 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:55080 in memory (size: 74.4 KB, free: 364.3 MB)
19/01/24 20:10:59 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 1719 bytes result sent to driver
19/01/24 20:10:59 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 418 ms on localhost (executor driver) (1/1)
19/01/24 20:10:59 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 20:10:59 INFO DAGScheduler: ResultStage 12 (count at DecisionTreeMetadata.scala:118) finished in 0,419 s
19/01/24 20:10:59 INFO DAGScheduler: Job 7 finished: count at DecisionTreeMetadata.scala:118, took 0,428211 s
19/01/24 20:10:59 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_5f283c632e5e-204551382-1: {"numFeatures":8098}
19/01/24 20:10:59 INFO Instrumentation: RandomForestClassifier-random_forest_classifier_5f283c632e5e-204551382-1: {"numClasses":2}
19/01/24 20:11:00 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:928
19/01/24 20:11:00 INFO DAGScheduler: Registering RDD 46 (flatMap at RandomForest.scala:921)
19/01/24 20:11:00 INFO DAGScheduler: Got job 8 (collectAsMap at RandomForest.scala:928) with 1 output partitions
19/01/24 20:11:00 INFO DAGScheduler: Final stage: ResultStage 14 (collectAsMap at RandomForest.scala:928)
19/01/24 20:11:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
19/01/24 20:11:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
19/01/24 20:11:00 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[46] at flatMap at RandomForest.scala:921), which has no missing parents
19/01/24 20:11:00 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 199.7 KB, free 362.9 MB)
19/01/24 20:11:00 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 108.1 KB, free 362.8 MB)
19/01/24 20:11:00 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:55080 (size: 108.1 KB, free: 364.2 MB)
19/01/24 20:11:00 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/01/24 20:11:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[46] at flatMap at RandomForest.scala:921) (first 15 tasks are for partitions Vector(0))
19/01/24 20:11:00 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 20:11:00 WARN TaskSetManager: Stage 13 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 20:11:00 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914234 bytes)
19/01/24 20:11:00 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 20:11:00 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 20:11:01 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:55080 in memory (size: 74.1 KB, free: 364.3 MB)
19/01/24 20:11:19 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 1865 bytes result sent to driver
19/01/24 20:11:19 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 19121 ms on localhost (executor driver) (1/1)
19/01/24 20:11:19 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 20:11:19 INFO DAGScheduler: ShuffleMapStage 13 (flatMap at RandomForest.scala:921) finished in 19,122 s
19/01/24 20:11:19 INFO DAGScheduler: looking for newly runnable stages
19/01/24 20:11:19 INFO DAGScheduler: running: Set()
19/01/24 20:11:19 INFO DAGScheduler: waiting: Set(ResultStage 14)
19/01/24 20:11:19 INFO DAGScheduler: failed: Set()
19/01/24 20:11:19 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[48] at map at RandomForest.scala:923), which has no missing parents
19/01/24 20:11:19 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 233.7 KB, free 362.7 MB)
19/01/24 20:11:19 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 109.7 KB, free 362.6 MB)
19/01/24 20:11:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:55080 (size: 109.7 KB, free: 364.2 MB)
19/01/24 20:11:19 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 20:11:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[48] at map at RandomForest.scala:923) (first 15 tasks are for partitions Vector(0))
19/01/24 20:11:19 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/01/24 20:11:19 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 13, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 20:11:19 INFO Executor: Running task 0.0 in stage 14.0 (TID 13)
19/01/24 20:11:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 20:11:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 20:11:19 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:55080 in memory (size: 108.1 KB, free: 364.3 MB)
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 20:11:19 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 20:11:19 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:55080 in memory (size: 3.7 KB, free: 364.3 MB)
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 20:11:19 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 20:11:21 ERROR Executor: Exception in task 0.0 in stage 14.0 (TID 13)
java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
19/01/24 20:11:21 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 13,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
19/01/24 20:11:21 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 20:11:21 WARN TaskSetManager: Lost task 0.0 in stage 14.0 (TID 13, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)

19/01/24 20:11:21 ERROR TaskSetManager: Task 0 in stage 14.0 failed 1 times; aborting job
19/01/24 20:11:21 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/01/24 20:11:21 INFO TaskSchedulerImpl: Cancelling stage 14
19/01/24 20:11:21 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 20:11:21 INFO DAGScheduler: ResultStage 14 (collectAsMap at RandomForest.scala:928) failed in 2,675 s due to Job aborted due to stage failure: Task 0 in stage 14.0 failed 1 times, most recent failure: Lost task 0.0 in stage 14.0 (TID 13, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(Unknown Source)
	at java.nio.ByteBuffer.allocate(Unknown Source)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5.apply(ShuffleBlockFetcherIterator.scala:390)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)
	at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)

Driver stacktrace:
19/01/24 20:11:21 INFO DAGScheduler: Job 8 failed: collectAsMap at RandomForest.scala:928, took 21,827490 s
19/01/24 20:11:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 20:11:21 INFO MemoryStore: MemoryStore cleared
19/01/24 20:11:21 INFO BlockManager: BlockManager stopped
19/01/24 20:11:21 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 20:11:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 20:11:21 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-403189c1-3904-43d8-a243-b24e64ac35da\userFiles-f273b279-0c22-4ee0-b524-06e8203ccc01
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-403189c1-3904-43d8-a243-b24e64ac35da\userFiles-f273b279-0c22-4ee0-b524-06e8203ccc01
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 20:11:21 INFO SparkContext: Successfully stopped SparkContext
19/01/24 20:11:21 INFO ShutdownHookManager: Shutdown hook called
19/01/24 20:11:21 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-403189c1-3904-43d8-a243-b24e64ac35da\userFiles-f273b279-0c22-4ee0-b524-06e8203ccc01
19/01/24 20:11:21 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-403189c1-3904-43d8-a243-b24e64ac35da\userFiles-f273b279-0c22-4ee0-b524-06e8203ccc01
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-403189c1-3904-43d8-a243-b24e64ac35da\userFiles-f273b279-0c22-4ee0-b524-06e8203ccc01
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 20:11:21 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-403189c1-3904-43d8-a243-b24e64ac35da
19/01/24 20:11:21 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-403189c1-3904-43d8-a243-b24e64ac35da
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-403189c1-3904-43d8-a243-b24e64ac35da
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 21:12:30 INFO SparkContext: Running Spark version 2.2.0
19/01/24 21:12:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 21:12:31 INFO SparkContext: Submitted application: sparklyr
19/01/24 21:12:31 INFO SecurityManager: Changing view acls to: yanis
19/01/24 21:12:31 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 21:12:31 INFO SecurityManager: Changing view acls groups to: 
19/01/24 21:12:31 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 21:12:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 21:12:31 INFO Utils: Successfully started service 'sparkDriver' on port 55644.
19/01/24 21:12:31 INFO SparkEnv: Registering MapOutputTracker
19/01/24 21:12:31 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 21:12:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 21:12:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 21:12:31 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-7f1c56b0-88a3-4371-be25-4367d330f1cb
19/01/24 21:12:31 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 21:12:31 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 21:12:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 21:12:32 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 21:12:32 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:55644/jars/sparklyr-2.2-2.11.jar with timestamp 1548360752138
19/01/24 21:12:32 INFO Executor: Starting executor ID driver on host localhost
19/01/24 21:12:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55685.
19/01/24 21:12:32 INFO NettyBlockTransferService: Server created on 127.0.0.1:55685
19/01/24 21:12:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 21:12:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 55685, None)
19/01/24 21:12:32 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:55685 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 55685, None)
19/01/24 21:12:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 55685, None)
19/01/24 21:12:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 55685, None)
19/01/24 21:12:32 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 21:12:32 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 21:12:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 21:12:32 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 21:12:33 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 21:12:34 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 21:12:34 INFO ObjectStore: ObjectStore, initialize called
19/01/24 21:12:34 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 21:12:34 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 21:12:35 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 21:12:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 21:12:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 21:12:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 21:12:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 21:12:36 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 21:12:36 INFO ObjectStore: Initialized ObjectStore
19/01/24 21:12:36 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 21:12:37 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 21:12:37 INFO HiveMetaStore: Added admin role in metastore
19/01/24 21:12:37 INFO HiveMetaStore: Added public role in metastore
19/01/24 21:12:37 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 21:12:37 INFO HiveMetaStore: 0: get_all_databases
19/01/24 21:12:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 21:12:37 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 21:12:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 21:12:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 21:12:37 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/38c75b0e-e1a5-4111-ba78-0b02df276a6a_resources
19/01/24 21:12:37 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/38c75b0e-e1a5-4111-ba78-0b02df276a6a
19/01/24 21:12:37 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/38c75b0e-e1a5-4111-ba78-0b02df276a6a
19/01/24 21:12:37 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/38c75b0e-e1a5-4111-ba78-0b02df276a6a/_tmp_space.db
19/01/24 21:12:37 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 21:12:37 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:12:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:12:37 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 21:12:37 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 21:12:37 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 21:12:37 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/722addbe-03bd-44a8-9b92-290d6b99a5d3_resources
19/01/24 21:12:37 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/722addbe-03bd-44a8-9b92-290d6b99a5d3
19/01/24 21:12:37 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/722addbe-03bd-44a8-9b92-290d6b99a5d3
19/01/24 21:12:38 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/722addbe-03bd-44a8-9b92-290d6b99a5d3/_tmp_space.db
19/01/24 21:12:38 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 21:12:38 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 21:12:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 21:12:40 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:12:40 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:12:40 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:12:40 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:12:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 21:12:40 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 21:12:40 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 21:12:40 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 21:12:40 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 21:12:40 INFO DAGScheduler: Parents of final stage: List()
19/01/24 21:12:40 INFO DAGScheduler: Missing parents: List()
19/01/24 21:12:40 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 21:12:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 21:12:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 21:12:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:55685 (size: 3.4 KB, free: 366.3 MB)
19/01/24 21:12:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 21:12:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 21:12:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 21:12:41 INFO Executor: Fetching spark://127.0.0.1:55644/jars/sparklyr-2.2-2.11.jar with timestamp 1548360752138
19/01/24 21:12:41 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:55644 after 18 ms (0 ms spent in bootstraps)
19/01/24 21:12:41 INFO Utils: Fetching spark://127.0.0.1:55644/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-684f762e-3435-4276-bb69-c1166628a7af\userFiles-73ad9615-25b9-4f5c-b617-4063213d802b\fetchFileTemp4711361121059052922.tmp
19/01/24 21:12:41 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-684f762e-3435-4276-bb69-c1166628a7af/userFiles-73ad9615-25b9-4f5c-b617-4063213d802b/sparklyr-2.2-2.11.jar to class loader
19/01/24 21:12:41 INFO CodeGenerator: Code generated in 208.058674 ms
19/01/24 21:12:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/01/24 21:12:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 599 ms on localhost (executor driver) (1/1)
19/01/24 21:12:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 21:12:41 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,623 s
19/01/24 21:12:41 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,857001 s
19/01/24 21:12:41 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:55685 in memory (size: 3.4 KB, free: 366.3 MB)
19/01/24 21:12:41 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 21:12:42 INFO SparkSqlParser: Parsing command: reviews
19/01/24 21:12:42 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 21:12:42 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 21:12:42 INFO CodeGenerator: Code generated in 17.580851 ms
19/01/24 21:12:42 INFO CodeGenerator: Code generated in 10.35487 ms
19/01/24 21:12:42 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 21:12:42 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 21:12:42 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 21:12:42 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 21:12:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 21:12:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 21:12:42 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 21:12:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 21:12:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 21:12:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:55685 (size: 7.7 KB, free: 366.3 MB)
19/01/24 21:12:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 21:12:42 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 21:12:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 21:12:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 21:12:42 INFO CodeGenerator: Code generated in 10.419782 ms
19/01/24 21:12:42 INFO CodeGenerator: Code generated in 28.459756 ms
19/01/24 21:12:42 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.5 MB)
19/01/24 21:12:42 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:55685 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 21:12:43 INFO CodeGenerator: Code generated in 6.804785 ms
19/01/24 21:12:43 INFO CodeGenerator: Code generated in 26.932508 ms
19/01/24 21:12:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 21:12:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 501 ms on localhost (executor driver) (1/1)
19/01/24 21:12:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 21:12:43 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,502 s
19/01/24 21:12:43 INFO DAGScheduler: looking for newly runnable stages
19/01/24 21:12:43 INFO DAGScheduler: running: Set()
19/01/24 21:12:43 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 21:12:43 INFO DAGScheduler: failed: Set()
19/01/24 21:12:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 21:12:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 21:12:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 21:12:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:55685 (size: 3.7 KB, free: 364.5 MB)
19/01/24 21:12:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 21:12:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 21:12:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 21:12:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 21:12:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
19/01/24 21:12:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:55685 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 21:12:43 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 21:12:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
19/01/24 21:12:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 243 ms on localhost (executor driver) (1/1)
19/01/24 21:12:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 21:12:43 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,243 s
19/01/24 21:12:43 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,798007 s
19/01/24 21:12:43 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 21:12:43 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:12:43 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:12:43 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 21:12:43 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 21:12:43 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 21:12:43 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 21:12:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 21:12:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 21:12:43 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 21:12:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 21:12:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.4 MB)
19/01/24 21:12:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:55685 (size: 7.7 KB, free: 364.5 MB)
19/01/24 21:12:43 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:43 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 21:12:43 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 21:12:43 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 21:12:43 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 21:12:43 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 21:12:43 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
19/01/24 21:12:43 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 45 ms on localhost (executor driver) (1/1)
19/01/24 21:12:43 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 21:12:43 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,046 s
19/01/24 21:12:43 INFO DAGScheduler: looking for newly runnable stages
19/01/24 21:12:43 INFO DAGScheduler: running: Set()
19/01/24 21:12:43 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 21:12:43 INFO DAGScheduler: failed: Set()
19/01/24 21:12:43 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 21:12:43 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 21:12:43 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 21:12:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:55685 (size: 3.7 KB, free: 364.5 MB)
19/01/24 21:12:43 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:43 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 21:12:43 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 21:12:43 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 21:12:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 21:12:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 21:12:43 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
19/01/24 21:12:43 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
19/01/24 21:12:43 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 21:12:43 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,006 s
19/01/24 21:12:43 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,074971 s
19/01/24 21:12:43 INFO CodeGenerator: Code generated in 8.837104 ms
19/01/24 21:12:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz1`
WHERE (0 = 1)
19/01/24 21:12:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 21:12:47 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e41eef29ca
19/01/24 21:12:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e41eef29ca` AS `zzz2`
WHERE (0 = 1)
19/01/24 21:12:47 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e411bb6101
19/01/24 21:12:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e411bb6101` AS `zzz3`
WHERE (0 = 1)
19/01/24 21:12:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e41eef29ca`
19/01/24 21:12:48 INFO CodeGenerator: Code generated in 32.291368 ms
19/01/24 21:12:48 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 21:12:48 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 21:12:48 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 21:12:48 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 21:12:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 21:12:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 21:12:48 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 21:12:48 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 21:12:48 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 21:12:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:55685 (size: 13.0 KB, free: 364.5 MB)
19/01/24 21:12:48 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:48 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 21:12:48 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 21:12:48 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 21:12:48 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 21:12:48 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 21:12:48 INFO CodeGenerator: Code generated in 12.835736 ms
19/01/24 21:12:48 INFO CodeGenerator: Code generated in 15.438402 ms
19/01/24 21:12:48 INFO CodeGenerator: Code generated in 12.345981 ms
19/01/24 21:12:48 INFO CodeGenerator: Code generated in 11.940829 ms
19/01/24 21:12:49 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:55685 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 21:12:49 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 21:12:49 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:55685 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 21:12:49 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1951 bytes result sent to driver
19/01/24 21:12:49 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 953 ms on localhost (executor driver) (1/1)
19/01/24 21:12:49 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 21:12:49 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 0,953 s
19/01/24 21:12:49 INFO DAGScheduler: looking for newly runnable stages
19/01/24 21:12:49 INFO DAGScheduler: running: Set()
19/01/24 21:12:49 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 21:12:49 INFO DAGScheduler: failed: Set()
19/01/24 21:12:49 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 21:12:49 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 21:12:49 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 21:12:49 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:55685 (size: 1887.0 B, free: 364.5 MB)
19/01/24 21:12:49 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:49 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 21:12:49 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 21:12:49 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 21:12:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 21:12:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 21:12:49 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 21:12:49 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:55685 (size: 686.3 KB, free: 363.8 MB)
19/01/24 21:12:49 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1830 bytes result sent to driver
19/01/24 21:12:49 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 106 ms on localhost (executor driver) (1/1)
19/01/24 21:12:49 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 21:12:49 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,108 s
19/01/24 21:12:49 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 1,100370 s
19/01/24 21:12:49 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 21:12:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 21:12:49 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 21:12:49 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 21:12:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 21:12:49 INFO DAGScheduler: Missing parents: List()
19/01/24 21:12:49 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 21:12:49 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.7 MB)
19/01/24 21:12:49 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.7 MB)
19/01/24 21:12:49 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:55685 (size: 2.2 KB, free: 363.8 MB)
19/01/24 21:12:49 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:49 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 21:12:49 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 21:12:49 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 21:12:49 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 21:12:49 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 21:12:49 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 54 ms on localhost (executor driver) (1/1)
19/01/24 21:12:49 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 21:12:49 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,054 s
19/01/24 21:12:49 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,073710 s
19/01/24 21:12:49 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 21:12:49 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.5 MB)
19/01/24 21:12:49 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:55685 (size: 89.8 KB, free: 363.7 MB)
19/01/24 21:12:49 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 21:12:49 INFO CodeGenerator: Code generated in 38.517417 ms
19/01/24 21:12:49 INFO Instrumentation: NaiveBayes-naive_bayes_56e413354c2d-61505308-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 21:12:49 INFO Instrumentation: NaiveBayes-naive_bayes_56e413354c2d-61505308-1: {"smoothing":1.0,"featuresCol":"vectorizer_output","modelType":"multinomial","labelCol":"Sentiment","predictionCol":"prediction","rawPredictionCol":"rawPrediction","probabilityCol":"probability"}
19/01/24 21:12:49 INFO CodeGenerator: Code generated in 25.664178 ms
19/01/24 21:12:49 INFO SparkContext: Starting job: head at NaiveBayes.scala:154
19/01/24 21:12:49 INFO DAGScheduler: Got job 5 (head at NaiveBayes.scala:154) with 1 output partitions
19/01/24 21:12:49 INFO DAGScheduler: Final stage: ResultStage 9 (head at NaiveBayes.scala:154)
19/01/24 21:12:49 INFO DAGScheduler: Parents of final stage: List()
19/01/24 21:12:49 INFO DAGScheduler: Missing parents: List()
19/01/24 21:12:49 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154), which has no missing parents
19/01/24 21:12:49 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 113.1 KB, free 362.4 MB)
19/01/24 21:12:49 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 72.9 KB, free 362.4 MB)
19/01/24 21:12:49 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:55685 (size: 72.9 KB, free: 363.6 MB)
19/01/24 21:12:49 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:49 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 21:12:49 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 21:12:49 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 21:12:49 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 21:12:49 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 21:12:50 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 1743 bytes result sent to driver
19/01/24 21:12:50 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 95 ms on localhost (executor driver) (1/1)
19/01/24 21:12:50 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 21:12:50 INFO DAGScheduler: ResultStage 9 (head at NaiveBayes.scala:154) finished in 0,096 s
19/01/24 21:12:50 INFO DAGScheduler: Job 5 finished: head at NaiveBayes.scala:154, took 0,106543 s
19/01/24 21:12:50 INFO CodeGenerator: Code generated in 7.171646 ms
19/01/24 21:12:50 INFO Instrumentation: NaiveBayes-naive_bayes_56e413354c2d-61505308-1: {"numFeatures":8098}
19/01/24 21:12:50 INFO CodeGenerator: Code generated in 24.886332 ms
19/01/24 21:12:50 INFO SparkContext: Starting job: collect at NaiveBayes.scala:174
19/01/24 21:12:50 INFO DAGScheduler: Registering RDD 43 (map at NaiveBayes.scala:162)
19/01/24 21:12:50 INFO DAGScheduler: Got job 6 (collect at NaiveBayes.scala:174) with 1 output partitions
19/01/24 21:12:50 INFO DAGScheduler: Final stage: ResultStage 11 (collect at NaiveBayes.scala:174)
19/01/24 21:12:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/01/24 21:12:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/01/24 21:12:50 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162), which has no missing parents
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 177
19/01/24 21:12:50 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 243.7 KB, free 362.1 MB)
19/01/24 21:12:50 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 76.0 KB, free 362.1 MB)
19/01/24 21:12:50 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:55685 (size: 76.0 KB, free: 364.2 MB)
19/01/24 21:12:50 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:50 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 21:12:50 INFO BlockManager: Removing RDD 30
19/01/24 21:12:50 WARN TaskSetManager: Stage 10 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 21:12:50 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 21:12:50 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 21:12:50 INFO ContextCleaner: Cleaned RDD 30
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 258
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 260
19/01/24 21:12:50 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 178
19/01/24 21:12:50 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:55685 in memory (size: 2.2 KB, free: 364.2 MB)
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 174
19/01/24 21:12:50 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:55685 in memory (size: 1887.0 B, free: 364.2 MB)
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 257
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 261
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 175
19/01/24 21:12:50 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:55685 in memory (size: 72.9 KB, free: 364.3 MB)
19/01/24 21:12:50 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:55685 in memory (size: 13.0 KB, free: 364.3 MB)
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 176
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 259
19/01/24 21:12:50 INFO ContextCleaner: Cleaned accumulator 262
19/01/24 21:12:50 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 21:12:50 INFO CodeGenerator: Code generated in 7.251508 ms
19/01/24 21:12:50 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1908 bytes result sent to driver
19/01/24 21:12:50 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 509 ms on localhost (executor driver) (1/1)
19/01/24 21:12:50 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 21:12:50 INFO DAGScheduler: ShuffleMapStage 10 (map at NaiveBayes.scala:162) finished in 0,511 s
19/01/24 21:12:50 INFO DAGScheduler: looking for newly runnable stages
19/01/24 21:12:50 INFO DAGScheduler: running: Set()
19/01/24 21:12:50 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/01/24 21:12:50 INFO DAGScheduler: failed: Set()
19/01/24 21:12:50 INFO DAGScheduler: Submitting ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163), which has no missing parents
19/01/24 21:12:50 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 244.4 KB, free 362.7 MB)
19/01/24 21:12:50 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 76.4 KB, free 362.6 MB)
19/01/24 21:12:50 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:55685 (size: 76.4 KB, free: 364.2 MB)
19/01/24 21:12:50 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/01/24 21:12:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 21:12:50 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 21:12:50 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 21:12:50 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 21:12:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 21:12:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 21:12:50 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 132406 bytes result sent to driver
19/01/24 21:12:50 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 11 ms on localhost (executor driver) (1/1)
19/01/24 21:12:50 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 21:12:50 INFO DAGScheduler: ResultStage 11 (collect at NaiveBayes.scala:174) finished in 0,011 s
19/01/24 21:12:50 INFO DAGScheduler: Job 6 finished: collect at NaiveBayes.scala:174, took 0,563279 s
19/01/24 21:12:50 INFO Instrumentation: NaiveBayes-naive_bayes_56e413354c2d-61505308-1: {"numClasses":2}
19/01/24 21:12:50 INFO Instrumentation: NaiveBayes-naive_bayes_56e413354c2d-61505308-1: training finished
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 252
19/01/24 21:12:52 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:55685 in memory (size: 76.0 KB, free: 364.3 MB)
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 254
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 292
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 256
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 289
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 253
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 290
19/01/24 21:12:52 INFO ContextCleaner: Cleaned shuffle 3
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 251
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 291
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 255
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 288
19/01/24 21:12:52 INFO ContextCleaner: Cleaned accumulator 287
19/01/24 21:12:52 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:55685 in memory (size: 76.4 KB, free: 364.4 MB)
19/01/24 21:13:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e411bb6101`
19/01/24 21:13:31 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e4a5486d
19/01/24 21:13:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e4a5486d` AS `zzz4`
WHERE (0 = 1)
19/01/24 21:13:31 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e4a5486d`
GROUP BY `Sentiment`, `Prediction`
19/01/24 21:13:31 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:13:31 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:13:31 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e4a5486d`
GROUP BY `Sentiment`, `Prediction`
19/01/24 21:13:31 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:13:31 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:13:31 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e4a5486d`
GROUP BY `Sentiment`, `Prediction`
LIMIT 11
19/01/24 21:13:31 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:13:31 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:13:32 INFO CodeGenerator: Code generated in 33.410547 ms
19/01/24 21:13:32 INFO CodeGenerator: Code generated in 59.682998 ms
19/01/24 21:13:32 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 21:13:32 INFO DAGScheduler: Registering RDD 47 (collect at utils.scala:200)
19/01/24 21:13:32 INFO DAGScheduler: Got job 7 (collect at utils.scala:200) with 1 output partitions
19/01/24 21:13:32 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:200)
19/01/24 21:13:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/01/24 21:13:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/01/24 21:13:32 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[47] at collect at utils.scala:200), which has no missing parents
19/01/24 21:13:32 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 254.9 KB, free 363.0 MB)
19/01/24 21:13:32 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 115.8 KB, free 362.9 MB)
19/01/24 21:13:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:55685 (size: 115.8 KB, free: 364.3 MB)
19/01/24 21:13:32 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 21:13:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[47] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 21:13:32 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 21:13:32 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 21:13:32 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 21:13:32 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 21:13:32 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 21:13:32 INFO CodeGenerator: Code generated in 9.338893 ms
19/01/24 21:13:32 INFO CodeGenerator: Code generated in 10.213013 ms
19/01/24 21:13:32 INFO CodeGenerator: Code generated in 8.353548 ms
19/01/24 21:13:32 INFO CodeGenerator: Code generated in 19.275119 ms
19/01/24 21:13:32 INFO CodeGenerator: Code generated in 17.129023 ms
19/01/24 21:13:32 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/01/24 21:13:32 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/01/24 21:13:32 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 2263 bytes result sent to driver
19/01/24 21:13:32 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 619 ms on localhost (executor driver) (1/1)
19/01/24 21:13:32 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 21:13:32 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:200) finished in 0,620 s
19/01/24 21:13:32 INFO DAGScheduler: looking for newly runnable stages
19/01/24 21:13:32 INFO DAGScheduler: running: Set()
19/01/24 21:13:32 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/01/24 21:13:32 INFO DAGScheduler: failed: Set()
19/01/24 21:13:32 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 21:13:32 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 236.2 KB, free 362.7 MB)
19/01/24 21:13:32 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 108.8 KB, free 362.6 MB)
19/01/24 21:13:32 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:55685 (size: 108.8 KB, free: 364.2 MB)
19/01/24 21:13:32 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/01/24 21:13:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 21:13:32 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 21:13:32 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 21:13:32 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 21:13:32 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 2584 bytes result sent to driver
19/01/24 21:13:32 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 17 ms on localhost (executor driver) (1/1)
19/01/24 21:13:32 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 21:13:32 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:200) finished in 0,017 s
19/01/24 21:13:32 INFO DAGScheduler: Job 7 finished: collect at utils.scala:200, took 0,663766 s
19/01/24 21:13:32 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 21:13:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 149 bytes
19/01/24 21:13:32 INFO DAGScheduler: Got job 8 (collect at utils.scala:200) with 4 output partitions
19/01/24 21:13:32 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:200)
19/01/24 21:13:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/01/24 21:13:32 INFO DAGScheduler: Missing parents: List()
19/01/24 21:13:32 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 21:13:32 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 236.2 KB, free 362.3 MB)
19/01/24 21:13:32 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 108.9 KB, free 362.2 MB)
19/01/24 21:13:32 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:55685 (size: 108.9 KB, free: 364.1 MB)
19/01/24 21:13:32 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 21:13:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
19/01/24 21:13:32 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/01/24 21:13:32 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
19/01/24 21:13:32 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
19/01/24 21:13:32 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
19/01/24 21:13:32 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 16, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
19/01/24 21:13:32 INFO Executor: Running task 0.0 in stage 15.0 (TID 13)
19/01/24 21:13:32 INFO Executor: Running task 1.0 in stage 15.0 (TID 14)
19/01/24 21:13:32 INFO Executor: Running task 2.0 in stage 15.0 (TID 15)
19/01/24 21:13:32 INFO Executor: Running task 3.0 in stage 15.0 (TID 16)
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 21:13:32 INFO Executor: Finished task 3.0 in stage 15.0 (TID 16). 2558 bytes result sent to driver
19/01/24 21:13:32 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 16) in 17 ms on localhost (executor driver) (1/4)
19/01/24 21:13:32 INFO Executor: Finished task 2.0 in stage 15.0 (TID 15). 2515 bytes result sent to driver
19/01/24 21:13:32 INFO Executor: Finished task 0.0 in stage 15.0 (TID 13). 2558 bytes result sent to driver
19/01/24 21:13:32 INFO Executor: Finished task 1.0 in stage 15.0 (TID 14). 2515 bytes result sent to driver
19/01/24 21:13:32 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 15) in 19 ms on localhost (executor driver) (2/4)
19/01/24 21:13:32 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 13) in 20 ms on localhost (executor driver) (3/4)
19/01/24 21:13:32 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 14) in 20 ms on localhost (executor driver) (4/4)
19/01/24 21:13:32 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 21:13:32 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:200) finished in 0,020 s
19/01/24 21:13:32 INFO DAGScheduler: Job 8 finished: collect at utils.scala:200, took 0,033371 s
19/01/24 21:13:32 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 21:13:32 INFO DAGScheduler: Got job 9 (collect at utils.scala:200) with 3 output partitions
19/01/24 21:13:32 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:200)
19/01/24 21:13:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
19/01/24 21:13:32 INFO DAGScheduler: Missing parents: List()
19/01/24 21:13:32 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 21:13:32 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 236.2 KB, free 362.0 MB)
19/01/24 21:13:32 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 108.8 KB, free 361.9 MB)
19/01/24 21:13:32 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:55685 (size: 108.8 KB, free: 364.0 MB)
19/01/24 21:13:32 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/01/24 21:13:32 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 17 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(5, 6, 7))
19/01/24 21:13:32 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
19/01/24 21:13:32 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 17, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
19/01/24 21:13:32 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 5, ANY, 4726 bytes)
19/01/24 21:13:32 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 19, localhost, executor driver, partition 7, ANY, 4726 bytes)
19/01/24 21:13:32 INFO Executor: Running task 1.0 in stage 17.0 (TID 17)
19/01/24 21:13:32 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
19/01/24 21:13:32 INFO Executor: Running task 2.0 in stage 17.0 (TID 19)
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 21:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 21:13:32 INFO Executor: Finished task 1.0 in stage 17.0 (TID 17). 2558 bytes result sent to driver
19/01/24 21:13:32 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 2591 bytes result sent to driver
19/01/24 21:13:32 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 17) in 19 ms on localhost (executor driver) (1/3)
19/01/24 21:13:32 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 19 ms on localhost (executor driver) (2/3)
19/01/24 21:13:32 INFO Executor: Finished task 2.0 in stage 17.0 (TID 19). 2535 bytes result sent to driver
19/01/24 21:13:32 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 19) in 21 ms on localhost (executor driver) (3/3)
19/01/24 21:13:32 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 21:13:32 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:200) finished in 0,024 s
19/01/24 21:13:32 INFO DAGScheduler: Job 9 finished: collect at utils.scala:200, took 0,038253 s
19/01/24 21:13:32 INFO CodeGenerator: Code generated in 10.767679 ms
19/01/24 21:13:33 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e4a5486d`
GROUP BY `Sentiment`, `Prediction`
19/01/24 21:13:33 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:13:33 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:13:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 21:13:34 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:13:34 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:13:34 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:13:34 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:13:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 21:13:34 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 21:13:34 INFO CodeGenerator: Code generated in 7.008272 ms
19/01/24 21:13:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 21:13:34 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:13:34 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:13:34 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:13:34 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:13:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 21:13:34 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 21:13:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 21:13:34 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:13:34 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:13:34 INFO HiveMetaStore: 0: get_database: default
19/01/24 21:13:34 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 21:13:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 21:13:34 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 21:42:32 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:55685 in memory (size: 108.8 KB, free: 364.1 MB)
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 341
19/01/24 21:42:32 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:55685 in memory (size: 115.8 KB, free: 364.2 MB)
19/01/24 21:42:32 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:55685 in memory (size: 108.8 KB, free: 364.3 MB)
19/01/24 21:42:32 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:55685 in memory (size: 108.9 KB, free: 364.4 MB)
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 118
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 114
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 121
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 115
19/01/24 21:42:32 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:55685 in memory (size: 3.7 KB, free: 364.4 MB)
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 120
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 123
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 122
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 21:42:32 INFO ContextCleaner: Cleaned shuffle 1
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 113
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 124
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 117
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 119
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 116
19/01/24 21:42:32 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 21:42:32 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 22:23:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 22:23:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:23:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:23:48 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:23:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:23:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 22:23:48 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 22:23:48 INFO CodeGenerator: Code generated in 14.162049 ms
19/01/24 22:23:48 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 22:23:48 INFO DAGScheduler: Got job 10 (collect at utils.scala:44) with 4 output partitions
19/01/24 22:23:48 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:44)
19/01/24 22:23:48 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:23:48 INFO DAGScheduler: Missing parents: List()
19/01/24 22:23:48 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[55] at map at utils.scala:41), which has no missing parents
19/01/24 22:23:48 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 6.6 KB, free 363.3 MB)
19/01/24 22:23:48 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.6 KB, free 363.3 MB)
19/01/24 22:23:48 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:55685 (size: 3.6 KB, free: 364.4 MB)
19/01/24 22:23:48 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/01/24 22:23:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[55] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/01/24 22:23:48 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
19/01/24 22:23:48 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/01/24 22:23:48 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
19/01/24 22:23:48 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 22, localhost, executor driver, partition 2, PROCESS_LOCAL, 5035 bytes)
19/01/24 22:23:48 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 23, localhost, executor driver, partition 3, PROCESS_LOCAL, 5027 bytes)
19/01/24 22:23:48 INFO Executor: Running task 0.0 in stage 18.0 (TID 20)
19/01/24 22:23:48 INFO Executor: Running task 1.0 in stage 18.0 (TID 21)
19/01/24 22:23:48 INFO Executor: Running task 2.0 in stage 18.0 (TID 22)
19/01/24 22:23:48 INFO Executor: Running task 3.0 in stage 18.0 (TID 23)
19/01/24 22:23:48 INFO Executor: Finished task 2.0 in stage 18.0 (TID 22). 912 bytes result sent to driver
19/01/24 22:23:48 INFO Executor: Finished task 0.0 in stage 18.0 (TID 20). 894 bytes result sent to driver
19/01/24 22:23:48 INFO Executor: Finished task 3.0 in stage 18.0 (TID 23). 910 bytes result sent to driver
19/01/24 22:23:48 INFO Executor: Finished task 1.0 in stage 18.0 (TID 21). 912 bytes result sent to driver
19/01/24 22:23:48 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 22) in 11 ms on localhost (executor driver) (1/4)
19/01/24 22:23:48 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 21) in 11 ms on localhost (executor driver) (2/4)
19/01/24 22:23:48 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 23) in 11 ms on localhost (executor driver) (3/4)
19/01/24 22:23:48 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 20) in 18 ms on localhost (executor driver) (4/4)
19/01/24 22:23:48 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/01/24 22:23:48 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:44) finished in 0,019 s
19/01/24 22:23:48 INFO DAGScheduler: Job 10 finished: collect at utils.scala:44, took 0,045338 s
19/01/24 22:23:49 INFO SparkSqlParser: Parsing command: reviews_spark
19/01/24 22:23:49 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews_spark`
19/01/24 22:23:49 INFO SparkSqlParser: Parsing command: `reviews_spark`
19/01/24 22:23:49 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 22:23:49 INFO DAGScheduler: Registering RDD 63 (sql at <unknown>:0)
19/01/24 22:23:49 INFO DAGScheduler: Got job 11 (sql at <unknown>:0) with 1 output partitions
19/01/24 22:23:49 INFO DAGScheduler: Final stage: ResultStage 20 (sql at <unknown>:0)
19/01/24 22:23:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
19/01/24 22:23:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
19/01/24 22:23:49 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[63] at sql at <unknown>:0), which has no missing parents
19/01/24 22:23:49 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 15.5 KB, free 363.3 MB)
19/01/24 22:23:49 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.7 KB, free 363.2 MB)
19/01/24 22:23:49 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:55685 (size: 7.7 KB, free: 364.4 MB)
19/01/24 22:23:49 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/01/24 22:23:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[63] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 22:23:49 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/01/24 22:23:49 WARN TaskSetManager: Stage 19 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:23:49 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:23:49 INFO Executor: Running task 0.0 in stage 19.0 (TID 24)
19/01/24 22:23:49 INFO MemoryStore: Block rdd_60_0 stored as values in memory (estimated size 1865.6 KB, free 361.4 MB)
19/01/24 22:23:49 INFO BlockManagerInfo: Added rdd_60_0 in memory on 127.0.0.1:55685 (size: 1865.6 KB, free: 362.6 MB)
19/01/24 22:23:49 INFO Executor: Finished task 0.0 in stage 19.0 (TID 24). 2328 bytes result sent to driver
19/01/24 22:23:49 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 24) in 261 ms on localhost (executor driver) (1/1)
19/01/24 22:23:49 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/01/24 22:23:49 INFO DAGScheduler: ShuffleMapStage 19 (sql at <unknown>:0) finished in 0,263 s
19/01/24 22:23:49 INFO DAGScheduler: looking for newly runnable stages
19/01/24 22:23:49 INFO DAGScheduler: running: Set()
19/01/24 22:23:49 INFO DAGScheduler: waiting: Set(ResultStage 20)
19/01/24 22:23:49 INFO DAGScheduler: failed: Set()
19/01/24 22:23:49 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[66] at sql at <unknown>:0), which has no missing parents
19/01/24 22:23:49 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 7.0 KB, free 361.4 MB)
19/01/24 22:23:49 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.7 KB, free 361.4 MB)
19/01/24 22:23:49 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:55685 (size: 3.7 KB, free: 362.6 MB)
19/01/24 22:23:49 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/01/24 22:23:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[66] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 22:23:49 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/01/24 22:23:49 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 25, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 22:23:49 INFO Executor: Running task 0.0 in stage 20.0 (TID 25)
19/01/24 22:23:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:23:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 22:23:49 INFO Executor: Finished task 0.0 in stage 20.0 (TID 25). 1581 bytes result sent to driver
19/01/24 22:23:49 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 25) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:23:49 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/01/24 22:23:49 INFO DAGScheduler: ResultStage 20 (sql at <unknown>:0) finished in 0,028 s
19/01/24 22:23:49 INFO DAGScheduler: Job 11 finished: sql at <unknown>:0, took 0,363356 s
19/01/24 22:23:49 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews_spark`
19/01/24 22:23:49 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:23:49 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:23:50 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 22:23:50 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:200)
19/01/24 22:23:50 INFO DAGScheduler: Got job 12 (collect at utils.scala:200) with 1 output partitions
19/01/24 22:23:50 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:200)
19/01/24 22:23:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
19/01/24 22:23:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
19/01/24 22:23:50 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[69] at collect at utils.scala:200), which has no missing parents
19/01/24 22:23:50 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 15.5 KB, free 361.4 MB)
19/01/24 22:23:50 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.7 KB, free 361.4 MB)
19/01/24 22:23:50 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:55685 (size: 7.7 KB, free: 362.5 MB)
19/01/24 22:23:50 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/01/24 22:23:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[69] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 22:23:50 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/01/24 22:23:50 WARN TaskSetManager: Stage 21 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:23:50 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:23:50 INFO Executor: Running task 0.0 in stage 21.0 (TID 26)
19/01/24 22:23:50 INFO BlockManager: Found block rdd_60_0 locally
19/01/24 22:23:50 ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file C:\Users\yanis\AppData\Local\Temp\blockmgr-7f1c56b0-88a3-4371-be25-4367d330f1cb\2e\temp_shuffle_e20300ec-4f68-4968-b83a-97447086fbb5
java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-7f1c56b0-88a3-4371-be25-4367d330f1cb\2e\temp_shuffle_e20300ec-4f68-4968-b83a-97447086fbb5 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$revertPartialWritesAndClose$2.apply$mcV$sp(DiskBlockObjectWriter.scala:215)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1346)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:212)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:237)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:102)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
19/01/24 22:23:50 ERROR BypassMergeSortShuffleWriter: Error while deleting file C:\Users\yanis\AppData\Local\Temp\blockmgr-7f1c56b0-88a3-4371-be25-4367d330f1cb\2e\temp_shuffle_e20300ec-4f68-4968-b83a-97447086fbb5
19/01/24 22:23:50 ERROR Executor: Exception in task 0.0 in stage 21.0 (TID 26)
java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-7f1c56b0-88a3-4371-be25-4367d330f1cb\2e\temp_shuffle_e20300ec-4f68-4968-b83a-97447086fbb5 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
19/01/24 22:23:50 WARN TaskSetManager: Lost task 0.0 in stage 21.0 (TID 26, localhost, executor driver): java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-7f1c56b0-88a3-4371-be25-4367d330f1cb\2e\temp_shuffle_e20300ec-4f68-4968-b83a-97447086fbb5 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

19/01/24 22:23:50 ERROR TaskSetManager: Task 0 in stage 21.0 failed 1 times; aborting job
19/01/24 22:23:50 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/01/24 22:23:50 INFO TaskSchedulerImpl: Cancelling stage 21
19/01/24 22:23:50 INFO DAGScheduler: ShuffleMapStage 21 (collect at utils.scala:200) failed in 0,301 s due to Job aborted due to stage failure: Task 0 in stage 21.0 failed 1 times, most recent failure: Lost task 0.0 in stage 21.0 (TID 26, localhost, executor driver): java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-7f1c56b0-88a3-4371-be25-4367d330f1cb\2e\temp_shuffle_e20300ec-4f68-4968-b83a-97447086fbb5 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
19/01/24 22:23:50 INFO DAGScheduler: Job 12 failed: collect at utils.scala:200, took 0,345479 s
19/01/24 22:23:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 22:23:55 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e42bfd501
19/01/24 22:23:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e42bfd501` AS `zzz5`
WHERE (0 = 1)
19/01/24 22:23:55 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e426004266
19/01/24 22:23:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e426004266` AS `zzz6`
WHERE (0 = 1)
19/01/24 22:23:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e42bfd501`
19/01/24 22:23:56 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 22:23:56 INFO DAGScheduler: Registering RDD 78 (flatMap at CountVectorizer.scala:163)
19/01/24 22:23:56 INFO DAGScheduler: Got job 13 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 22:23:56 INFO DAGScheduler: Final stage: ResultStage 24 (count at CountVectorizer.scala:176)
19/01/24 22:23:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
19/01/24 22:23:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
19/01/24 22:23:56 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[78] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 22:23:56 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 28.5 KB, free 361.4 MB)
19/01/24 22:23:56 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 13.0 KB, free 361.4 MB)
19/01/24 22:23:56 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:55685 (size: 13.0 KB, free: 362.5 MB)
19/01/24 22:23:56 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/01/24 22:23:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[78] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 22:23:56 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/01/24 22:23:56 WARN TaskSetManager: Stage 23 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:23:56 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:23:56 INFO Executor: Running task 0.0 in stage 23.0 (TID 27)
19/01/24 22:23:56 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 22:23:56 INFO CodeGenerator: Code generated in 24.260189 ms
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 553
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 554
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 549
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 487
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 551
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 547
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 550
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 481
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 552
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 484
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 491
19/01/24 22:23:56 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:55685 in memory (size: 3.6 KB, free: 362.5 MB)
19/01/24 22:23:56 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:55685 in memory (size: 3.7 KB, free: 362.5 MB)
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 543
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 492
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 482
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 546
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 485
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 548
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 489
19/01/24 22:23:56 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:55685 in memory (size: 7.7 KB, free: 362.5 MB)
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 545
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 544
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 493
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 488
19/01/24 22:23:56 INFO ContextCleaner: Cleaned shuffle 6
19/01/24 22:23:56 INFO ContextCleaner: Cleaned shuffle 5
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 490
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 542
19/01/24 22:23:56 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:55685 in memory (size: 7.7 KB, free: 362.6 MB)
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 454
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 483
19/01/24 22:23:56 INFO ContextCleaner: Cleaned accumulator 486
19/01/24 22:23:56 ERROR Executor: Exception in task 0.0 in stage 23.0 (TID 27)
java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-7f1c56b0-88a3-4371-be25-4367d330f1cb\1b\shuffle_7_0_0.data.b28b9019-9046-42b4-975c-307ff435a3c2 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$1.writeNext(WritablePartitionedPairCollection.scala:56)
	at org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:699)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
19/01/24 22:23:56 WARN TaskSetManager: Lost task 0.0 in stage 23.0 (TID 27, localhost, executor driver): java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-7f1c56b0-88a3-4371-be25-4367d330f1cb\1b\shuffle_7_0_0.data.b28b9019-9046-42b4-975c-307ff435a3c2 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$1.writeNext(WritablePartitionedPairCollection.scala:56)
	at org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:699)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

19/01/24 22:23:56 ERROR TaskSetManager: Task 0 in stage 23.0 failed 1 times; aborting job
19/01/24 22:23:56 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/01/24 22:23:56 INFO TaskSchedulerImpl: Cancelling stage 23
19/01/24 22:23:56 INFO DAGScheduler: ShuffleMapStage 23 (flatMap at CountVectorizer.scala:163) failed in 0,564 s due to Job aborted due to stage failure: Task 0 in stage 23.0 failed 1 times, most recent failure: Lost task 0.0 in stage 23.0 (TID 27, localhost, executor driver): java.io.FileNotFoundException: C:\Users\yanis\AppData\Local\Temp\blockmgr-7f1c56b0-88a3-4371-be25-4367d330f1cb\1b\shuffle_7_0_0.data.b28b9019-9046-42b4-975c-307ff435a3c2 (The system cannot find the path specified)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(Unknown Source)
	at java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)
	at org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$1.writeNext(WritablePartitionedPairCollection.scala:56)
	at org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:699)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
19/01/24 22:23:56 INFO DAGScheduler: Job 13 failed: count at CountVectorizer.scala:176, took 0,593842 s
19/01/24 22:25:03 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 22:25:03 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 22:25:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 22:25:03 INFO MemoryStore: MemoryStore cleared
19/01/24 22:25:03 INFO BlockManager: BlockManager stopped
19/01/24 22:25:03 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 22:25:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 22:25:03 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-684f762e-3435-4276-bb69-c1166628a7af\userFiles-73ad9615-25b9-4f5c-b617-4063213d802b
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-684f762e-3435-4276-bb69-c1166628a7af\userFiles-73ad9615-25b9-4f5c-b617-4063213d802b
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 22:25:03 INFO SparkContext: Successfully stopped SparkContext
19/01/24 22:25:03 INFO ShutdownHookManager: Shutdown hook called
19/01/24 22:25:03 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-684f762e-3435-4276-bb69-c1166628a7af
19/01/24 22:25:04 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-684f762e-3435-4276-bb69-c1166628a7af
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-684f762e-3435-4276-bb69-c1166628a7af
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 22:25:04 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-684f762e-3435-4276-bb69-c1166628a7af\userFiles-73ad9615-25b9-4f5c-b617-4063213d802b
19/01/24 22:25:04 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-684f762e-3435-4276-bb69-c1166628a7af\userFiles-73ad9615-25b9-4f5c-b617-4063213d802b
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-684f762e-3435-4276-bb69-c1166628a7af\userFiles-73ad9615-25b9-4f5c-b617-4063213d802b
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 22:25:20 INFO SparkContext: Running Spark version 2.2.0
19/01/24 22:25:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 22:25:20 INFO SparkContext: Submitted application: sparklyr
19/01/24 22:25:21 INFO SecurityManager: Changing view acls to: yanis
19/01/24 22:25:21 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 22:25:21 INFO SecurityManager: Changing view acls groups to: 
19/01/24 22:25:21 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 22:25:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 22:25:21 INFO Utils: Successfully started service 'sparkDriver' on port 56410.
19/01/24 22:25:21 INFO SparkEnv: Registering MapOutputTracker
19/01/24 22:25:21 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 22:25:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 22:25:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 22:25:21 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-859c8068-0c0e-403e-92ac-df36e77e4031
19/01/24 22:25:21 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 22:25:21 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 22:25:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 22:25:21 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 22:25:21 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:56410/jars/sparklyr-2.2-2.11.jar with timestamp 1548365121516
19/01/24 22:25:21 INFO Executor: Starting executor ID driver on host localhost
19/01/24 22:25:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56451.
19/01/24 22:25:21 INFO NettyBlockTransferService: Server created on 127.0.0.1:56451
19/01/24 22:25:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 22:25:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56451, None)
19/01/24 22:25:21 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:56451 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 56451, None)
19/01/24 22:25:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56451, None)
19/01/24 22:25:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56451, None)
19/01/24 22:25:21 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 22:25:21 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 22:25:21 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 22:25:21 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 22:25:22 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 22:25:23 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 22:25:23 INFO ObjectStore: ObjectStore, initialize called
19/01/24 22:25:23 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 22:25:23 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 22:25:24 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 22:25:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 22:25:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 22:25:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 22:25:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 22:25:26 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 22:25:26 INFO ObjectStore: Initialized ObjectStore
19/01/24 22:25:26 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 22:25:26 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 22:25:26 INFO HiveMetaStore: Added admin role in metastore
19/01/24 22:25:26 INFO HiveMetaStore: Added public role in metastore
19/01/24 22:25:26 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 22:25:26 INFO HiveMetaStore: 0: get_all_databases
19/01/24 22:25:26 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 22:25:26 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 22:25:26 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 22:25:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 22:25:26 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/eb9bca1c-14e7-4593-931c-31e390dc619f_resources
19/01/24 22:25:26 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/eb9bca1c-14e7-4593-931c-31e390dc619f
19/01/24 22:25:26 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/eb9bca1c-14e7-4593-931c-31e390dc619f
19/01/24 22:25:26 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/eb9bca1c-14e7-4593-931c-31e390dc619f/_tmp_space.db
19/01/24 22:25:26 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 22:25:26 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:25:26 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:25:26 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 22:25:26 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 22:25:26 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 22:25:27 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/89b29371-6681-47bf-9342-fd1c9171e94d_resources
19/01/24 22:25:27 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/89b29371-6681-47bf-9342-fd1c9171e94d
19/01/24 22:25:27 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/89b29371-6681-47bf-9342-fd1c9171e94d
19/01/24 22:25:27 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/89b29371-6681-47bf-9342-fd1c9171e94d/_tmp_space.db
19/01/24 22:25:27 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 22:25:27 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 22:25:27 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 22:25:28 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:25:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:25:28 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:25:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:25:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 22:25:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 22:25:30 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 22:25:30 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 22:25:30 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 22:25:30 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:25:30 INFO DAGScheduler: Missing parents: List()
19/01/24 22:25:30 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 22:25:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 22:25:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 22:25:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:56451 (size: 3.4 KB, free: 366.3 MB)
19/01/24 22:25:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 22:25:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 22:25:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 22:25:30 INFO Executor: Fetching spark://127.0.0.1:56410/jars/sparklyr-2.2-2.11.jar with timestamp 1548365121516
19/01/24 22:25:30 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:56410 after 21 ms (0 ms spent in bootstraps)
19/01/24 22:25:30 INFO Utils: Fetching spark://127.0.0.1:56410/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-d9e95ef0-5d51-4784-9dcf-a538472dc3ff\userFiles-8b9501e7-9d80-4a7d-9364-2f796e4c84ca\fetchFileTemp3589993851260054360.tmp
19/01/24 22:25:31 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-d9e95ef0-5d51-4784-9dcf-a538472dc3ff/userFiles-8b9501e7-9d80-4a7d-9364-2f796e4c84ca/sparklyr-2.2-2.11.jar to class loader
19/01/24 22:25:31 INFO CodeGenerator: Code generated in 223.349019 ms
19/01/24 22:25:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/01/24 22:25:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1049 ms on localhost (executor driver) (1/1)
19/01/24 22:25:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 22:25:31 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 1,083 s
19/01/24 22:25:31 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 1,320350 s
19/01/24 22:25:31 INFO SparkSqlParser: Parsing command: reviews
19/01/24 22:25:32 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews`
19/01/24 22:25:32 INFO SparkSqlParser: Parsing command: `reviews`
19/01/24 22:25:32 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:56451 in memory (size: 3.4 KB, free: 366.3 MB)
19/01/24 22:25:32 INFO CodeGenerator: Code generated in 17.485672 ms
19/01/24 22:25:32 INFO CodeGenerator: Code generated in 10.736682 ms
19/01/24 22:25:32 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 22:25:32 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 22:25:32 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 22:25:32 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 22:25:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 22:25:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 22:25:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 22:25:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 22:25:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:56451 (size: 7.7 KB, free: 366.3 MB)
19/01/24 22:25:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 22:25:32 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:25:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 22:25:32 INFO CodeGenerator: Code generated in 9.673297 ms
19/01/24 22:25:32 INFO CodeGenerator: Code generated in 29.845875 ms
19/01/24 22:25:32 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.5 MB)
19/01/24 22:25:32 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:56451 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 22:25:32 INFO CodeGenerator: Code generated in 5.438358 ms
19/01/24 22:25:32 INFO CodeGenerator: Code generated in 22.134879 ms
19/01/24 22:25:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 460 ms on localhost (executor driver) (1/1)
19/01/24 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 22:25:32 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,461 s
19/01/24 22:25:32 INFO DAGScheduler: looking for newly runnable stages
19/01/24 22:25:32 INFO DAGScheduler: running: Set()
19/01/24 22:25:32 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 22:25:32 INFO DAGScheduler: failed: Set()
19/01/24 22:25:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 22:25:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 22:25:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 22:25:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:56451 (size: 3.7 KB, free: 364.5 MB)
19/01/24 22:25:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 22:25:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
19/01/24 22:25:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1624 bytes result sent to driver
19/01/24 22:25:33 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 22:25:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:56451 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 152 ms on localhost (executor driver) (1/1)
19/01/24 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 22:25:33 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 22:25:33 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,154 s
19/01/24 22:25:33 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,670055 s
19/01/24 22:25:33 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews`
19/01/24 22:25:33 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:25:33 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:25:33 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 22:25:33 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 22:25:33 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 22:25:33 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 22:25:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 22:25:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 22:25:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 22:25:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.4 MB)
19/01/24 22:25:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:56451 (size: 7.7 KB, free: 364.5 MB)
19/01/24 22:25:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 22:25:33 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:25:33 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 22:25:33 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 22:25:33 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
19/01/24 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 43 ms on localhost (executor driver) (1/1)
19/01/24 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 22:25:33 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,044 s
19/01/24 22:25:33 INFO DAGScheduler: looking for newly runnable stages
19/01/24 22:25:33 INFO DAGScheduler: running: Set()
19/01/24 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 22:25:33 INFO DAGScheduler: failed: Set()
19/01/24 22:25:33 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 22:25:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 22:25:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 22:25:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:56451 (size: 3.7 KB, free: 364.5 MB)
19/01/24 22:25:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:33 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 22:25:33 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:25:33 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
19/01/24 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
19/01/24 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 22:25:33 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,006 s
19/01/24 22:25:33 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,070671 s
19/01/24 22:25:33 INFO CodeGenerator: Code generated in 6.44376 ms
19/01/24 22:25:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews` AS `zzz7`
WHERE (0 = 1)
19/01/24 22:25:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews`
19/01/24 22:25:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e441057e58
19/01/24 22:25:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e441057e58` AS `zzz8`
WHERE (0 = 1)
19/01/24 22:25:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e43a322341
19/01/24 22:25:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e43a322341` AS `zzz9`
WHERE (0 = 1)
19/01/24 22:25:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e441057e58`
19/01/24 22:25:38 INFO CodeGenerator: Code generated in 36.390649 ms
19/01/24 22:25:38 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 22:25:38 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 22:25:38 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 22:25:38 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 22:25:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 22:25:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 22:25:38 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 22:25:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 22:25:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 22:25:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:56451 (size: 13.0 KB, free: 364.5 MB)
19/01/24 22:25:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:38 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 22:25:38 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:25:38 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 22:25:38 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 22:25:38 INFO CodeGenerator: Code generated in 17.958652 ms
19/01/24 22:25:38 INFO CodeGenerator: Code generated in 18.397352 ms
19/01/24 22:25:38 INFO CodeGenerator: Code generated in 14.039884 ms
19/01/24 22:25:38 INFO CodeGenerator: Code generated in 18.547233 ms
19/01/24 22:25:39 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:56451 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 22:25:39 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 22:25:39 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:56451 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 22:25:40 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1951 bytes result sent to driver
19/01/24 22:25:40 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1295 ms on localhost (executor driver) (1/1)
19/01/24 22:25:40 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 22:25:40 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 1,295 s
19/01/24 22:25:40 INFO DAGScheduler: looking for newly runnable stages
19/01/24 22:25:40 INFO DAGScheduler: running: Set()
19/01/24 22:25:40 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 22:25:40 INFO DAGScheduler: failed: Set()
19/01/24 22:25:40 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 22:25:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 22:25:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 22:25:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:56451 (size: 1887.0 B, free: 364.5 MB)
19/01/24 22:25:40 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:40 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 22:25:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 22:25:40 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 22:25:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:25:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:25:40 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 22:25:40 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:56451 (size: 686.3 KB, free: 363.8 MB)
19/01/24 22:25:40 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1787 bytes result sent to driver
19/01/24 22:25:40 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 135 ms on localhost (executor driver) (1/1)
19/01/24 22:25:40 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 22:25:40 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,136 s
19/01/24 22:25:40 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 1,470501 s
19/01/24 22:25:40 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 22:25:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 22:25:40 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 22:25:40 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 22:25:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 22:25:40 INFO DAGScheduler: Missing parents: List()
19/01/24 22:25:40 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 22:25:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.7 MB)
19/01/24 22:25:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.7 MB)
19/01/24 22:25:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:56451 (size: 2.2 KB, free: 363.8 MB)
19/01/24 22:25:40 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:40 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 22:25:40 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 22:25:40 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 22:25:40 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 22:25:40 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 22:25:40 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 67 ms on localhost (executor driver) (1/1)
19/01/24 22:25:40 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 22:25:40 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,067 s
19/01/24 22:25:40 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,086118 s
19/01/24 22:25:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 22:25:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.5 MB)
19/01/24 22:25:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:56451 (size: 89.8 KB, free: 363.7 MB)
19/01/24 22:25:40 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 22:25:40 INFO CodeGenerator: Code generated in 30.316666 ms
19/01/24 22:25:40 INFO Instrumentation: NaiveBayes-naive_bayes_56e46e777e22-1623139651-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/01/24 22:25:40 INFO Instrumentation: NaiveBayes-naive_bayes_56e46e777e22-1623139651-1: {"smoothing":1.0,"featuresCol":"vectorizer_output","modelType":"multinomial","labelCol":"Sentiment","predictionCol":"prediction","rawPredictionCol":"rawPrediction","probabilityCol":"probability"}
19/01/24 22:25:40 INFO CodeGenerator: Code generated in 24.2095 ms
19/01/24 22:25:40 INFO SparkContext: Starting job: head at NaiveBayes.scala:154
19/01/24 22:25:40 INFO DAGScheduler: Got job 5 (head at NaiveBayes.scala:154) with 1 output partitions
19/01/24 22:25:40 INFO DAGScheduler: Final stage: ResultStage 9 (head at NaiveBayes.scala:154)
19/01/24 22:25:40 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:25:40 INFO DAGScheduler: Missing parents: List()
19/01/24 22:25:40 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154), which has no missing parents
19/01/24 22:25:40 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 113.1 KB, free 362.4 MB)
19/01/24 22:25:40 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 72.9 KB, free 362.4 MB)
19/01/24 22:25:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:56451 (size: 72.9 KB, free: 363.6 MB)
19/01/24 22:25:40 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at head at NaiveBayes.scala:154) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:40 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 22:25:40 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:25:40 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:25:40 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 22:25:40 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 22:25:40 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 1743 bytes result sent to driver
19/01/24 22:25:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 76 ms on localhost (executor driver) (1/1)
19/01/24 22:25:40 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 22:25:40 INFO DAGScheduler: ResultStage 9 (head at NaiveBayes.scala:154) finished in 0,076 s
19/01/24 22:25:40 INFO DAGScheduler: Job 5 finished: head at NaiveBayes.scala:154, took 0,088762 s
19/01/24 22:25:40 INFO CodeGenerator: Code generated in 5.750153 ms
19/01/24 22:25:40 INFO Instrumentation: NaiveBayes-naive_bayes_56e46e777e22-1623139651-1: {"numFeatures":8098}
19/01/24 22:25:40 INFO CodeGenerator: Code generated in 24.563961 ms
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 176
19/01/24 22:25:40 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:56451 in memory (size: 1887.0 B, free: 363.6 MB)
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 261
19/01/24 22:25:40 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:56451 in memory (size: 13.0 KB, free: 363.6 MB)
19/01/24 22:25:40 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:56451 in memory (size: 2.2 KB, free: 363.6 MB)
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 257
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 177
19/01/24 22:25:40 INFO BlockManager: Removing RDD 30
19/01/24 22:25:40 INFO ContextCleaner: Cleaned RDD 30
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 174
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 262
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 259
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 175
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 258
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 260
19/01/24 22:25:40 INFO SparkContext: Starting job: collect at NaiveBayes.scala:174
19/01/24 22:25:40 INFO DAGScheduler: Registering RDD 43 (map at NaiveBayes.scala:162)
19/01/24 22:25:40 INFO DAGScheduler: Got job 6 (collect at NaiveBayes.scala:174) with 1 output partitions
19/01/24 22:25:40 INFO DAGScheduler: Final stage: ResultStage 11 (collect at NaiveBayes.scala:174)
19/01/24 22:25:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/01/24 22:25:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/01/24 22:25:40 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162), which has no missing parents
19/01/24 22:25:40 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 22:25:40 INFO ContextCleaner: Cleaned accumulator 178
19/01/24 22:25:40 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:56451 in memory (size: 72.9 KB, free: 364.4 MB)
19/01/24 22:25:40 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 243.7 KB, free 363.0 MB)
19/01/24 22:25:40 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 76.0 KB, free 363.0 MB)
19/01/24 22:25:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:56451 (size: 76.0 KB, free: 364.3 MB)
19/01/24 22:25:40 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[43] at map at NaiveBayes.scala:162) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:40 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 22:25:41 WARN TaskSetManager: Stage 10 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:25:41 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:25:41 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 22:25:41 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 22:25:41 INFO CodeGenerator: Code generated in 10.400818 ms
19/01/24 22:25:41 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1951 bytes result sent to driver
19/01/24 22:25:41 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 570 ms on localhost (executor driver) (1/1)
19/01/24 22:25:41 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 22:25:41 INFO DAGScheduler: ShuffleMapStage 10 (map at NaiveBayes.scala:162) finished in 0,571 s
19/01/24 22:25:41 INFO DAGScheduler: looking for newly runnable stages
19/01/24 22:25:41 INFO DAGScheduler: running: Set()
19/01/24 22:25:41 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/01/24 22:25:41 INFO DAGScheduler: failed: Set()
19/01/24 22:25:41 INFO DAGScheduler: Submitting ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163), which has no missing parents
19/01/24 22:25:41 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 244.4 KB, free 362.7 MB)
19/01/24 22:25:41 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 76.4 KB, free 362.6 MB)
19/01/24 22:25:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:56451 (size: 76.4 KB, free: 364.2 MB)
19/01/24 22:25:41 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/01/24 22:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRDD[44] at aggregateByKey at NaiveBayes.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 22:25:41 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 22:25:41 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 22:25:41 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 22:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 22:25:41 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 132363 bytes result sent to driver
19/01/24 22:25:41 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 14 ms on localhost (executor driver) (1/1)
19/01/24 22:25:41 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 22:25:41 INFO DAGScheduler: ResultStage 11 (collect at NaiveBayes.scala:174) finished in 0,014 s
19/01/24 22:25:41 INFO DAGScheduler: Job 6 finished: collect at NaiveBayes.scala:174, took 0,611055 s
19/01/24 22:25:41 INFO Instrumentation: NaiveBayes-naive_bayes_56e46e777e22-1623139651-1: {"numClasses":2}
19/01/24 22:25:41 INFO Instrumentation: NaiveBayes-naive_bayes_56e46e777e22-1623139651-1: training finished
19/01/24 22:26:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e43a322341`
19/01/24 22:26:27 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e44ae34726
19/01/24 22:26:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e44ae34726` AS `zzz10`
WHERE (0 = 1)
19/01/24 22:26:27 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e44ae34726`
GROUP BY `Sentiment`, `Prediction`
19/01/24 22:26:27 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:26:27 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:26:27 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e44ae34726`
GROUP BY `Sentiment`, `Prediction`
19/01/24 22:26:27 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:26:27 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:26:27 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e44ae34726`
GROUP BY `Sentiment`, `Prediction`
LIMIT 11
19/01/24 22:26:27 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:26:27 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:26:27 INFO CodeGenerator: Code generated in 19.435575 ms
19/01/24 22:26:27 INFO CodeGenerator: Code generated in 49.60309 ms
19/01/24 22:26:27 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 22:26:27 INFO DAGScheduler: Registering RDD 47 (collect at utils.scala:200)
19/01/24 22:26:27 INFO DAGScheduler: Got job 7 (collect at utils.scala:200) with 1 output partitions
19/01/24 22:26:27 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:200)
19/01/24 22:26:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/01/24 22:26:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/01/24 22:26:27 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[47] at collect at utils.scala:200), which has no missing parents
19/01/24 22:26:27 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 254.9 KB, free 362.4 MB)
19/01/24 22:26:27 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 115.8 KB, free 362.3 MB)
19/01/24 22:26:27 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:56451 (size: 115.8 KB, free: 364.1 MB)
19/01/24 22:26:27 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 22:26:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[47] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 22:26:27 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 22:26:27 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:26:27 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:26:27 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 22:26:27 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 22:26:27 INFO CodeGenerator: Code generated in 7.081207 ms
19/01/24 22:26:27 INFO CodeGenerator: Code generated in 5.53609 ms
19/01/24 22:26:27 INFO CodeGenerator: Code generated in 6.444124 ms
19/01/24 22:26:27 INFO CodeGenerator: Code generated in 11.33985 ms
19/01/24 22:26:27 INFO CodeGenerator: Code generated in 7.851395 ms
19/01/24 22:26:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/01/24 22:26:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/01/24 22:26:28 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 2263 bytes result sent to driver
19/01/24 22:26:28 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 414 ms on localhost (executor driver) (1/1)
19/01/24 22:26:28 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 22:26:28 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:200) finished in 0,415 s
19/01/24 22:26:28 INFO DAGScheduler: looking for newly runnable stages
19/01/24 22:26:28 INFO DAGScheduler: running: Set()
19/01/24 22:26:28 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/01/24 22:26:28 INFO DAGScheduler: failed: Set()
19/01/24 22:26:28 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 22:26:28 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 236.1 KB, free 362.1 MB)
19/01/24 22:26:28 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 108.9 KB, free 361.9 MB)
19/01/24 22:26:28 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:56451 (size: 108.9 KB, free: 364.0 MB)
19/01/24 22:26:28 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/01/24 22:26:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 22:26:28 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 22:26:28 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 22:26:28 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:26:28 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 2584 bytes result sent to driver
19/01/24 22:26:28 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 12 ms on localhost (executor driver) (1/1)
19/01/24 22:26:28 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 22:26:28 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:200) finished in 0,012 s
19/01/24 22:26:28 INFO DAGScheduler: Job 7 finished: collect at utils.scala:200, took 0,453512 s
19/01/24 22:26:28 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 22:26:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 149 bytes
19/01/24 22:26:28 INFO DAGScheduler: Got job 8 (collect at utils.scala:200) with 4 output partitions
19/01/24 22:26:28 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:200)
19/01/24 22:26:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/01/24 22:26:28 INFO DAGScheduler: Missing parents: List()
19/01/24 22:26:28 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 22:26:28 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 236.1 KB, free 361.7 MB)
19/01/24 22:26:28 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 108.9 KB, free 361.6 MB)
19/01/24 22:26:28 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:56451 (size: 108.9 KB, free: 363.9 MB)
19/01/24 22:26:28 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 22:26:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
19/01/24 22:26:28 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/01/24 22:26:28 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
19/01/24 22:26:28 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
19/01/24 22:26:28 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
19/01/24 22:26:28 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 16, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
19/01/24 22:26:28 INFO Executor: Running task 0.0 in stage 15.0 (TID 13)
19/01/24 22:26:28 INFO Executor: Running task 1.0 in stage 15.0 (TID 14)
19/01/24 22:26:28 INFO Executor: Running task 3.0 in stage 15.0 (TID 16)
19/01/24 22:26:28 INFO Executor: Running task 2.0 in stage 15.0 (TID 15)
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:26:28 INFO Executor: Finished task 0.0 in stage 15.0 (TID 13). 2558 bytes result sent to driver
19/01/24 22:26:28 INFO Executor: Finished task 3.0 in stage 15.0 (TID 16). 2558 bytes result sent to driver
19/01/24 22:26:28 INFO Executor: Finished task 1.0 in stage 15.0 (TID 14). 2558 bytes result sent to driver
19/01/24 22:26:28 INFO Executor: Finished task 2.0 in stage 15.0 (TID 15). 2558 bytes result sent to driver
19/01/24 22:26:28 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 16) in 16 ms on localhost (executor driver) (1/4)
19/01/24 22:26:28 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 13) in 16 ms on localhost (executor driver) (2/4)
19/01/24 22:26:28 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 14) in 16 ms on localhost (executor driver) (3/4)
19/01/24 22:26:28 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 15) in 16 ms on localhost (executor driver) (4/4)
19/01/24 22:26:28 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 22:26:28 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:200) finished in 0,018 s
19/01/24 22:26:28 INFO DAGScheduler: Job 8 finished: collect at utils.scala:200, took 0,028623 s
19/01/24 22:26:28 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 22:26:28 INFO DAGScheduler: Got job 9 (collect at utils.scala:200) with 3 output partitions
19/01/24 22:26:28 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:200)
19/01/24 22:26:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
19/01/24 22:26:28 INFO DAGScheduler: Missing parents: List()
19/01/24 22:26:28 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[50] at collect at utils.scala:200), which has no missing parents
19/01/24 22:26:28 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 236.1 KB, free 361.4 MB)
19/01/24 22:26:28 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 108.8 KB, free 361.3 MB)
19/01/24 22:26:28 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:56451 (size: 108.8 KB, free: 363.8 MB)
19/01/24 22:26:28 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/01/24 22:26:28 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 17 (MapPartitionsRDD[50] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(5, 6, 7))
19/01/24 22:26:28 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
19/01/24 22:26:28 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 17, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
19/01/24 22:26:28 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 5, ANY, 4726 bytes)
19/01/24 22:26:28 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 19, localhost, executor driver, partition 7, ANY, 4726 bytes)
19/01/24 22:26:28 INFO Executor: Running task 1.0 in stage 17.0 (TID 17)
19/01/24 22:26:28 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
19/01/24 22:26:28 INFO Executor: Running task 2.0 in stage 17.0 (TID 19)
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:26:28 INFO Executor: Finished task 1.0 in stage 17.0 (TID 17). 2558 bytes result sent to driver
19/01/24 22:26:28 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 17) in 11 ms on localhost (executor driver) (1/3)
19/01/24 22:26:28 INFO Executor: Finished task 2.0 in stage 17.0 (TID 19). 2578 bytes result sent to driver
19/01/24 22:26:28 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 2591 bytes result sent to driver
19/01/24 22:26:28 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 19) in 15 ms on localhost (executor driver) (2/3)
19/01/24 22:26:28 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 15 ms on localhost (executor driver) (3/3)
19/01/24 22:26:28 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 22:26:28 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:200) finished in 0,015 s
19/01/24 22:26:28 INFO DAGScheduler: Job 9 finished: collect at utils.scala:200, took 0,025326 s
19/01/24 22:26:28 INFO CodeGenerator: Code generated in 5.061651 ms
19/01/24 22:26:28 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e44ae34726`
GROUP BY `Sentiment`, `Prediction`
19/01/24 22:26:28 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:26:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:26:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 22:26:28 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:26:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:26:28 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:26:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:26:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 22:26:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 22:26:28 INFO CodeGenerator: Code generated in 13.567998 ms
19/01/24 22:26:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 22:26:28 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:26:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:26:28 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:26:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:26:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 22:26:28 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 22:26:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 22:26:29 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:26:29 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:26:29 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:26:29 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:26:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 22:26:29 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 22:27:34 INFO SparkContext: Invoking stop() from shutdown hook
19/01/24 22:27:34 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:56451 in memory (size: 76.0 KB, free: 363.9 MB)
19/01/24 22:27:34 INFO ContextCleaner: Cleaned accumulator 346
19/01/24 22:27:34 INFO ContextCleaner: Cleaned accumulator 349
19/01/24 22:27:34 INFO ContextCleaner: Cleaned accumulator 256
19/01/24 22:27:34 INFO ContextCleaner: Cleaned accumulator 351
19/01/24 22:27:34 INFO ContextCleaner: Cleaned accumulator 255
19/01/24 22:27:34 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/01/24 22:27:34 INFO ContextCleaner: Cleaned shuffle 3
19/01/24 22:27:34 INFO ContextCleaner: Cleaned accumulator 287
19/01/24 22:27:34 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:56451 in memory (size: 76.4 KB, free: 364.0 MB)
19/01/24 22:27:34 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:56451 in memory (size: 108.9 KB, free: 364.1 MB)
19/01/24 22:27:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/01/24 22:27:34 INFO MemoryStore: MemoryStore cleared
19/01/24 22:27:34 INFO BlockManager: BlockManager stopped
19/01/24 22:27:34 INFO BlockManagerMaster: BlockManagerMaster stopped
19/01/24 22:27:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/01/24 22:27:34 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-d9e95ef0-5d51-4784-9dcf-a538472dc3ff\userFiles-8b9501e7-9d80-4a7d-9364-2f796e4c84ca
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-d9e95ef0-5d51-4784-9dcf-a538472dc3ff\userFiles-8b9501e7-9d80-4a7d-9364-2f796e4c84ca
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 22:27:34 INFO SparkContext: Successfully stopped SparkContext
19/01/24 22:27:34 INFO ShutdownHookManager: Shutdown hook called
19/01/24 22:27:34 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-d9e95ef0-5d51-4784-9dcf-a538472dc3ff\userFiles-8b9501e7-9d80-4a7d-9364-2f796e4c84ca
19/01/24 22:27:34 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-d9e95ef0-5d51-4784-9dcf-a538472dc3ff\userFiles-8b9501e7-9d80-4a7d-9364-2f796e4c84ca
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-d9e95ef0-5d51-4784-9dcf-a538472dc3ff\userFiles-8b9501e7-9d80-4a7d-9364-2f796e4c84ca
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 22:27:34 INFO ShutdownHookManager: Deleting directory C:\Users\yanis\AppData\Local\Temp\spark-d9e95ef0-5d51-4784-9dcf-a538472dc3ff
19/01/24 22:27:34 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\yanis\AppData\Local\Temp\spark-d9e95ef0-5d51-4784-9dcf-a538472dc3ff
java.io.IOException: Failed to delete: C:\Users\yanis\AppData\Local\Temp\spark-d9e95ef0-5d51-4784-9dcf-a538472dc3ff
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/01/24 22:27:41 INFO SparkContext: Running Spark version 2.2.0
19/01/24 22:27:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/24 22:27:42 INFO SparkContext: Submitted application: sparklyr
19/01/24 22:27:42 INFO SecurityManager: Changing view acls to: yanis
19/01/24 22:27:42 INFO SecurityManager: Changing modify acls to: yanis
19/01/24 22:27:42 INFO SecurityManager: Changing view acls groups to: 
19/01/24 22:27:42 INFO SecurityManager: Changing modify acls groups to: 
19/01/24 22:27:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yanis); groups with view permissions: Set(); users  with modify permissions: Set(yanis); groups with modify permissions: Set()
19/01/24 22:27:42 INFO Utils: Successfully started service 'sparkDriver' on port 56523.
19/01/24 22:27:42 INFO SparkEnv: Registering MapOutputTracker
19/01/24 22:27:42 INFO SparkEnv: Registering BlockManagerMaster
19/01/24 22:27:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/01/24 22:27:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/01/24 22:27:42 INFO DiskBlockManager: Created local directory at C:\Users\yanis\AppData\Local\Temp\blockmgr-abed489e-134b-4235-935a-9236dc328f89
19/01/24 22:27:42 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/01/24 22:27:42 INFO SparkEnv: Registering OutputCommitCoordinator
19/01/24 22:27:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/01/24 22:27:42 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/01/24 22:27:42 INFO SparkContext: Added JAR file:/C:/Users/yanis/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:56523/jars/sparklyr-2.2-2.11.jar with timestamp 1548365262657
19/01/24 22:27:42 INFO Executor: Starting executor ID driver on host localhost
19/01/24 22:27:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56564.
19/01/24 22:27:42 INFO NettyBlockTransferService: Server created on 127.0.0.1:56564
19/01/24 22:27:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/01/24 22:27:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56564, None)
19/01/24 22:27:42 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:56564 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 56564, None)
19/01/24 22:27:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56564, None)
19/01/24 22:27:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56564, None)
19/01/24 22:27:43 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/01/24 22:27:43 INFO SharedState: loading hive config file: file:/C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/01/24 22:27:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/01/24 22:27:43 INFO SharedState: Warehouse path is 'C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/01/24 22:27:43 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/01/24 22:27:44 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/01/24 22:27:44 INFO ObjectStore: ObjectStore, initialize called
19/01/24 22:27:44 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/01/24 22:27:44 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/01/24 22:27:45 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/01/24 22:27:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 22:27:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 22:27:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 22:27:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 22:27:46 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/01/24 22:27:46 INFO ObjectStore: Initialized ObjectStore
19/01/24 22:27:46 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/01/24 22:27:47 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/01/24 22:27:47 INFO HiveMetaStore: Added admin role in metastore
19/01/24 22:27:47 INFO HiveMetaStore: Added public role in metastore
19/01/24 22:27:47 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/01/24 22:27:47 INFO HiveMetaStore: 0: get_all_databases
19/01/24 22:27:47 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_all_databases	
19/01/24 22:27:47 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/01/24 22:27:47 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/01/24 22:27:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/01/24 22:27:47 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/2949de77-a10c-4d96-b6af-66b586603e81_resources
19/01/24 22:27:47 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/2949de77-a10c-4d96-b6af-66b586603e81
19/01/24 22:27:47 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/2949de77-a10c-4d96-b6af-66b586603e81
19/01/24 22:27:47 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/2949de77-a10c-4d96-b6af-66b586603e81/_tmp_space.db
19/01/24 22:27:47 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 22:27:47 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:27:47 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:27:47 INFO HiveMetaStore: 0: get_database: global_temp
19/01/24 22:27:47 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/01/24 22:27:47 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/01/24 22:27:47 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/Temp/e6aad1d1-b340-4b27-b99a-a52924e5e6ac_resources
19/01/24 22:27:47 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/e6aad1d1-b340-4b27-b99a-a52924e5e6ac
19/01/24 22:27:47 INFO SessionState: Created local directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/e6aad1d1-b340-4b27-b99a-a52924e5e6ac
19/01/24 22:27:47 INFO SessionState: Created HDFS directory: C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/yanis/e6aad1d1-b340-4b27-b99a-a52924e5e6ac/_tmp_space.db
19/01/24 22:27:47 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/yanis/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/01/24 22:27:47 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/01/24 22:27:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 22:27:49 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:27:49 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:27:49 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:27:49 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:27:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 22:27:49 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 22:27:50 INFO SparkContext: Starting job: collect at utils.scala:44
19/01/24 22:27:50 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/01/24 22:27:50 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/01/24 22:27:50 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:27:50 INFO DAGScheduler: Missing parents: List()
19/01/24 22:27:50 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/01/24 22:27:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
19/01/24 22:27:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
19/01/24 22:27:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:56564 (size: 3.4 KB, free: 366.3 MB)
19/01/24 22:27:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/01/24 22:27:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/01/24 22:27:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/01/24 22:27:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/01/24 22:27:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/01/24 22:27:50 INFO Executor: Fetching spark://127.0.0.1:56523/jars/sparklyr-2.2-2.11.jar with timestamp 1548365262657
19/01/24 22:27:50 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:56523 after 16 ms (0 ms spent in bootstraps)
19/01/24 22:27:50 INFO Utils: Fetching spark://127.0.0.1:56523/jars/sparklyr-2.2-2.11.jar to C:\Users\yanis\AppData\Local\Temp\spark-6aa392ae-16cc-41a8-bd7b-3e0037f33f4e\userFiles-4581e8e1-3aee-44e3-b8a4-e87f1fa11811\fetchFileTemp2156967545226720288.tmp
19/01/24 22:27:50 INFO Executor: Adding file:/C:/Users/yanis/AppData/Local/Temp/spark-6aa392ae-16cc-41a8-bd7b-3e0037f33f4e/userFiles-4581e8e1-3aee-44e3-b8a4-e87f1fa11811/sparklyr-2.2-2.11.jar to class loader
19/01/24 22:27:51 INFO CodeGenerator: Code generated in 252.824752 ms
19/01/24 22:27:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/01/24 22:27:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 620 ms on localhost (executor driver) (1/1)
19/01/24 22:27:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/01/24 22:27:51 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,641 s
19/01/24 22:27:51 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,850333 s
19/01/24 22:27:51 INFO SparkSqlParser: Parsing command: reviews_spark
19/01/24 22:27:51 INFO SparkSqlParser: Parsing command: CACHE TABLE `reviews_spark`
19/01/24 22:27:51 INFO SparkSqlParser: Parsing command: `reviews_spark`
19/01/24 22:27:52 INFO CodeGenerator: Code generated in 18.243826 ms
19/01/24 22:27:52 INFO CodeGenerator: Code generated in 13.126744 ms
19/01/24 22:27:52 INFO SparkContext: Starting job: sql at <unknown>:0
19/01/24 22:27:52 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/01/24 22:27:52 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/01/24 22:27:52 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/01/24 22:27:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/01/24 22:27:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/01/24 22:27:52 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/01/24 22:27:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 366.3 MB)
19/01/24 22:27:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 366.3 MB)
19/01/24 22:27:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:56564 (size: 7.7 KB, free: 366.3 MB)
19/01/24 22:27:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/01/24 22:27:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 22:27:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/01/24 22:27:52 WARN TaskSetManager: Stage 1 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:27:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:27:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/01/24 22:27:52 INFO CodeGenerator: Code generated in 10.263702 ms
19/01/24 22:27:52 INFO CodeGenerator: Code generated in 28.948781 ms
19/01/24 22:27:52 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 1865.6 KB, free 364.4 MB)
19/01/24 22:27:52 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:56564 (size: 1865.6 KB, free: 364.5 MB)
19/01/24 22:27:52 INFO CodeGenerator: Code generated in 5.075509 ms
19/01/24 22:27:52 INFO CodeGenerator: Code generated in 22.402913 ms
19/01/24 22:27:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/01/24 22:27:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 459 ms on localhost (executor driver) (1/1)
19/01/24 22:27:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/01/24 22:27:52 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,461 s
19/01/24 22:27:52 INFO DAGScheduler: looking for newly runnable stages
19/01/24 22:27:52 INFO DAGScheduler: running: Set()
19/01/24 22:27:52 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/01/24 22:27:52 INFO DAGScheduler: failed: Set()
19/01/24 22:27:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/01/24 22:27:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 22:27:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 22:27:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:56564 (size: 3.7 KB, free: 364.5 MB)
19/01/24 22:27:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/01/24 22:27:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/01/24 22:27:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/01/24 22:27:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 22:27:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/01/24 22:27:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:27:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/01/24 22:27:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1538 bytes result sent to driver
19/01/24 22:27:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (executor driver) (1/1)
19/01/24 22:27:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/01/24 22:27:52 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,032 s
19/01/24 22:27:52 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,541499 s
19/01/24 22:27:52 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `reviews_spark`
19/01/24 22:27:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:56564 in memory (size: 3.4 KB, free: 364.5 MB)
19/01/24 22:27:52 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:27:52 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 52
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 57
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 58
19/01/24 22:27:52 INFO ContextCleaner: Cleaned shuffle 0
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 63
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 55
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 59
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 51
19/01/24 22:27:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:56564 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 56
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 60
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 54
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 53
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 62
19/01/24 22:27:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:56564 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 61
19/01/24 22:27:52 INFO ContextCleaner: Cleaned accumulator 0
19/01/24 22:27:52 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 22:27:52 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:200)
19/01/24 22:27:52 INFO DAGScheduler: Got job 2 (collect at utils.scala:200) with 1 output partitions
19/01/24 22:27:52 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:200)
19/01/24 22:27:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/01/24 22:27:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/01/24 22:27:52 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200), which has no missing parents
19/01/24 22:27:52 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KB, free 364.5 MB)
19/01/24 22:27:52 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.5 MB)
19/01/24 22:27:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:56564 (size: 7.7 KB, free: 364.5 MB)
19/01/24 22:27:52 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/01/24 22:27:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 22:27:52 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/01/24 22:27:53 WARN TaskSetManager: Stage 3 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:27:53 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:27:53 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/01/24 22:27:53 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 22:27:53 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
19/01/24 22:27:53 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 55 ms on localhost (executor driver) (1/1)
19/01/24 22:27:53 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/01/24 22:27:53 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:200) finished in 0,055 s
19/01/24 22:27:53 INFO DAGScheduler: looking for newly runnable stages
19/01/24 22:27:53 INFO DAGScheduler: running: Set()
19/01/24 22:27:53 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/01/24 22:27:53 INFO DAGScheduler: failed: Set()
19/01/24 22:27:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200), which has no missing parents
19/01/24 22:27:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
19/01/24 22:27:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
19/01/24 22:27:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:56564 (size: 3.7 KB, free: 364.5 MB)
19/01/24 22:27:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/01/24 22:27:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 22:27:53 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/01/24 22:27:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 22:27:53 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/01/24 22:27:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:27:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:27:53 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/01/24 22:27:53 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
19/01/24 22:27:53 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/01/24 22:27:53 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:200) finished in 0,005 s
19/01/24 22:27:53 INFO DAGScheduler: Job 2 finished: collect at utils.scala:200, took 0,079592 s
19/01/24 22:27:53 INFO CodeGenerator: Code generated in 8.174859 ms
19/01/24 22:27:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews_spark` AS `zzz11`
WHERE (0 = 1)
19/01/24 22:27:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `reviews_spark`
19/01/24 22:27:57 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e478bc24cd
19/01/24 22:27:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e478bc24cd` AS `zzz12`
WHERE (0 = 1)
19/01/24 22:27:57 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e448ea71b
19/01/24 22:27:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e448ea71b` AS `zzz13`
WHERE (0 = 1)
19/01/24 22:27:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e478bc24cd`
19/01/24 22:27:58 INFO CodeGenerator: Code generated in 34.87653 ms
19/01/24 22:27:58 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
19/01/24 22:27:58 INFO DAGScheduler: Registering RDD 27 (flatMap at CountVectorizer.scala:163)
19/01/24 22:27:58 INFO DAGScheduler: Got job 3 (count at CountVectorizer.scala:176) with 1 output partitions
19/01/24 22:27:58 INFO DAGScheduler: Final stage: ResultStage 6 (count at CountVectorizer.scala:176)
19/01/24 22:27:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/01/24 22:27:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/01/24 22:27:58 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163), which has no missing parents
19/01/24 22:27:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.5 KB, free 364.4 MB)
19/01/24 22:27:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.4 MB)
19/01/24 22:27:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:56564 (size: 13.0 KB, free: 364.5 MB)
19/01/24 22:27:58 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/01/24 22:27:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
19/01/24 22:27:58 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/01/24 22:27:58 WARN TaskSetManager: Stage 5 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:27:58 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:27:58 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/01/24 22:27:58 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 22:27:58 INFO CodeGenerator: Code generated in 14.230972 ms
19/01/24 22:27:58 INFO CodeGenerator: Code generated in 13.809775 ms
19/01/24 22:27:58 INFO CodeGenerator: Code generated in 8.133286 ms
19/01/24 22:27:58 INFO CodeGenerator: Code generated in 13.007496 ms
19/01/24 22:27:59 INFO ContextCleaner: Cleaned accumulator 112
19/01/24 22:27:59 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:56564 in memory (size: 7.7 KB, free: 364.5 MB)
19/01/24 22:27:59 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:56564 in memory (size: 3.7 KB, free: 364.5 MB)
19/01/24 22:27:59 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1951 bytes result sent to driver
19/01/24 22:27:59 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 999 ms on localhost (executor driver) (1/1)
19/01/24 22:27:59 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/01/24 22:27:59 INFO DAGScheduler: ShuffleMapStage 5 (flatMap at CountVectorizer.scala:163) finished in 1,000 s
19/01/24 22:27:59 INFO DAGScheduler: looking for newly runnable stages
19/01/24 22:27:59 INFO DAGScheduler: running: Set()
19/01/24 22:27:59 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/01/24 22:27:59 INFO DAGScheduler: failed: Set()
19/01/24 22:27:59 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173), which has no missing parents
19/01/24 22:27:59 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 364.4 MB)
19/01/24 22:27:59 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1887.0 B, free 364.4 MB)
19/01/24 22:27:59 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:56564 (size: 1887.0 B, free: 364.5 MB)
19/01/24 22:27:59 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/01/24 22:27:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
19/01/24 22:27:59 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/01/24 22:27:59 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
19/01/24 22:27:59 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/01/24 22:27:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:27:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:27:59 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 686.3 KB, free 363.8 MB)
19/01/24 22:27:59 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:56564 (size: 686.3 KB, free: 363.8 MB)
19/01/24 22:27:59 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1830 bytes result sent to driver
19/01/24 22:27:59 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 130 ms on localhost (executor driver) (1/1)
19/01/24 22:27:59 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/01/24 22:27:59 INFO DAGScheduler: ResultStage 6 (count at CountVectorizer.scala:176) finished in 0,130 s
19/01/24 22:27:59 INFO DAGScheduler: Job 3 finished: count at CountVectorizer.scala:176, took 1,164289 s
19/01/24 22:27:59 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
19/01/24 22:27:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 143 bytes
19/01/24 22:27:59 INFO DAGScheduler: Got job 4 (top at CountVectorizer.scala:179) with 1 output partitions
19/01/24 22:27:59 INFO DAGScheduler: Final stage: ResultStage 8 (top at CountVectorizer.scala:179)
19/01/24 22:27:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/01/24 22:27:59 INFO DAGScheduler: Missing parents: List()
19/01/24 22:27:59 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179), which has no missing parents
19/01/24 22:27:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 363.8 MB)
19/01/24 22:27:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.8 MB)
19/01/24 22:27:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:56564 (size: 2.2 KB, free: 363.8 MB)
19/01/24 22:27:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/01/24 22:27:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
19/01/24 22:27:59 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/01/24 22:27:59 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
19/01/24 22:27:59 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
19/01/24 22:27:59 INFO BlockManager: Found block rdd_30_0 locally
19/01/24 22:27:59 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 174434 bytes result sent to driver
19/01/24 22:27:59 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 42 ms on localhost (executor driver) (1/1)
19/01/24 22:27:59 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/01/24 22:27:59 INFO DAGScheduler: ResultStage 8 (top at CountVectorizer.scala:179) finished in 0,042 s
19/01/24 22:27:59 INFO DAGScheduler: Job 4 finished: top at CountVectorizer.scala:179, took 0,058503 s
19/01/24 22:27:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1137.7 KB, free 362.6 MB)
19/01/24 22:27:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 89.8 KB, free 362.6 MB)
19/01/24 22:27:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:56564 (size: 89.8 KB, free: 363.7 MB)
19/01/24 22:27:59 INFO SparkContext: Created broadcast 8 from broadcast at CountVectorizer.scala:244
19/01/24 22:27:59 INFO CodeGenerator: Code generated in 39.179663 ms
19/01/24 22:28:00 INFO CodeGenerator: Code generated in 21.436896 ms
19/01/24 22:28:00 INFO Instrumentation: LogisticRegression-logistic_regression_56e41ec73575-1938028476-1: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
19/01/24 22:28:00 INFO Instrumentation: LogisticRegression-logistic_regression_56e41ec73575-1938028476-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
19/01/24 22:28:00 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:517
19/01/24 22:28:00 INFO DAGScheduler: Got job 5 (treeAggregate at LogisticRegression.scala:517) with 1 output partitions
19/01/24 22:28:00 INFO DAGScheduler: Final stage: ResultStage 9 (treeAggregate at LogisticRegression.scala:517)
19/01/24 22:28:00 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:00 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:00 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at treeAggregate at LogisticRegression.scala:517), which has no missing parents
19/01/24 22:28:00 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 116.1 KB, free 362.4 MB)
19/01/24 22:28:00 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 74.8 KB, free 362.4 MB)
19/01/24 22:28:00 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 363.6 MB)
19/01/24 22:28:00 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at treeAggregate at LogisticRegression.scala:517) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:00 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/01/24 22:28:00 WARN TaskSetManager: Stage 9 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:00 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:00 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
19/01/24 22:28:00 INFO ContextCleaner: Cleaned accumulator 173
19/01/24 22:28:00 INFO ContextCleaner: Cleaned accumulator 175
19/01/24 22:28:00 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 22:28:00 INFO ContextCleaner: Cleaned accumulator 176
19/01/24 22:28:00 INFO ContextCleaner: Cleaned shuffle 2
19/01/24 22:28:00 INFO ContextCleaner: Cleaned accumulator 177
19/01/24 22:28:00 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:56564 in memory (size: 13.0 KB, free: 363.6 MB)
19/01/24 22:28:00 INFO BlockManager: Removing RDD 30
19/01/24 22:28:00 INFO CodeGenerator: Code generated in 6.429537 ms
19/01/24 22:28:00 INFO ContextCleaner: Cleaned RDD 30
19/01/24 22:28:00 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:56564 in memory (size: 1887.0 B, free: 364.3 MB)
19/01/24 22:28:00 INFO ContextCleaner: Cleaned accumulator 174
19/01/24 22:28:00 INFO ContextCleaner: Cleaned accumulator 178
19/01/24 22:28:00 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:56564 in memory (size: 2.2 KB, free: 364.3 MB)
19/01/24 22:28:00 INFO MemoryStore: Block rdd_40_0 stored as values in memory (estimated size 2.5 MB, free 360.6 MB)
19/01/24 22:28:00 INFO BlockManagerInfo: Added rdd_40_0 in memory on 127.0.0.1:56564 (size: 2.5 MB, free: 361.8 MB)
19/01/24 22:28:00 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 524197 bytes result sent to driver
19/01/24 22:28:00 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 814 ms on localhost (executor driver) (1/1)
19/01/24 22:28:00 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/01/24 22:28:00 INFO DAGScheduler: ResultStage 9 (treeAggregate at LogisticRegression.scala:517) finished in 0,814 s
19/01/24 22:28:00 INFO DAGScheduler: Job 5 finished: treeAggregate at LogisticRegression.scala:517, took 0,830379 s
19/01/24 22:28:01 INFO Instrumentation: LogisticRegression-logistic_regression_56e41ec73575-1938028476-1: {"numClasses":2}
19/01/24 22:28:01 INFO Instrumentation: LogisticRegression-logistic_regression_56e41ec73575-1938028476-1: {"numFeatures":8098}
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 63.3 KB, free 360.5 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.7 KB, free 360.5 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:56564 (size: 7.7 KB, free: 361.8 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 10 from broadcast at LogisticRegression.scala:600
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 439.0 B, free 360.4 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:56564 (size: 439.0 B, free: 361.8 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 11 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:01 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:01 INFO DAGScheduler: Got job 6 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:01 INFO DAGScheduler: Final stage: ResultStage 10 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:01 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:01 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:01 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:01 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/01/24 22:28:01 WARN TaskSetManager: Stage 10 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:01 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:01 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
19/01/24 22:28:01 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:01 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 68236 bytes result sent to driver
19/01/24 22:28:01 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 52 ms on localhost (executor driver) (1/1)
19/01/24 22:28:01 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/01/24 22:28:01 INFO DAGScheduler: ResultStage 10 (treeAggregate at LogisticRegression.scala:1892) finished in 0,053 s
19/01/24 22:28:01 INFO DAGScheduler: Job 6 finished: treeAggregate at LogisticRegression.scala:1892, took 0,062452 s
19/01/24 22:28:01 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/01/24 22:28:01 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/01/24 22:28:01 INFO TorrentBroadcast: Destroying Broadcast(11) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:01 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:56564 in memory (size: 439.0 B, free: 361.7 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.5 KB, free 360.2 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:56564 (size: 23.5 KB, free: 361.7 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 13 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:01 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:01 INFO DAGScheduler: Got job 7 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:01 INFO DAGScheduler: Final stage: ResultStage 11 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:01 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:01 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:01 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[43] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[43] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:01 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/01/24 22:28:01 WARN TaskSetManager: Stage 11 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:01 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:01 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
19/01/24 22:28:01 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:01 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 68236 bytes result sent to driver
19/01/24 22:28:01 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 39 ms on localhost (executor driver) (1/1)
19/01/24 22:28:01 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/01/24 22:28:01 INFO DAGScheduler: ResultStage 11 (treeAggregate at LogisticRegression.scala:1892) finished in 0,039 s
19/01/24 22:28:01 INFO DAGScheduler: Job 7 finished: treeAggregate at LogisticRegression.scala:1892, took 0,046312 s
19/01/24 22:28:01 INFO TorrentBroadcast: Destroying Broadcast(13) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:01 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:56564 in memory (size: 23.5 KB, free: 361.6 MB)
19/01/24 22:28:01 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:01 INFO LBFGS: Val and Grad Norm: 0,330456 (rel: 0,523) 0,367278
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 57.6 KB, free 360.0 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:56564 (size: 57.6 KB, free: 361.6 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 15 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:01 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:01 INFO DAGScheduler: Got job 8 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:01 INFO DAGScheduler: Final stage: ResultStage 12 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:01 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:01 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:01 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:01 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/01/24 22:28:01 WARN TaskSetManager: Stage 12 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:01 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:01 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
19/01/24 22:28:01 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:01 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 68236 bytes result sent to driver
19/01/24 22:28:01 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 32 ms on localhost (executor driver) (1/1)
19/01/24 22:28:01 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/01/24 22:28:01 INFO DAGScheduler: ResultStage 12 (treeAggregate at LogisticRegression.scala:1892) finished in 0,033 s
19/01/24 22:28:01 INFO DAGScheduler: Job 8 finished: treeAggregate at LogisticRegression.scala:1892, took 0,041427 s
19/01/24 22:28:01 INFO TorrentBroadcast: Destroying Broadcast(15) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:01 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:56564 in memory (size: 57.6 KB, free: 361.5 MB)
19/01/24 22:28:01 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:01 INFO LBFGS: Val and Grad Norm: 0,213198 (rel: 0,355) 0,167363
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 17 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:01 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:01 INFO DAGScheduler: Got job 9 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:01 INFO DAGScheduler: Final stage: ResultStage 13 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:01 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:01 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:01 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[45] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[45] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:01 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/01/24 22:28:01 WARN TaskSetManager: Stage 13 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:01 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:01 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
19/01/24 22:28:01 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:01 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 68193 bytes result sent to driver
19/01/24 22:28:01 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 29 ms on localhost (executor driver) (1/1)
19/01/24 22:28:01 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/01/24 22:28:01 INFO DAGScheduler: ResultStage 13 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 22:28:01 INFO DAGScheduler: Job 9 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039019 s
19/01/24 22:28:01 INFO TorrentBroadcast: Destroying Broadcast(17) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:01 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:01 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:01 INFO LBFGS: Val and Grad Norm: 0,147331 (rel: 0,309) 0,0949852
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 19 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:01 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:01 INFO DAGScheduler: Got job 10 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:01 INFO DAGScheduler: Final stage: ResultStage 14 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:01 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:01 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:01 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:01 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/01/24 22:28:01 WARN TaskSetManager: Stage 14 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:01 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:01 INFO Executor: Running task 0.0 in stage 14.0 (TID 13)
19/01/24 22:28:01 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:01 INFO Executor: Finished task 0.0 in stage 14.0 (TID 13). 68236 bytes result sent to driver
19/01/24 22:28:01 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 13) in 28 ms on localhost (executor driver) (1/1)
19/01/24 22:28:01 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/01/24 22:28:01 INFO DAGScheduler: ResultStage 14 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 22:28:01 INFO DAGScheduler: Job 10 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036371 s
19/01/24 22:28:01 INFO TorrentBroadcast: Destroying Broadcast(19) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:01 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:01 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:01 INFO LBFGS: Val and Grad Norm: 0,100491 (rel: 0,318) 0,0613800
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 57.7 KB, free 359.4 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:56564 (size: 57.7 KB, free: 361.3 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 21 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:01 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:01 INFO DAGScheduler: Got job 11 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:01 INFO DAGScheduler: Final stage: ResultStage 15 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:01 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:01 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:01 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[47] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:01 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:01 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:01 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[47] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:01 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/01/24 22:28:01 WARN TaskSetManager: Stage 15 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:01 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:01 INFO Executor: Running task 0.0 in stage 15.0 (TID 14)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 15.0 (TID 14). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 14) in 31 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 15 (treeAggregate at LogisticRegression.scala:1892) finished in 0,033 s
19/01/24 22:28:02 INFO DAGScheduler: Job 11 finished: treeAggregate at LogisticRegression.scala:1892, took 0,041466 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(21) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:56564 in memory (size: 57.7 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0724526 (rel: 0,279) 0,0316812
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 23 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 16 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.5 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:02 WARN TaskSetManager: Stage 16 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 16.0 (TID 15)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 16.0 (TID 15). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 15) in 34 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 16 (treeAggregate at LogisticRegression.scala:1892) finished in 0,036 s
19/01/24 22:28:02 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:1892, took 0,056641 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(23) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.8 MB)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0587020 (rel: 0,190) 0,0233276
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.4 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.7 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 25 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 17 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[49] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[49] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 17 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 17.0 (TID 16)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 17.0 (TID 16). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 16) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 17 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 22:28:02 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039202 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(25) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.7 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0508755 (rel: 0,133) 0,0191974
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 27 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 18 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 18 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 18.0 (TID 17)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 18.0 (TID 17). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 17) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 18 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:02 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030948 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(27) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0492985 (rel: 0,0310) 0,0273011
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.0 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 29 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 19 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[51] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[51] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 19 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 19.0 (TID 18)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 19.0 (TID 18). 68236 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 18) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 19 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:02 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033369 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(29) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0448300 (rel: 0,0906) 0,0186364
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 31 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 20 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 20 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 20.0 (TID 19)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 20.0 (TID 19). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 19) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 20 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:02 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031358 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(31) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0396473 (rel: 0,116) 0,0195072
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 33 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 21 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[53] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[53] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 21 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 21.0 (TID 20)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 21.0 (TID 20). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 20) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 21 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:02 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030465 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(33) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.4 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 35 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 22 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 22.0 (TID 21)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 22.0 (TID 21). 68236 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 21) in 28 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037021 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(35) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO StrongWolfeLineSearch: Line search t: 0.32886824614418664 fval: 0.03927381963744339 rhs: 0.03964717451086121 cdd: 6.991968417275898E-4
19/01/24 22:28:02 INFO LBFGS: Step Size: 0,3289
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0392738 (rel: 0,00942) 0,0181790
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 37 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[55] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[55] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 23 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 23.0 (TID 22)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 23.0 (TID 22). 68236 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 22) in 40 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 23 (treeAggregate at LogisticRegression.scala:1892) finished in 0,042 s
19/01/24 22:28:02 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1892, took 0,049483 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(37) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0379879 (rel: 0,0327) 0,0145010
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 57.6 KB, free 360.4 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:56564 (size: 57.6 KB, free: 361.7 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 39 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 24 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 24.0 (TID 23)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 24.0 (TID 23). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 23) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:02 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032051 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(39) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:56564 in memory (size: 57.6 KB, free: 361.7 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0369358 (rel: 0,0277) 0,0191350
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 41 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[57] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[57] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 25 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 25.0 (TID 24)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 25.0 (TID 24). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 24) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 25 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:02 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032573 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(41) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0363885 (rel: 0,0148) 0,0167591
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.0 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 43 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 26 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 26.0 (TID 25)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 26.0 (TID 25). 68236 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 25) in 30 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 22:28:02 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038155 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(43) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 63.3 KB, free 359.8 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 45 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[59] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[59] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 27 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 27.0 (TID 26)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 27.0 (TID 26). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 26) in 29 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 27 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 22:28:02 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036811 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(45) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO StrongWolfeLineSearch: Line search t: 0.4108013193598613 fval: 0.03594493422285328 rhs: 0.03638839827048342 cdd: 3.814229000619686E-4
19/01/24 22:28:02 INFO LBFGS: Step Size: 0,4108
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0359449 (rel: 0,0122) 0,0135038
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 47 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 28 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 28.0 (TID 27)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 28.0 (TID 27). 68236 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 27) in 30 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 22:28:02 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035911 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(47) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0357242 (rel: 0,00614) 0,00639451
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 49 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[61] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 29 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 29.0 (TID 28)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 29.0 (TID 28). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 28) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 29 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 22:28:02 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031016 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(49) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0353285 (rel: 0,0111) 0,00918555
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 51 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 30 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 30.0 (TID 29)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 30.0 (TID 29). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 29) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:02 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029359 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(51) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0349337 (rel: 0,0112) 0,00751039
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.2 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 53 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.1 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[63] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 31 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 31.0 (TID 30)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 31.0 (TID 30). 68236 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 30) in 33 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 31 (treeAggregate at LogisticRegression.scala:1892) finished in 0,034 s
19/01/24 22:28:02 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1892, took 0,040508 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(53) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 55 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 32 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 32.0 (TID 31)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 32.0 (TID 31). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 31) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 32 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:02 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034752 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(55) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO StrongWolfeLineSearch: Line search t: 0.17279326617073676 fval: 0.03482345995373003 rhs: 0.03493363733470484 cdd: 9.033313740993744E-4
19/01/24 22:28:02 INFO LBFGS: Step Size: 0,1728
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0348235 (rel: 0,00315) 0,0355699
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 57 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[65] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 33 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 33.0 (TID 32)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 33.0 (TID 32). 68236 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 32) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 33 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:02 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037784 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(57) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0341632 (rel: 0,0190) 0,00651399
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.0 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 59 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 30 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 34 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 34.0 (TID 33)
19/01/24 22:28:02 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:02 INFO Executor: Finished task 0.0 in stage 34.0 (TID 33). 68193 bytes result sent to driver
19/01/24 22:28:02 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 33) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:02 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/01/24 22:28:02 INFO DAGScheduler: ResultStage 34 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:02 INFO DAGScheduler: Job 30 finished: treeAggregate at LogisticRegression.scala:1892, took 0,041910 s
19/01/24 22:28:02 INFO TorrentBroadcast: Destroying Broadcast(59) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:02 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:02 INFO LBFGS: Val and Grad Norm: 0,0339435 (rel: 0,00643) 0,00558368
19/01/24 22:28:02 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 61 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:02 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:02 INFO DAGScheduler: Got job 31 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:02 INFO DAGScheduler: Final stage: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:02 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:02 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:02 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:02 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:02 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:02 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[67] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:02 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/01/24 22:28:02 WARN TaskSetManager: Stage 35 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:02 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:02 INFO Executor: Running task 0.0 in stage 35.0 (TID 34)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 35.0 (TID 34). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 34) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 35 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:03 INFO DAGScheduler: Job 31 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031728 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(61) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0334690 (rel: 0,0140) 0,00643648
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 63 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 32 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 36 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 36.0 (TID 35)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 36.0 (TID 35). 68236 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 35) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:03 INFO DAGScheduler: Job 32 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033787 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(63) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0326367 (rel: 0,0249) 0,0142538
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 65 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 33 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[69] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 37 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 37.0 (TID 36)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 37.0 (TID 36). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 36) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 37 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:03 INFO DAGScheduler: Job 33 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033152 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(65) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0322304 (rel: 0,0124) 0,00481859
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 67 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 34 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 38 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 38.0 (TID 37)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 38.0 (TID 37). 68236 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 37) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:03 INFO DAGScheduler: Job 34 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038141 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(67) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0320398 (rel: 0,00592) 0,00458256
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.1 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.2 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 69 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 35 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[71] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:03 WARN TaskSetManager: Stage 39 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 39.0 (TID 38)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 39.0 (TID 38). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 38) in 28 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 39 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 22:28:03 INFO DAGScheduler: Job 35 finished: treeAggregate at LogisticRegression.scala:1892, took 0,044603 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(69) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.8 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0317947 (rel: 0,00765) 0,0150047
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.7 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 71 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 36 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 40 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 40.0 (TID 39)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 40.0 (TID 39). 68236 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 39) in 33 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 40 (treeAggregate at LogisticRegression.scala:1892) finished in 0,033 s
19/01/24 22:28:03 INFO DAGScheduler: Job 36 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038941 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(71) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.7 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0315248 (rel: 0,00849) 0,00508445
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 73 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 37 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[73] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 41 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 41.0 (TID 40)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 41.0 (TID 40). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 40) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 41 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:03 INFO DAGScheduler: Job 37 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031277 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(73) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0314268 (rel: 0,00311) 0,00583252
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 75 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 38 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 42 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 42.0 (TID 41)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 42.0 (TID 41). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 41) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 42 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:03 INFO DAGScheduler: Job 38 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032111 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(75) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0312075 (rel: 0,00698) 0,00464233
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 77 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 39 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 43 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[75] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[75] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 43 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 43.0 (TID 42)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 43.0 (TID 42). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 42) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 43 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:03 INFO DAGScheduler: Job 39 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031978 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(77) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0309571 (rel: 0,00802) 0,00454268
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 79 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 40 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 44 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 44 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 44.0 (TID 43)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 44.0 (TID 43). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 43) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 44 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:03 INFO DAGScheduler: Job 40 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031596 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(79) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0307409 (rel: 0,00698) 0,00503477
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 81 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 41 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 45 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[77] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[77] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 45 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 45.0 (TID 44)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 45.0 (TID 44). 68236 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 44) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 45 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:03 INFO DAGScheduler: Job 41 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031006 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(81) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0304751 (rel: 0,00864) 0,00428555
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 83 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 42 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 46 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[78] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[78] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 46 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 46.0 (TID 45)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 46.0 (TID 45). 68236 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 45) in 46 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 46 (treeAggregate at LogisticRegression.scala:1892) finished in 0,047 s
19/01/24 22:28:03 INFO DAGScheduler: Job 42 finished: treeAggregate at LogisticRegression.scala:1892, took 0,053220 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(83) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.8 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0302014 (rel: 0,00898) 0,00396539
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.7 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 85 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 43 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 47 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[79] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[79] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 47 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 47.0 (TID 46)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 47.0 (TID 46). 68236 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 46) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 47 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:03 INFO DAGScheduler: Job 43 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030981 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(85) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.7 MB)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0298543 (rel: 0,0115) 0,00537635
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 87 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 44 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 48 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[80] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[80] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 48 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 48.0 (TID 47)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 48.0 (TID 47). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 47) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 48 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:03 INFO DAGScheduler: Job 44 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030397 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(87) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0296887 (rel: 0,00554) 0,0116162
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 89 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 45 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 49 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[81] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[81] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 49 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 49.0 (TID 48)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 49.0 (TID 48). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 48) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 49 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:03 INFO DAGScheduler: Job 45 finished: treeAggregate at LogisticRegression.scala:1892, took 0,050165 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(89) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0295122 (rel: 0,00595) 0,00539889
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 91 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 46 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 50 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[82] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[82] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 50 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 50.0 (TID 49)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 50.0 (TID 49). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 49) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 50 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:03 INFO DAGScheduler: Job 46 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030822 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(91) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0294075 (rel: 0,00355) 0,00319102
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 93 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 47 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 51 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[83] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[83] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 51 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 51.0 (TID 50)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 51.0 (TID 50). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 50) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 51 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:03 INFO DAGScheduler: Job 47 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030203 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(93) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0293339 (rel: 0,00250) 0,00352100
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 95 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 48 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 52 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[84] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[84] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 52 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 52.0 (TID 51)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 52.0 (TID 51). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 51) in 28 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 52 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 22:28:03 INFO DAGScheduler: Job 48 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036089 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(95) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0292944 (rel: 0,00135) 0,0111846
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 97 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 49 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 53 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[85] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[85] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 53 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 53.0 (TID 52)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 53.0 (TID 52). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 52) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 53 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:03 INFO DAGScheduler: Job 49 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033972 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(97) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0292388 (rel: 0,00190) 0,00613614
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.2 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 99 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 50 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 54 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.1 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 54 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 54.0 (TID 53)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 54.0 (TID 53). 68236 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 53) in 33 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 54 (treeAggregate at LogisticRegression.scala:1892) finished in 0,034 s
19/01/24 22:28:03 INFO DAGScheduler: Job 50 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038764 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(99) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0291668 (rel: 0,00246) 0,00573039
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 101 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 51 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 55 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[87] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
19/01/24 22:28:03 WARN TaskSetManager: Stage 55 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:03 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:03 INFO Executor: Running task 0.0 in stage 55.0 (TID 54)
19/01/24 22:28:03 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:03 INFO Executor: Finished task 0.0 in stage 55.0 (TID 54). 68193 bytes result sent to driver
19/01/24 22:28:03 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 54) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:03 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/01/24 22:28:03 INFO DAGScheduler: ResultStage 55 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:03 INFO DAGScheduler: Job 51 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031241 s
19/01/24 22:28:03 INFO TorrentBroadcast: Destroying Broadcast(101) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:03 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:03 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:03 INFO LBFGS: Val and Grad Norm: 0,0291146 (rel: 0,00179) 0,00597272
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 103 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:03 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:03 INFO DAGScheduler: Got job 52 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:03 INFO DAGScheduler: Final stage: ResultStage 56 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:03 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:03 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:03 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:03 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:03 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:03 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:03 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 56 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 56.0 (TID 55)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 56.0 (TID 55). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 55) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 56 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:04 INFO DAGScheduler: Job 52 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033031 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(103) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0289667 (rel: 0,00508) 0,00414288
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.0 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 105 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 53 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 57 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[89] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 57 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 57.0 (TID 56)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 57.0 (TID 56). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 56) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 57 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:04 INFO DAGScheduler: Job 53 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030124 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(105) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0288259 (rel: 0,00486) 0,00436637
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 107 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 54 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 58 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 58 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 58.0 (TID 57)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 58.0 (TID 57). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 57) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 58 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:04 INFO DAGScheduler: Job 54 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030445 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(107) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0287244 (rel: 0,00352) 0,00223707
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 109 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 55 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 59 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[91] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 59 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 59.0 (TID 58)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 59.0 (TID 58). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 58) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 59 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:04 INFO DAGScheduler: Job 55 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032988 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(109) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0286589 (rel: 0,00228) 0,00213336
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 111 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 56 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 60 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 60 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 60.0 (TID 59)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 60.0 (TID 59). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 59) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 60 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:04 INFO DAGScheduler: Job 56 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033030 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(111) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0285803 (rel: 0,00274) 0,00415048
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 113 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 57 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 61 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[93] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 61 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 61.0 (TID 60)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 61.0 (TID 60). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 60) in 28 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 61 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 22:28:04 INFO DAGScheduler: Job 57 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036717 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(113) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.1 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.2 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 115 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 58 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 62 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:04 WARN TaskSetManager: Stage 62 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 62.0 (TID 61)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 62.0 (TID 61). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 61) in 32 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 62 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 22:28:04 INFO DAGScheduler: Job 58 finished: treeAggregate at LogisticRegression.scala:1892, took 0,050080 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(115) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.8 MB)
19/01/24 22:28:04 INFO StrongWolfeLineSearch: Line search t: 0.4267145302663191 fval: 0.02848748920414812 rhs: 0.028580243313891446 cdd: 5.6037400286210854E-8
19/01/24 22:28:04 INFO LBFGS: Step Size: 0,4267
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0284875 (rel: 0,00325) 0,00586295
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 117 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 59 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 63 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[95] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 63 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 63.0 (TID 62)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 63.0 (TID 62). 68279 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 62) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 63 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:04 INFO DAGScheduler: Job 59 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033388 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(117) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0283739 (rel: 0,00399) 0,00531647
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 119 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 60 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 64 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 64 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 64.0 (TID 63)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 64.0 (TID 63). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 63) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 64 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 22:28:04 INFO DAGScheduler: Job 60 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032740 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(119) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0282870 (rel: 0,00306) 0,00553462
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 121 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 61 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 65 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[97] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 65 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 65.0 (TID 64)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 65.0 (TID 64). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 64) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 65 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:04 INFO DAGScheduler: Job 61 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029529 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(121) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0282548 (rel: 0,00114) 0,00397435
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 123 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 62 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 66 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 66 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 66.0 (TID 65)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 66.0 (TID 65). 68236 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 65) in 28 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 66 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 22:28:04 INFO DAGScheduler: Job 62 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033945 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(123) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0282183 (rel: 0,00129) 0,00289874
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 125 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 63 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 67 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[99] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 67 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 67.0 (TID 66)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 67.0 (TID 66). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 66) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 67 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:04 INFO DAGScheduler: Job 63 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030405 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(125) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0281719 (rel: 0,00164) 0,00445034
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 127 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 64 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 68 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 68 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 68.0 (TID 67)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 68.0 (TID 67). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 67) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 68 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:04 INFO DAGScheduler: Job 64 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030519 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(127) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0281092 (rel: 0,00223) 0,00521472
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 129 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 65 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 69 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[101] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 69 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 69.0 (TID 68)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 69.0 (TID 68). 68236 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 68) in 30 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 69 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 22:28:04 INFO DAGScheduler: Job 65 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036360 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(129) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0280739 (rel: 0,00125) 0,00627099
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.1 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 131 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.8 MB)
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 66 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 70 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 116.3 KB, free 360.4 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 70 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 70.0 (TID 69)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 70.0 (TID 69). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 69) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 70 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 22:28:04 INFO DAGScheduler: Job 66 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030276 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(131) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.8 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0280154 (rel: 0,00208) 0,00209270
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 133 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 67 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 71 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[103] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 71 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 71.0 (TID 70)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 71.0 (TID 70). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 70) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 71 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:04 INFO DAGScheduler: Job 67 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029428 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(133) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0279933 (rel: 0,000787) 0,00174697
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 135 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 68 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 72 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 72 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 72.0 (TID 71)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 72.0 (TID 71). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 71) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 72 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:04 INFO DAGScheduler: Job 68 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030566 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(135) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0279381 (rel: 0,00197) 0,00168608
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 137 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 69 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 73 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[105] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[105] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 73 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 73.0 (TID 72)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 73.0 (TID 72). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 72) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 73 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:04 INFO DAGScheduler: Job 69 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031589 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(137) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0278585 (rel: 0,00285) 0,00163783
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 139 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 70 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 74 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[106] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[106] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 74 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 74.0 (TID 73)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 74.0 (TID 73). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 73) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 74 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:04 INFO DAGScheduler: Job 70 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034819 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(139) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0277578 (rel: 0,00361) 0,00180832
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 141 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 71 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 75 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[107] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[107] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 75 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 75.0 (TID 74)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 75.0 (TID 74). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 74) in 31 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 75 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 22:28:04 INFO DAGScheduler: Job 71 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035722 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(141) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 143 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 72 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 76 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[108] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[108] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 76 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 76.0 (TID 75)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 76.0 (TID 75). 68193 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 75) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 76 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:04 INFO DAGScheduler: Job 72 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031528 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(143) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO StrongWolfeLineSearch: Line search t: 0.1 fval: 0.027738693432296787 rhs: 0.027757797712281675 cdd: -5.903516402336295E-6
19/01/24 22:28:04 INFO LBFGS: Step Size: 0,1000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0277387 (rel: 0,000688) 0,00422118
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 145 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:04 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:04 INFO DAGScheduler: Got job 73 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:04 INFO DAGScheduler: Final stage: ResultStage 77 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:04 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:04 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:04 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[109] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[109] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:04 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
19/01/24 22:28:04 WARN TaskSetManager: Stage 77 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:04 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:04 INFO Executor: Running task 0.0 in stage 77.0 (TID 76)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:04 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:04 INFO Executor: Finished task 0.0 in stage 77.0 (TID 76). 68279 bytes result sent to driver
19/01/24 22:28:04 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 76) in 44 ms on localhost (executor driver) (1/1)
19/01/24 22:28:04 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
19/01/24 22:28:04 INFO DAGScheduler: ResultStage 77 (treeAggregate at LogisticRegression.scala:1892) finished in 0,045 s
19/01/24 22:28:04 INFO DAGScheduler: Job 73 finished: treeAggregate at LogisticRegression.scala:1892, took 0,052405 s
19/01/24 22:28:04 INFO TorrentBroadcast: Destroying Broadcast(145) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:04 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:04 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 22:28:04 INFO LBFGS: Val and Grad Norm: 0,0276637 (rel: 0,00270) 0,00155316
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:04 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.4 MB)
19/01/24 22:28:04 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.7 MB)
19/01/24 22:28:04 INFO SparkContext: Created broadcast 147 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 74 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 78 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[110] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[110] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 78 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 78.0 (TID 77)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 78.0 (TID 77). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 77) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 78 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:05 INFO DAGScheduler: Job 74 finished: treeAggregate at LogisticRegression.scala:1892, took 0,030626 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(147) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.7 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0276344 (rel: 0,00106) 0,00261385
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 149 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 75 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 79 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[111] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[111] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 79 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 79.0 (TID 78)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 79.0 (TID 78). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 78) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 79 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 22:28:05 INFO DAGScheduler: Job 75 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028811 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(149) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0276142 (rel: 0,000733) 0,00179582
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 151 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 76 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 80 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[112] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[112] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 80 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 80.0 (TID 79)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 80.0 (TID 79). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 79) in 32 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 80 (treeAggregate at LogisticRegression.scala:1892) finished in 0,033 s
19/01/24 22:28:05 INFO DAGScheduler: Job 76 finished: treeAggregate at LogisticRegression.scala:1892, took 0,041971 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(151) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0275970 (rel: 0,000620) 0,00226395
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 153 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 77 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 81 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[113] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[113] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 81 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 81.0 (TID 80)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 81.0 (TID 80). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 80) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 81 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:05 INFO DAGScheduler: Job 77 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034545 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(153) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0275743 (rel: 0,000825) 0,00167558
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 155 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 78 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 82 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[114] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[114] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 82 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 82.0 (TID 81)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 82.0 (TID 81). 68236 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 81) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 82 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:05 INFO DAGScheduler: Job 78 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032590 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(155) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 157 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 79 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 83 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[115] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[115] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 83 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 83.0 (TID 82)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 83.0 (TID 82). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 82) in 32 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 83 (treeAggregate at LogisticRegression.scala:1892) finished in 0,033 s
19/01/24 22:28:05 INFO DAGScheduler: Job 79 finished: treeAggregate at LogisticRegression.scala:1892, took 0,038649 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(157) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO StrongWolfeLineSearch: Line search t: 0.4769797418924374 fval: 0.0275444991324947 rhs: 0.02757426596461796 cdd: 3.9424837397726215E-8
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO LBFGS: Step Size: 0,4770
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0275445 (rel: 0,00108) 0,00616549
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 159 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 80 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 84 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[116] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[116] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 84 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 84.0 (TID 83)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 84.0 (TID 83). 68236 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 83) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 84 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 22:28:05 INFO DAGScheduler: Job 80 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029104 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(159) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0275073 (rel: 0,00135) 0,00214546
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.2 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 161 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 81 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 85 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[117] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 74.8 KB, free 358.9 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.1 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[117] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 85 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 85.0 (TID 84)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 85.0 (TID 84). 68279 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 84) in 31 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 85 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 22:28:05 INFO DAGScheduler: Job 81 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036723 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(161) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0274931 (rel: 0,000516) 0,00158449
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.4 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.7 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 163 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 82 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 86 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[118] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[118] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 86 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 86.0 (TID 85)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 86.0 (TID 85). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 85) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 86 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:05 INFO DAGScheduler: Job 82 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028490 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(163) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.7 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0274843 (rel: 0,000320) 0,00180161
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 165 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 83 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 87 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[119] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[119] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 87 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 87.0 (TID 86)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 87.0 (TID 86). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 86) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 87 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:05 INFO DAGScheduler: Job 83 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029311 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(165) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0274576 (rel: 0,000971) 0,00158743
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.0 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 167 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 84 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 88 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[120] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[120] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 88 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 88.0 (TID 87)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 88.0 (TID 87). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 87) in 22 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 88 (treeAggregate at LogisticRegression.scala:1892) finished in 0,022 s
19/01/24 22:28:05 INFO DAGScheduler: Job 84 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029533 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(167) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0274144 (rel: 0,00158) 0,00393116
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 169 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 85 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 89 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[121] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[121] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 89 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 89.0 (TID 88)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 89.0 (TID 88). 68236 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 88) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 89 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:05 INFO DAGScheduler: Job 85 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031851 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(169) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0273875 (rel: 0,000982) 0,00432852
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.6 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 171 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 86 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 90 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[122] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[122] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 90 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 90.0 (TID 89)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 90.0 (TID 89). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 89) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 90 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:05 INFO DAGScheduler: Job 86 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031404 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(171) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0273598 (rel: 0,00101) 0,00188127
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.4 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 173 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 87 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 91 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[123] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[123] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 91 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 91.0 (TID 90)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 91.0 (TID 90). 68236 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 90) in 31 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 91 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 22:28:05 INFO DAGScheduler: Job 87 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036977 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(173) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0273468 (rel: 0,000476) 0,00116889
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 175 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 88 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 92 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[124] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[124] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 92 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 92.0 (TID 91)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 92.0 (TID 91). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 91) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 92 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:05 INFO DAGScheduler: Job 88 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029947 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(175) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0273375 (rel: 0,000339) 0,00133102
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.2 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 177 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 89 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 93 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[125] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 116.3 KB, free 358.9 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[125] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:05 WARN TaskSetManager: Stage 93 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 93.0 (TID 92)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 93.0 (TID 92). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 92) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 93 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:05 INFO DAGScheduler: Job 89 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037173 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(177) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 57.5 KB, free 360.4 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.7 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 179 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 90 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 94 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[126] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[126] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 94 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 94.0 (TID 93)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 94.0 (TID 93). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 93) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 94 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:05 INFO DAGScheduler: Job 90 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031914 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(179) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO StrongWolfeLineSearch: Line search t: 0.44238853046279136 fval: 0.027322638685121102 rhs: 0.02733753822231949 cdd: 4.543171550924762E-8
19/01/24 22:28:05 INFO LBFGS: Step Size: 0,4424
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.7 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0273226 (rel: 0,000545) 0,00359478
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 181 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 91 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 95 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[127] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[127] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 95 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 95.0 (TID 94)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 95.0 (TID 94). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 94) in 31 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 95 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 22:28:05 INFO DAGScheduler: Job 91 finished: treeAggregate at LogisticRegression.scala:1892, took 0,035615 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(181) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0273029 (rel: 0,000724) 0,00144224
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 183 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 92 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 96 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[128] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[128] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 96 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 96.0 (TID 95)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 96.0 (TID 95). 68236 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 95) in 31 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 96 (treeAggregate at LogisticRegression.scala:1892) finished in 0,031 s
19/01/24 22:28:05 INFO DAGScheduler: Job 92 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036581 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(183) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0272873 (rel: 0,000571) 0,00140178
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 185 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 93 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 97 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[129] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[129] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 97 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 97.0 (TID 96)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 97.0 (TID 96). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 96) in 30 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 97 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 22:28:05 INFO DAGScheduler: Job 93 finished: treeAggregate at LogisticRegression.scala:1892, took 0,036939 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(185) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 187 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 94 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 98 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[130] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[130] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 98 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 98.0 (TID 97)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 98.0 (TID 97). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 97) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 98 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:05 INFO DAGScheduler: Job 94 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031432 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(187) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO StrongWolfeLineSearch: Line search t: 0.18124034043854675 fval: 0.02727528205684075 rhs: 0.027287265460974944 cdd: -5.034893050342904E-7
19/01/24 22:28:05 INFO LBFGS: Step Size: 0,1812
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0272753 (rel: 0,000439) 0,00379483
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 189 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 95 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 99 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[131] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[131] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 99 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 99.0 (TID 98)
19/01/24 22:28:05 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:05 INFO Executor: Finished task 0.0 in stage 99.0 (TID 98). 68193 bytes result sent to driver
19/01/24 22:28:05 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 98) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:05 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
19/01/24 22:28:05 INFO DAGScheduler: ResultStage 99 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:05 INFO DAGScheduler: Job 95 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034721 s
19/01/24 22:28:05 INFO TorrentBroadcast: Destroying Broadcast(189) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:05 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:05 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO LBFGS: Val and Grad Norm: 0,0272599 (rel: 0,000564) 0,00212009
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.2 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 191 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:05 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:05 INFO DAGScheduler: Got job 96 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:05 INFO DAGScheduler: Final stage: ResultStage 100 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:05 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:05 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:05 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[132] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:05 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:05 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:05 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[132] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:05 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
19/01/24 22:28:05 WARN TaskSetManager: Stage 100 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:05 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:05 INFO Executor: Running task 0.0 in stage 100.0 (TID 99)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 100.0 (TID 99). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 99) in 29 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 100 (treeAggregate at LogisticRegression.scala:1892) finished in 0,030 s
19/01/24 22:28:06 INFO DAGScheduler: Job 96 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034634 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(191) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0272480 (rel: 0,000436) 0,00117490
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.2 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 193 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.8 MB)
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 97 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 101 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[133] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 116.3 KB, free 360.4 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.4 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[133] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 101 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 101.0 (TID 100)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 101.0 (TID 100). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 100) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 101 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:06 INFO DAGScheduler: Job 97 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031647 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(193) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0272368 (rel: 0,000412) 0,00132283
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.4 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 195 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 98 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 102 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[134] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[134] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 102 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 102.0 (TID 101)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 102.0 (TID 101). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 101) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 102 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:06 INFO DAGScheduler: Job 98 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028446 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(195) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0272191 (rel: 0,000649) 0,00202239
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 197 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 99 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 103 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[135] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[135] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 103 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 103.0 (TID 102)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 103.0 (TID 102). 68236 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 102) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 103 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:06 INFO DAGScheduler: Job 99 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032585 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(197) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0272060 (rel: 0,000484) 0,00307922
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.0 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 199 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 100 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 104 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[136] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[136] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 104 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 104.0 (TID 103)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 104.0 (TID 103). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 103) in 29 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 104 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 22:28:06 INFO DAGScheduler: Job 100 finished: treeAggregate at LogisticRegression.scala:1892, took 0,033887 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(199) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0271824 (rel: 0,000867) 0,00153555
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 201 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 101 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 105 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[137] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[137] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 105 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 105.0 (TID 104)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 105.0 (TID 104). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 104) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 105 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:06 INFO DAGScheduler: Job 101 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031799 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(201) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0271749 (rel: 0,000274) 0,00102271
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 203 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 102 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 106 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[138] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[138] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 106 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 106.0 (TID 105)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 106.0 (TID 105). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 105) in 31 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 106 (treeAggregate at LogisticRegression.scala:1892) finished in 0,032 s
19/01/24 22:28:06 INFO DAGScheduler: Job 102 finished: treeAggregate at LogisticRegression.scala:1892, took 0,037980 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(203) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0271630 (rel: 0,000438) 0,000860860
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.4 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 205 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 103 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 107 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[139] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[139] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 107 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 107.0 (TID 106)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 107.0 (TID 106). 68236 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 106) in 27 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 107 (treeAggregate at LogisticRegression.scala:1892) finished in 0,027 s
19/01/24 22:28:06 INFO DAGScheduler: Job 103 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031521 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(205) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 207 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 104 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 108 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[140] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[140] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 108 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 108.0 (TID 107)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 108.0 (TID 107). 68236 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 107) in 33 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 108 (treeAggregate at LogisticRegression.scala:1892) finished in 0,034 s
19/01/24 22:28:06 INFO DAGScheduler: Job 104 finished: treeAggregate at LogisticRegression.scala:1892, took 0,039313 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(207) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO StrongWolfeLineSearch: Line search t: 0.19604525695405883 fval: 0.02715561387700296 rhs: 0.027163021359093393 cdd: -2.620166538343346E-8
19/01/24 22:28:06 INFO LBFGS: Step Size: 0,1960
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0271556 (rel: 0,000273) 0,00187077
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 63.3 KB, free 359.1 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.1 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 209 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.8 MB)
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 105 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 109 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[141] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 116.3 KB, free 360.4 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.4 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[141] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 109 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 109.0 (TID 108)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 109.0 (TID 108). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 108) in 28 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 109 (treeAggregate at LogisticRegression.scala:1892) finished in 0,028 s
19/01/24 22:28:06 INFO DAGScheduler: Job 105 finished: treeAggregate at LogisticRegression.scala:1892, took 0,032135 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(209) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.8 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0271413 (rel: 0,000526) 0,00152413
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 63.3 KB, free 360.4 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 57.3 KB, free 360.4 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.7 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 211 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 106 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 110 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[142] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[142] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 110 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 110.0 (TID 109)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 110.0 (TID 109). 68236 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 109) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 110 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 22:28:06 INFO DAGScheduler: Job 106 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028043 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(211) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.7 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0271041 (rel: 0,00137) 0,00202190
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 213 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 107 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 111 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[143] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[143] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 111 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 111.0 (TID 110)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 111.0 (TID 110). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 110) in 25 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 111 (treeAggregate at LogisticRegression.scala:1892) finished in 0,025 s
19/01/24 22:28:06 INFO DAGScheduler: Job 107 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029972 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(213) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 215 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 108 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 112 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[144] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[144] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 112 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 112.0 (TID 111)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 112.0 (TID 111). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 111) in 29 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 112 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 22:28:06 INFO DAGScheduler: Job 108 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034035 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(215) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO StrongWolfeLineSearch: Line search t: 0.5007448344415253 fval: 0.027092939336304526 rhs: 0.027104070568816956 cdd: -4.9042881056530016E-9
19/01/24 22:28:06 INFO LBFGS: Step Size: 0,5007
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0270929 (rel: 0,000411) 0,00189099
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.8 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 217 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 109 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 113 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[145] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[145] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 113 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 113.0 (TID 112)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 113.0 (TID 112). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 112) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 113 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 22:28:06 INFO DAGScheduler: Job 109 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027903 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(217) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0270825 (rel: 0,000385) 0,00131139
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.6 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 219 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 110 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 114 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[146] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 116.3 KB, free 359.5 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.4 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[146] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 114 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 114.0 (TID 113)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 114.0 (TID 113). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 113) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 114 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:06 INFO DAGScheduler: Job 110 finished: treeAggregate at LogisticRegression.scala:1892, took 0,028620 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(219) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.4 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0270734 (rel: 0,000337) 0,00167538
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 63.3 KB, free 359.5 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 57.4 KB, free 359.4 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 221 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 111 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 115 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[147] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 116.3 KB, free 359.3 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[147] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 115 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 115.0 (TID 114)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 115.0 (TID 114). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 114) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 115 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:06 INFO DAGScheduler: Job 111 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029665 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(221) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0270557 (rel: 0,000654) 0,00129150
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 63.3 KB, free 359.3 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 57.3 KB, free 359.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 127.0.0.1:56564 (size: 57.3 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 223 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 112 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 116 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[148] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 116.3 KB, free 359.1 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.1 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.2 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[148] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 116 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 116.0 (TID 115)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 116.0 (TID 115). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 115) in 28 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 116 (treeAggregate at LogisticRegression.scala:1892) finished in 0,029 s
19/01/24 22:28:06 INFO DAGScheduler: Job 112 finished: treeAggregate at LogisticRegression.scala:1892, took 0,034326 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(223) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 127.0.0.1:56564 in memory (size: 57.3 KB, free: 361.3 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0270527 (rel: 0,000112) 0,00487597
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 63.3 KB, free 359.7 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 225 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 361.7 MB)
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 113 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 117 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[149] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 116.3 KB, free 360.3 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[149] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 117 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 117.0 (TID 116)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 117.0 (TID 116). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 116) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 117 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:06 INFO DAGScheduler: Job 113 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029627 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(225) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.7 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0270365 (rel: 0,000598) 0,00244017
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 63.3 KB, free 360.2 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.2 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 227 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 114 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 118 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[150] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 116.3 KB, free 360.1 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 74.8 KB, free 360.0 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[150] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 118 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 118.0 (TID 117)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 118.0 (TID 117). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 117) in 23 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 118 (treeAggregate at LogisticRegression.scala:1892) finished in 0,023 s
19/01/24 22:28:06 INFO DAGScheduler: Job 114 finished: treeAggregate at LogisticRegression.scala:1892, took 0,027619 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(227) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0270285 (rel: 0,000294) 0,00115072
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 63.3 KB, free 360.0 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 57.4 KB, free 360.0 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 127.0.0.1:56564 (size: 57.4 KB, free: 361.6 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 229 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 115 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 119 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[151] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 116.3 KB, free 359.9 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.8 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[151] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 119 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 119.0 (TID 118)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 119.0 (TID 118). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 118) in 24 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 119 (treeAggregate at LogisticRegression.scala:1892) finished in 0,024 s
19/01/24 22:28:06 INFO DAGScheduler: Job 115 finished: treeAggregate at LogisticRegression.scala:1892, took 0,029479 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(229) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 127.0.0.1:56564 in memory (size: 57.4 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0270226 (rel: 0,000218) 0,000931583
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 63.3 KB, free 359.9 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 57.5 KB, free 359.8 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 127.0.0.1:56564 (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 231 from broadcast at LogisticRegression.scala:1879
19/01/24 22:28:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1892
19/01/24 22:28:06 INFO DAGScheduler: Got job 116 (treeAggregate at LogisticRegression.scala:1892) with 1 output partitions
19/01/24 22:28:06 INFO DAGScheduler: Final stage: ResultStage 120 (treeAggregate at LogisticRegression.scala:1892)
19/01/24 22:28:06 INFO DAGScheduler: Parents of final stage: List()
19/01/24 22:28:06 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:06 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[152] at treeAggregate at LogisticRegression.scala:1892), which has no missing parents
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 116.3 KB, free 359.7 MB)
19/01/24 22:28:06 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 74.8 KB, free 359.6 MB)
19/01/24 22:28:06 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 127.0.0.1:56564 (size: 74.8 KB, free: 361.4 MB)
19/01/24 22:28:06 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[152] at treeAggregate at LogisticRegression.scala:1892) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:06 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks
19/01/24 22:28:06 WARN TaskSetManager: Stage 120 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:06 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 119, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914136 bytes)
19/01/24 22:28:06 INFO Executor: Running task 0.0 in stage 120.0 (TID 119)
19/01/24 22:28:06 INFO BlockManager: Found block rdd_40_0 locally
19/01/24 22:28:06 INFO Executor: Finished task 0.0 in stage 120.0 (TID 119). 68193 bytes result sent to driver
19/01/24 22:28:06 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 119) in 26 ms on localhost (executor driver) (1/1)
19/01/24 22:28:06 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
19/01/24 22:28:06 INFO DAGScheduler: ResultStage 120 (treeAggregate at LogisticRegression.scala:1892) finished in 0,026 s
19/01/24 22:28:06 INFO DAGScheduler: Job 116 finished: treeAggregate at LogisticRegression.scala:1892, took 0,031779 s
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(231) (from destroy at LogisticRegression.scala:1933)
19/01/24 22:28:06 INFO LBFGS: Step Size: 1,000
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 127.0.0.1:56564 in memory (size: 57.5 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO LBFGS: Val and Grad Norm: 0,0270067 (rel: 0,000588) 0,000915275
19/01/24 22:28:06 INFO LBFGS: Converged because max iterations reached
19/01/24 22:28:06 INFO TorrentBroadcast: Destroying Broadcast(10) (from destroy at LogisticRegression.scala:796)
19/01/24 22:28:06 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:56564 in memory (size: 7.7 KB, free: 361.5 MB)
19/01/24 22:28:06 INFO MapPartitionsRDD: Removing RDD 40 from persistence list
19/01/24 22:28:06 INFO BlockManager: Removing RDD 40
19/01/24 22:28:07 INFO CodeGenerator: Code generated in 30.00779 ms
19/01/24 22:28:07 INFO Instrumentation: LogisticRegression-logistic_regression_56e41ec73575-1938028476-1: training finished
19/01/24 22:28:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e448ea71b`
19/01/24 22:28:49 INFO SparkSqlParser: Parsing command: sparklyr_tmp_56e48105a6b
19/01/24 22:28:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_56e48105a6b` AS `zzz14`
WHERE (0 = 1)
19/01/24 22:28:49 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e48105a6b`
GROUP BY `Sentiment`, `Prediction`
19/01/24 22:28:49 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:28:49 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:28:49 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e48105a6b`
GROUP BY `Sentiment`, `Prediction`
19/01/24 22:28:49 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:28:49 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:28:49 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e48105a6b`
GROUP BY `Sentiment`, `Prediction`
LIMIT 11
19/01/24 22:28:49 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:28:49 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:28:49 INFO CodeGenerator: Code generated in 17.199039 ms
19/01/24 22:28:49 INFO CodeGenerator: Code generated in 39.954227 ms
19/01/24 22:28:49 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 22:28:49 INFO DAGScheduler: Registering RDD 160 (collect at utils.scala:200)
19/01/24 22:28:49 INFO DAGScheduler: Got job 117 (collect at utils.scala:200) with 1 output partitions
19/01/24 22:28:49 INFO DAGScheduler: Final stage: ResultStage 122 (collect at utils.scala:200)
19/01/24 22:28:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)
19/01/24 22:28:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 121)
19/01/24 22:28:49 INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[160] at collect at utils.scala:200), which has no missing parents
19/01/24 22:28:49 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 196.0 KB, free 362.2 MB)
19/01/24 22:28:49 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 140.2 KB, free 362.0 MB)
19/01/24 22:28:49 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 127.0.0.1:56564 (size: 140.2 KB, free: 363.9 MB)
19/01/24 22:28:49 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[160] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:49 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
19/01/24 22:28:49 WARN TaskSetManager: Stage 121 contains a task of very large size (1869 KB). The maximum recommended task size is 100 KB.
19/01/24 22:28:49 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 1914125 bytes)
19/01/24 22:28:49 INFO Executor: Running task 0.0 in stage 121.0 (TID 120)
19/01/24 22:28:49 INFO BlockManager: Found block rdd_9_0 locally
19/01/24 22:28:49 INFO CodeGenerator: Code generated in 3.898347 ms
19/01/24 22:28:49 INFO CodeGenerator: Code generated in 4.354552 ms
19/01/24 22:28:49 INFO CodeGenerator: Code generated in 4.847225 ms
19/01/24 22:28:49 INFO CodeGenerator: Code generated in 7.302927 ms
19/01/24 22:28:49 INFO CodeGenerator: Code generated in 5.86393 ms
19/01/24 22:28:49 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 364.0 MB)
19/01/24 22:28:49 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 364.0 MB)
19/01/24 22:28:49 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 364.1 MB)
19/01/24 22:28:49 INFO ContextCleaner: Cleaned accumulator 2957
19/01/24 22:28:49 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 364.2 MB)
19/01/24 22:28:49 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 127.0.0.1:56564 in memory (size: 74.8 KB, free: 364.3 MB)
19/01/24 22:28:49 INFO Executor: Finished task 0.0 in stage 121.0 (TID 120). 2306 bytes result sent to driver
19/01/24 22:28:49 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 120) in 301 ms on localhost (executor driver) (1/1)
19/01/24 22:28:49 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
19/01/24 22:28:49 INFO DAGScheduler: ShuffleMapStage 121 (collect at utils.scala:200) finished in 0,303 s
19/01/24 22:28:49 INFO DAGScheduler: looking for newly runnable stages
19/01/24 22:28:49 INFO DAGScheduler: running: Set()
19/01/24 22:28:49 INFO DAGScheduler: waiting: Set(ResultStage 122)
19/01/24 22:28:49 INFO DAGScheduler: failed: Set()
19/01/24 22:28:49 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[163] at collect at utils.scala:200), which has no missing parents
19/01/24 22:28:49 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 177.3 KB, free 362.8 MB)
19/01/24 22:28:49 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 136.0 KB, free 362.6 MB)
19/01/24 22:28:49 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 127.0.0.1:56564 (size: 136.0 KB, free: 364.1 MB)
19/01/24 22:28:49 INFO SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[163] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(0))
19/01/24 22:28:49 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
19/01/24 22:28:49 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 121, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/01/24 22:28:49 INFO Executor: Running task 0.0 in stage 122.0 (TID 121)
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:28:49 INFO Executor: Finished task 0.0 in stage 122.0 (TID 121). 2541 bytes result sent to driver
19/01/24 22:28:49 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 121) in 8 ms on localhost (executor driver) (1/1)
19/01/24 22:28:49 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
19/01/24 22:28:49 INFO DAGScheduler: ResultStage 122 (collect at utils.scala:200) finished in 0,008 s
19/01/24 22:28:49 INFO DAGScheduler: Job 117 finished: collect at utils.scala:200, took 0,320119 s
19/01/24 22:28:49 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 22:28:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 149 bytes
19/01/24 22:28:49 INFO DAGScheduler: Got job 118 (collect at utils.scala:200) with 4 output partitions
19/01/24 22:28:49 INFO DAGScheduler: Final stage: ResultStage 124 (collect at utils.scala:200)
19/01/24 22:28:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 123)
19/01/24 22:28:49 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:49 INFO DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[163] at collect at utils.scala:200), which has no missing parents
19/01/24 22:28:49 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 177.3 KB, free 362.5 MB)
19/01/24 22:28:49 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 136.0 KB, free 362.3 MB)
19/01/24 22:28:49 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 127.0.0.1:56564 (size: 136.0 KB, free: 364.0 MB)
19/01/24 22:28:49 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:49 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 124 (MapPartitionsRDD[163] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
19/01/24 22:28:49 INFO TaskSchedulerImpl: Adding task set 124.0 with 4 tasks
19/01/24 22:28:49 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 122, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
19/01/24 22:28:49 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 123, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
19/01/24 22:28:49 INFO TaskSetManager: Starting task 2.0 in stage 124.0 (TID 124, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
19/01/24 22:28:49 INFO TaskSetManager: Starting task 3.0 in stage 124.0 (TID 125, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
19/01/24 22:28:49 INFO Executor: Running task 0.0 in stage 124.0 (TID 122)
19/01/24 22:28:49 INFO Executor: Running task 1.0 in stage 124.0 (TID 123)
19/01/24 22:28:49 INFO Executor: Running task 2.0 in stage 124.0 (TID 124)
19/01/24 22:28:49 INFO Executor: Running task 3.0 in stage 124.0 (TID 125)
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:28:49 INFO Executor: Finished task 0.0 in stage 124.0 (TID 122). 2515 bytes result sent to driver
19/01/24 22:28:49 INFO Executor: Finished task 3.0 in stage 124.0 (TID 125). 2515 bytes result sent to driver
19/01/24 22:28:49 INFO Executor: Finished task 1.0 in stage 124.0 (TID 123). 2515 bytes result sent to driver
19/01/24 22:28:49 INFO Executor: Finished task 2.0 in stage 124.0 (TID 124). 2515 bytes result sent to driver
19/01/24 22:28:49 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 122) in 12 ms on localhost (executor driver) (1/4)
19/01/24 22:28:49 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 123) in 12 ms on localhost (executor driver) (2/4)
19/01/24 22:28:49 INFO TaskSetManager: Finished task 2.0 in stage 124.0 (TID 124) in 12 ms on localhost (executor driver) (3/4)
19/01/24 22:28:49 INFO TaskSetManager: Finished task 3.0 in stage 124.0 (TID 125) in 12 ms on localhost (executor driver) (4/4)
19/01/24 22:28:49 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
19/01/24 22:28:49 INFO DAGScheduler: ResultStage 124 (collect at utils.scala:200) finished in 0,012 s
19/01/24 22:28:49 INFO DAGScheduler: Job 118 finished: collect at utils.scala:200, took 0,017480 s
19/01/24 22:28:49 INFO SparkContext: Starting job: collect at utils.scala:200
19/01/24 22:28:49 INFO DAGScheduler: Got job 119 (collect at utils.scala:200) with 3 output partitions
19/01/24 22:28:49 INFO DAGScheduler: Final stage: ResultStage 126 (collect at utils.scala:200)
19/01/24 22:28:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
19/01/24 22:28:49 INFO DAGScheduler: Missing parents: List()
19/01/24 22:28:49 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[163] at collect at utils.scala:200), which has no missing parents
19/01/24 22:28:49 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 177.3 KB, free 362.2 MB)
19/01/24 22:28:49 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 136.0 KB, free 362.0 MB)
19/01/24 22:28:49 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 127.0.0.1:56564 (size: 136.0 KB, free: 363.9 MB)
19/01/24 22:28:49 INFO SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1006
19/01/24 22:28:49 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 126 (MapPartitionsRDD[163] at collect at utils.scala:200) (first 15 tasks are for partitions Vector(5, 6, 7))
19/01/24 22:28:49 INFO TaskSchedulerImpl: Adding task set 126.0 with 3 tasks
19/01/24 22:28:49 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 126, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
19/01/24 22:28:49 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 127, localhost, executor driver, partition 5, ANY, 4726 bytes)
19/01/24 22:28:49 INFO TaskSetManager: Starting task 2.0 in stage 126.0 (TID 128, localhost, executor driver, partition 7, ANY, 4726 bytes)
19/01/24 22:28:49 INFO Executor: Running task 1.0 in stage 126.0 (TID 126)
19/01/24 22:28:49 INFO Executor: Running task 0.0 in stage 126.0 (TID 127)
19/01/24 22:28:49 INFO Executor: Running task 2.0 in stage 126.0 (TID 128)
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
19/01/24 22:28:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/01/24 22:28:49 INFO Executor: Finished task 2.0 in stage 126.0 (TID 128). 2535 bytes result sent to driver
19/01/24 22:28:49 INFO TaskSetManager: Finished task 2.0 in stage 126.0 (TID 128) in 6 ms on localhost (executor driver) (1/3)
19/01/24 22:28:49 INFO Executor: Finished task 1.0 in stage 126.0 (TID 126). 2515 bytes result sent to driver
19/01/24 22:28:49 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 126) in 8 ms on localhost (executor driver) (2/3)
19/01/24 22:28:49 INFO Executor: Finished task 0.0 in stage 126.0 (TID 127). 2548 bytes result sent to driver
19/01/24 22:28:49 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 127) in 7 ms on localhost (executor driver) (3/3)
19/01/24 22:28:49 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
19/01/24 22:28:49 INFO DAGScheduler: ResultStage 126 (collect at utils.scala:200) finished in 0,009 s
19/01/24 22:28:49 INFO DAGScheduler: Job 119 finished: collect at utils.scala:200, took 0,013318 s
19/01/24 22:28:49 INFO CodeGenerator: Code generated in 4.464318 ms
19/01/24 22:28:50 INFO SparkSqlParser: Parsing command: SELECT `Sentiment`, `Prediction`, count(*) AS `n`
FROM `sparklyr_tmp_56e48105a6b`
GROUP BY `Sentiment`, `Prediction`
19/01/24 22:28:50 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:28:50 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:28:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 22:28:50 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:28:50 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:28:50 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:28:50 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:28:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 22:28:50 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 22:28:50 INFO CodeGenerator: Code generated in 4.683122 ms
19/01/24 22:28:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 22:28:50 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:28:50 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:28:50 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:28:50 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:28:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 22:28:50 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 22:28:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/01/24 22:28:50 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:28:50 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:28:50 INFO HiveMetaStore: 0: get_database: default
19/01/24 22:28:50 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_database: default	
19/01/24 22:28:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/01/24 22:28:50 INFO audit: ugi=yanis	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/01/24 23:40:12 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:726)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:755)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:755)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:755)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
